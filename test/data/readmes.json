{"name":"joblib","owner":"joblib","path":"README.rst","readme":"|PyPi| |Travis| |AppVeyor| |Codecov|\n\n.. |Travis| image:: https://travis-ci.org/joblib/joblib.svg?branch=master\n   :target: https://travis-ci.org/joblib/joblib\n   :alt: Travis build status\n\n.. |AppVeyor| image:: https://ci.appveyor.com/api/projects/status/github/joblib/joblib?branch=master\u0026svg=true\n   :target: https://ci.appveyor.com/project/joblib-ci/joblib/history\n   :alt: AppVeyor build status\n\n.. |Codecov| image:: https://codecov.io/gh/joblib/joblib/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/joblib/joblib\n   :alt: Codecov coverage\n\n.. |PyPi| image:: https://badge.fury.io/py/joblib.svg\n   :target: https://badge.fury.io/py/joblib\n   :alt: Joblib version\n\n\nThe homepage of joblib with user documentation is located on:\n\nhttps://pythonhosted.org/joblib/\n\nGetting the latest code\n=========================\n\nTo get the latest code using git, simply type::\n\n    git clone git://github.com/joblib/joblib.git\n\nIf you don't have git installed, you can download a zip or tarball\nof the latest code: http://github.com/joblib/joblib/archives/master\n\nInstalling\n=========================\n\nYou can use `pip` to install joblib::\n\n    pip install joblib\n\nfrom any directory or\n\n    python setup.py install\n\nfrom the source directory.\n\nJoblib has no other mandatory dependency than Python (supported\nversions are 2.7+ and 3.4+). Numpy (at least version 1.6.1) is an\noptional dependency for array manipulation.\n\nWorkflow to contribute\n=========================\n\nTo contribute to joblib, first create an account on `github\n\u003chttp://github.com/\u003e`_. Once this is done, fork the `joblib repository\n\u003chttp://github.com/joblib/joblib\u003e`_ to have you own repository,\nclone it using 'git clone' on the computers where you want to work. Make\nyour changes in your clone, push them to your github account, test them\non several computers, and when you are happy with them, send a pull\nrequest to the main repository.\n\nRunning the test suite\n=========================\n\nTo run the test suite, you need the pytest (version \u003e= 3) and coverage modules.\nRun the test suite using::\n\n    pytest joblib\n\nfrom the root of the project.\n\nBuilding the docs\n=========================\n\nTo build the docs you need to have setuptools and sphinx (\u003e=0.5) installed.\nRun the command::\n\n    python setup.py build_sphinx\n\nThe docs are built in the build/sphinx/html directory.\n\n\nMaking a source tarball\n=========================\n\nTo create a source tarball, eg for packaging or distributing, run the\nfollowing command::\n\n    python setup.py sdist\n\nThe tarball will be created in the `dist` directory. This command will\ncompile the docs, and the resulting tarball can be installed with\nno extra dependencies than the Python standard library. You will need\nsetuptool and sphinx.\n\nMaking a release and uploading it to PyPI\n==================================================\n\nThis command is only run by project manager, to make a release, and\nupload in to PyPI::\n\n    python setup.py sdist bdist_wheel upload_docs --upload-dir build/sphinx/html\n    twine upload dist/*\n\nUpdating the changelog\n========================\n\nChanges are listed in the CHANGES.rst file. They must be manually updated\nbut, the following git command may be used to generate the lines::\n\n    git log --abbrev-commit --date=short --no-merges --sparse\n\nLicensing\n----------\n\njoblib is **BSD-licenced** (3 clause):\n\n    This software is OSI Certified Open Source Software.\n    OSI Certified is a certification mark of the Open Source Initiative.\n\n    Copyright (c) 2009-2011, joblib developpers\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright notice,\n      this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation\n      and/or other materials provided with the distribution.\n\n    * Neither the name of Gael Varoquaux. nor the names of other joblib\n      contributors may be used to endorse or promote products derived from\n      this software without specific prior written permission.\n\n    **This software is provided by the copyright holders and contributors\n    \"as is\" and any express or implied warranties, including, but not\n    limited to, the implied warranties of merchantability and fitness for\n    a particular purpose are disclaimed. In no event shall the copyright\n    owner or contributors be liable for any direct, indirect, incidental,\n    special, exemplary, or consequential damages (including, but not\n    limited to, procurement of substitute goods or services; loss of use,\n    data, or profits; or business interruption) however caused and on any\n    theory of liability, whether in contract, strict liability, or tort\n    (including negligence or otherwise) arising in any way out of the use\n    of this software, even if advised of the possibility of such\n    damage.**\n","remote_repo_id":654608,"sha":"7a5484a3cdbba411554039b66ba2969c1539e4ba","size":5095}
,{"name":"perceval","owner":"grimoirelab","path":"README.md","readme":"# Perceval [![Build Status](https://travis-ci.org/grimoirelab/perceval.svg?branch=master)](https://travis-ci.org/grimoirelab/perceval) [![Coverage Status](https://img.shields.io/coveralls/grimoirelab/perceval.svg)](https://coveralls.io/r/grimoirelab/perceval?branch=master) [![PyPI version](https://badge.fury.io/py/perceval.svg)](https://badge.fury.io/py/perceval)\n\nSend Sir Perceval on a quest to retrieve and gather data from software\nrepositories.\n\n## Usage\n\n```\nusage: perceval [-c \u003cfile\u003e] [-g] \u003cbackend\u003e [\u003cargs\u003e] | --help | --version\n\nRepositories are reached using specific backends. The most common backends\nare:\n    askbot           Fetch questions and answers from Askbot site\n    bugzilla         Fetch bugs from a Bugzilla server\n    bugzillarest     Fetch bugs from a Bugzilla server (\u003e=5.0) using its REST API\n    confluence       Fetch contents from a Confluence server\n    discourse        Fetch posts from Discourse site\n    dockerhub        Fetch repository data from Docker Hub site\n    gerrit           Fetch reviews from a Gerrit server\n    git              Fetch commits from Git\n    github           Fetch issues from GitHub\n    gmane            Fetch messages from Gmane\n    hyperkitty       Fetch messages from a HyperKitty archiver\n    jenkins          Fetch builds from a Jenkins server\n    jira             Fetch issues from JIRA issue tracker\n    launchpad        Fetch issues from Launchpad issue tracker\n    mbox             Fetch messages from MBox files\n    mediawiki        Fetch pages and revisions from a MediaWiki site\n    meetup           Fetch events from a Meetup group\n    nntp             Fetch articles from a NNTP news group\n    phabricator      Fetch tasks from a Phabricator site\n    pipermail        Fetch messages from a Pipermail archiver\n    redmine          Fetch issues from a Redmine server\n    rss              Fetch entries from a RSS feed server\n    slack            Fetch messages from a Slack channel\n    stackexchange    Fetch questions from StackExchange sites\n    supybot          Fetch messages from Supybot log files\n    telegram         Fetch messages from the Telegram server\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show version\n  -c FILE, --config FILE\n                        set configuration file\n  -g, --debug           set debug mode on\n\nRun 'perceval \u003cbackend\u003e --help' to get information about a specific backend.\n```\n\n## Requirements\n\n* Python \u003e= 3.4\n* python3-dateutil \u003e= 2.6\n* python3-requests \u003e= 2.7\n* python3-bs4 (beautifulsoup4) \u003e= 4.3\n* python3-feedparser \u003e= 5.1.3\n* python3-dulwich \u003e= 0.18.5\n* grimoirelab-toolkit \u003e= 0.1.0\n\n## Installation\n\nThere are several ways for installing Perceval on your system: from packages,\nfrom a docker image or from the source code.\n\n### Pip\n\nPerceval can be installed using [pip](https://pip.pypa.io/en/stable/), a tool\nfor installing Python packages. To do it, run the next command:\n\n```\n$ pip3 install perceval\n```\n\n### Docker\n\nA Perceval Docker image is available at [DockerHub](https://hub.docker.com/r/grimoirelab/perceval/).\n\nDetailed information on how to run and/or build this image can be found [here](https://github.com/grimoirelab/perceval/tree/master/docker/images/).\n\n### Source code\n\nTo install from the source code you will need to clone the repository first:\n\n```\n$ git clone https://github.com/grimoirelab/perceval.git\n```\n\nIn this case, [setuptools](http://setuptools.readthedocs.io/en/latest/) package will be required.\nMake sure it is installed before running the next commands:\n\n```\n$ pip3 install -r requirements.txt\n$ python3 setup.py install\n```\n\n## Documentation\n\nDocumentation is generated automagically in the [ReadTheDocs Perceval site](http://perceval.readthedocs.org/).\n\n## Examples\n\n### Askbot\n```\n$ perceval askbot 'http://askbot.org/' --from-date '2016-01-01'\n```\n\n### Bugzilla\nTo fetch bugs from Bugzilla, you have two options:\n\na) Use the traditional backend\n\n```\n$ perceval bugzilla 'https://bugzilla.redhat.com/' --backend-user user --backend-password pass --from-date '2016-01-01'\n```\n\nb) Use the REST API backend for Buzilla 5.0 (or higher) servers. We strongly recommend\nthis backend when data is fetched from version servers \u003e=5.0 because the retrieval\nprocess is much faster.\n\n```\n$ perceval bugzillarest 'https://bugzilla.mozilla.org/' --backend-user user --backend-password pass --from-date '2016-01-01'\n```\n\n### Confluence\n```\n$ perceval confluence 'https://wiki.opnfv.org/' --from-date '2016-01-01'\n```\n\n### Discourse\n```\n$ perceval discourse 'https://foro.mozilla-hispano.org/' --from-date '2016-01-01'\n```\n\n### Docker Hub\n```\n$ perceval dockerhub grimoirelab perceval\n```\n\n### Gerrit\nTo run gerrit, you will need an authorized SSH private key:\n\n```\n$ eval `ssh-agent -s`\n$ ssh-add ~/.ssh/id_rsa\nIdentity added: /home/user/.ssh/id_rsa (/home/user/.ssh/id_rsa)\n```\n\nTo run the backend, execute the next command:\n\n```\n$ perceval gerrit --user user 'review.openstack.org' --from-date '2016-01-01'\n```\n\n### Git\n\nTo run this backend execute the next command. Take into account that to run\nthis backend Git program has to be installed on your system.\n\n```\n$ perceval git 'https://github.com/grimoirelab/perceval.git' --from-date '2016-01-01'\n```\n\nGit backend can also work with a Git log file as input. We recommend to use the next command to get the most complete log file.\n\n```\ngit log --raw --numstat --pretty=fuller --decorate=full --parents --reverse --topo-order -M -C -c --remotes=origin --all \u003e /tmp/gitlog.log\n```\n\nThen, to run the backend, just execute any of the next commands:\n\n```\n$ perceval git --git-log '/tmp/gitlog.log' 'file:///myrepo.git'\n```\n\nor\n\n```\n$ perceval git '/tmp/gitlog.log'\n```\n\n### GitHub\n```\n$ perceval github elastic logstash --from-date '2016-01-01'\n```\n\n### Gmane\n```\n$ perceval gmane --offset 2000 'evince-list@gnome.org'\n```\n\n### HyperKitty\n```\n$ perceval hyperkitty 'https://lists.mailman3.org/archives/list/mailman-users@mailman3.org' --from-date 2017-01-01\n```\n\n### Jenkins\n```\n$ perceval jenkins 'http://jenkins.cyanogenmod.org/'\n```\n\n### JIRA\n```\n$ perceval jira 'https://tickets.puppetlabs.com' --project PUP --from-date '2016-01-01'\n```\n\n### Launchpad\n```\n$ perceval launchpad ubuntu --from-date '2016-01-01'\n```\n\n### MBox\n```\n$ perceval mbox 'http://example.com' /tmp/mboxes/\n```\n\n### MediaWiki\n```\n$ perceval mediawiki 'https://wiki.mozilla.org' --from-date '2016-06-30'\n```\n\n### Meetup\n```\n$ perceval meetup 'Software-Development-Analytics' --from-date '2016-06-01' -t abcdefghijk\n```\n\n### NNTP\n```\n$ perceval nntp 'news.mozilla.org' 'mozilla.dev.project-link' --offset 10\n```\n\n### Phabricator\n```\n$ perceval phabricator 'https://secure.phabricator.com/' -t 123456789abcefe\n```\n\n### Pipermail\n```\n$ perceval pipermail 'https://mail.gnome.org/archives/libart-hackers/'\n```\n\nPipermail also is able to fetch data from Apache's `mod_box` interface:\n```\n$ perceval pipermail 'http://mail-archives.apache.org/mod_mbox/httpd-dev/'\n```\n\n### Redmine\n```\n$ perceval redmine 'https://www.redmine.org/' --from-date '2016-01-01' -t abcdefghijk\n```\n\n### RSS\n```\n$ perceval rss 'https://blog.bitergia.com/feed/'\n```\n\n### Slack\n```\n$ perceval slack C0001 --from-date 2016-01-12 -t abcedefghijk\n```\n\n### StackExchange\n```\n$ perceval stackexchange --site stackoverflow --tagged python --from-date '2016-01-01' --token abcdabcdabcdabcd\n```\n\n### Supybot\n```\n$ perceval supybot 'http://channel.example.com' /tmp/supybot/\n```\n\n### Telegram\n\nTelegram backend needs an API token to authenticate the bot. In addition and\nin order to fetch messages from a group or channel, privacy settings must be\ndisabled. To know how to create a bot, to obtain its token and to configure it\nplease read the [Telegram Bots docs pages](https://core.telegram.org/bots).\n\n```\n$ perceval telegram mybot -t 12345678abcdefgh --chats 1 2 -10\n```\n\n## Running tests\n\nPerceval comes with a comprehensive list of unit tests.\nTo run them, in addition to the dependencies installed with Perceval,\nyou need version 0.8.6 of  `httpretty`.\nCurrently, latest version in pypi is 0.8.14,\nwhich seems to have a bug exposed by some Perceval tests.\nSo, ensure you install 0.8.6, which is known to work with them:\n\n```\n$ pip install httpretty==0.8.6\n$ cd tests\n$ python3 run_tests.py\n```\n\n## License\n\nLicensed under GNU General Public License (GPL), version 3 or later.\n","remote_repo_id":47415120,"sha":"aee76d0cb30588b5521e5959fe3d7a52b98d6ad8","size":8368}
,{"name":"gitea","owner":"go-gitea","path":"README.md","readme":"[简体中文](https://github.com/go-gitea/gitea/blob/master/README_ZH.md)\n\n# Gitea - Git with a cup of tea\n\n[![Build Status](https://drone.gitea.io/api/badges/go-gitea/gitea/status.svg)](https://drone.gitea.io/go-gitea/gitea)\n[![Join the Discord chat at https://discord.gg/NsatcWJ](https://img.shields.io/discord/322538954119184384.svg)](https://discord.gg/NsatcWJ)\n[![Join the Matrix chat at https://matrix.to/#/#gitea:matrix.org](https://img.shields.io/badge/matrix-%23gitea%3Amatrix.org-7bc9a4.svg)](https://matrix.to/#/#gitea:matrix.org)\n[![](https://images.microbadger.com/badges/image/gitea/gitea.svg)](https://microbadger.com/images/gitea/gitea \"Get your own image badge on microbadger.com\")\n[![codecov](https://codecov.io/gh/go-gitea/gitea/branch/master/graph/badge.svg)](https://codecov.io/gh/go-gitea/gitea)\n[![Go Report Card](https://goreportcard.com/badge/code.gitea.io/gitea)](https://goreportcard.com/report/code.gitea.io/gitea)\n[![GoDoc](https://godoc.org/code.gitea.io/gitea?status.svg)](https://godoc.org/code.gitea.io/gitea)\n[![Release](https://github-release-version.herokuapp.com/github/go-gitea/gitea/release.svg?style=flat)](https://github.com/go-gitea/gitea/releases/latest)\n[![Help Contribute to Open Source](https://www.codetriage.com/go-gitea/gitea/badges/users.svg)](https://www.codetriage.com/go-gitea/gitea)\n\n| | | |\n|:---:|:---:|:---:|\n|![Dashboard](https://image.ibb.co/dms6DG/1.png)|![Repository](https://image.ibb.co/m6MSLw/2.png)|![Commits History](https://image.ibb.co/cjrSLw/3.png)|\n|![Branches](https://image.ibb.co/e6vbDG/4.png)|![Issues](https://image.ibb.co/bJTJSb/5.png)|![Pull Request View](https://image.ibb.co/e02dSb/6.png)|\n|![Releases](https://image.ibb.co/cUzgfw/7.png)|![Activity](https://image.ibb.co/eZgGDG/8.png)|![Wiki](https://image.ibb.co/dYV9YG/9.png)|\n|![Diff](https://image.ibb.co/ewA9YG/10.png)|![Organization](https://image.ibb.co/ceOwDG/11.png)|![Profile](https://image.ibb.co/c44Q7b/12.png)|\n\n## Purpose\n\nThe goal of this project is to make the easiest, fastest, and most\npainless way of setting up a self-hosted Git service.\nUsing Go, this can be done with an independent binary distribution across\n**all platforms** which Go supports, including Linux, macOS, and Windows\non x86, amd64, ARM and PowerPC architectures.\nWant to try it before doing anything else?\nDo it [with the online demo](https://try.gitea.io/)!\nThis project has been\n[forked](https://blog.gitea.io/2016/12/welcome-to-gitea/) from\n[Gogs](https://gogs.io) since 2016.11 but changed a lot.\n\n## Building\n\nFrom the root of the source tree, run:\n\n    make generate all\n\nMore info: https://docs.gitea.io/en-us/install-from-source/\n\n## Using\n\n    ./gitea web\n\nNOTE: If you're interested in using our APIs, we have experimental\nsupport with [documentation](https://godoc.org/code.gitea.io/sdk/gitea).\n\n## Contributing\n\nExpected workflow is: Fork -\u003e Patch -\u003e Push -\u003e Pull Request\n\nNOTES:\n\n1. **YOU MUST READ THE [CONTRIBUTORS GUIDE](CONTRIBUTING.md) BEFORE STARTING TO WORK ON A PULL REQUEST.**\n2. If you have found a vulnerability in the project, please write privately to **security@gitea.io**. Thanks!\n\n## Further information\n\nFor more information and instructions about how to install Gitea, please look\nat our [documentation](https://docs.gitea.io/en-us/). If you have questions\nthat are not covered by the documentation, you can get in contact with us on\nour [Discord server](https://discord.gg/NsatcWJ),\n[Matrix room](https://matrix.to/#/#gitea:matrix.org),\nor [forum](https://discourse.gitea.io/)!\n\n## Authors\n\n* [Maintainers](https://github.com/orgs/go-gitea/people)\n* [Contributors](https://github.com/go-gitea/gitea/graphs/contributors)\n* [Translators](options/locale/TRANSLATORS)\n\n## License\n\nThis project is licensed under the MIT License.\nSee the [LICENSE](https://github.com/go-gitea/gitea/blob/master/LICENSE) file\nfor the full license text.\n","remote_repo_id":72495579,"sha":"1fe72f498fccd471de42d10edd96df761784818f","size":3880}
,{"name":"tidb","owner":"pingcap","path":"README.md","readme":"![](docs/logo_with_text.png)\n\n[![Build Status](https://travis-ci.org/pingcap/tidb.svg?branch=master)](https://travis-ci.org/pingcap/tidb)\n[![Go Report Card](https://goreportcard.com/badge/github.com/pingcap/tidb)](https://goreportcard.com/report/github.com/pingcap/tidb)\n![Project Status](https://img.shields.io/badge/version-1.0-green.svg)\n[![CircleCI Status](https://circleci.com/gh/pingcap/tidb.svg?style=shield)](https://circleci.com/gh/pingcap/tidb)\n[![Coverage Status](https://coveralls.io/repos/github/pingcap/tidb/badge.svg?branch=master)](https://coveralls.io/github/pingcap/tidb?branch=master)\n\n## What is TiDB?\n\nTiDB (The pronunciation is: /'taɪdiːbi:/ tai-D-B, etymology: titanium) is a Hybrid Transactional/Analytical Processing (HTAP) database. Inspired by the design of Google F1 and Google Spanner, TiDB features infinite horizontal scalability, strong consistency, and high availability. The goal of TiDB is to serve as a one-stop solution for online transactions and analyses.\n\n- __Horizontal scalability__\n\nGrow TiDB as your business grows. You can increase the capacity for storage and computation simply by adding more machines.\n\n- __Compatible with MySQL protocol__\n\nUse TiDB as MySQL. You can replace MySQL with TiDB to power your application without changing a single line of code in most cases.\n\n- __Automatic Failover and high availability__\n\nYour data and applications are always-on. TiDB automatically handles malfunctions and protects your applications from machine failures or even downtime of an entire data-center.\n\n- __Consistent distributed transactions__\n\nThink of TiDB as a single-machine RDBMS. You can start a transaction that crosses multiple machines without worrying about consistency. TiDB makes your application code simple and robust.\n\n- __Online DDL__\n\nEvolve TiDB schemas as your requirement changes. You can add new columns and indexes without stopping or affecting the on-going operations.\n\n- __Multiple storage engine support__\n\nPower TiDB with your most favorite engines. TiDB supports local storage engines such as GolevelDB and BoltDB, as well as [TiKV](https://github.com/pingcap/tikv), a distributed storage engine.\n\nFor more details, see [How we build TiDB](https://pingcap.github.io/blog/2016/10/17/how-we-build-tidb/).\n\n## Roadmap\n\nRead the [Roadmap](https://github.com/pingcap/docs/blob/master/ROADMAP.md).\n\n## Quick start\n\nRead the [Quick Start](https://pingcap.com/doc-QUICKSTART).\n\n## Documentation\n\n+ [English](https://pingcap.com/docs)\n+ [简体中文](https://pingcap.com/docs-cn)\n\n## Architecture\n\n![architecture](./docs/architecture.png)\n\n## Contributing\nContributions are welcomed and greatly appreciated. See [CONTRIBUTING.md](CONTRIBUTING.md)\nfor details on submitting patches and the contribution workflow.\n\n## Connect with us\n\n- **Twitter**: [@PingCAP](https://twitter.com/PingCAP)\n- **Reddit**: https://www.reddit.com/r/TiDB/\n- **Stack Overflow**: https://stackoverflow.com/questions/tagged/tidb\n- **Mailing list**: [Google Group](https://groups.google.com/forum/#!forum/tidb-user)\n\n## License\nTiDB is under the Apache 2.0 license. See the [LICENSE](./LICENSE) file for details.\n\n## Acknowledgments\n- Thanks [cznic](https://github.com/cznic) for providing some great open source tools.\n- Thanks [GolevelDB](https://github.com/syndtr/goleveldb), [BoltDB](https://github.com/boltdb/bolt), and [RocksDB](https://github.com/facebook/rocksdb) for their powerful storage engines.\n","remote_repo_id":41986369,"sha":"6d6e437edd08bd09d27c4ab26b1ffbdeaa658c75","size":3448}
,{"name":"DeepSpeech","owner":"mozilla","path":"README.md","readme":"# Project DeepSpeech\n\n[![Documentation Status](https://readthedocs.org/projects/deepspeech/badge/?version=master)](http://deepspeech.readthedocs.io/?badge=master)\n[![Task Status](https://github.taskcluster.net/v1/repository/mozilla/DeepSpeech/master/badge.svg)](https://github.taskcluster.net/v1/repository/mozilla/DeepSpeech/master/latest)\n\nProject DeepSpeech is an open source Speech-To-Text engine, using a model trained by machine learning techniques, based on [Baidu's Deep Speech research paper](https://arxiv.org/abs/1412.5567). Project DeepSpeech uses Google's [TensorFlow](https://www.tensorflow.org/) project to make the implementation easier.\n\n![Usage](images/usage.gif)\n\nPre-built binaries that can be used for performing inference with a trained model can be installed with `pip`. Proper setup using virtual environment is recommended and you can find that documented [below](#using-the-python-package).\n\nA pre-trained English model is available for use, and can be downloaded using [the instructions below](#getting-the-pre-trained-model).\n\nOnce everything is installed you can then use the `deepspeech` binary to do speech-to-text on short, approximately 5 second, audio files (currently only WAVE files with 16-bit, 16 kHz, mono are supported in the Python client):\n\n```bash\npip install deepspeech\ndeepspeech models/output_graph.pb my_audio_file.wav models/alphabet.txt\n```\n\nAlternatively, quicker inference (The realtime factor on a GeForce GTX 1070 is about 0.44.) can be performed using a supported NVIDIA GPU on Linux. (See the release notes to find which GPU's are supported.) This is done by instead installing the GPU specific package:\n\n```bash\npip install deepspeech-gpu\ndeepspeech models/output_graph.pb my_audio_file.wav models/alphabet.txt\n```\n\nSee the output of `deepspeech -h` for more information on the use of `deepspeech`. (If you experience problems running `deepspeech`, please check [required runtime dependencies](native_client/README.md#required-dependencies)).\n\n**Table of Contents**\n\n- [Prerequisites](#prerequisites)\n- [Getting the code](#getting-the-code)\n- [Getting the pre-trained model](#getting-the-pre-trained-model)\n- [Using the model](#using-the-model)\n  - [Using the Python package](#using-the-python-package)\n  - [Using the command line client](#using-the-command-line-client)\n  - [Using the Node.JS package](#using-the-nodejs-package)\n  - [Installing bindings from source](#installing-bindings-from-source)\n  - [Third party bindings](#third-party-bindings)\n- [Training](#training)\n  - [Installing prerequisites for training](#installing-prerequisites-for-training)\n  - [Recommendations](#recommendations)\n  - [Common Voice training data](#common-voice-training-data)\n  - [Training a model](#training-a-model)\n  - [Checkpointing](#checkpointing)\n  - [Exporting a model for inference](#exporting-a-model-for-inference)\n  - [Distributed computing across more than one machine](#distributed-training-across-more-than-one-machine)\n  - [Continuing training from a frozen graph](#continuing-training-from-a-frozen-graph)\n- [Code documentation](#code-documentation)\n- [Contact/Getting Help](#contactgetting-help)\n\n## Prerequisites\n\n* [Python 2.7](https://www.python.org/)\n* [Git Large File Storage](https://git-lfs.github.com/)\n\n## Getting the code\n\nInstall [Git Large File Storage](https://git-lfs.github.com/), either manually or through a package like `git-lfs` if available on your system. Then clone the DeepSpeech repository normally:\n\n```bash\ngit clone https://github.com/mozilla/DeepSpeech\n```\n\n## Getting the pre-trained model\n\nIf you want to use the pre-trained English model for performing speech-to-text, you can download it (along with other important inference material) from the [DeepSpeech releases page](https://github.com/mozilla/DeepSpeech/releases). Alternatively, you can run the following command to download and unzip the files in your current directory:\n\n```bash\nwget -O - https://github.com/mozilla/DeepSpeech/releases/download/v0.1.0/deepspeech-0.1.0-models.tar.gz | tar xvfz -\n```\n\n## Using the model\n\nThere are three ways to use DeepSpeech inference:\n\n- [The Python package](#using-the-python-package)\n- [The command-line client](#using-the-command-line-client)\n- [The Node.JS package](#using-the-nodejs-package)\n\n\n### Using the Python package\n\nPre-built binaries that can be used for performing inference with a trained model can be installed with `pip`. You can then use the `deepspeech` binary to do speech-to-text on an audio file:\n\nFor the Python bindings, it is highly recommended that you perform the installation within a Python 2.7 virtual environment. You can find more information about those in [this documentation](http://docs.python-guide.org/en/latest/dev/virtualenvs/).\nWe will continue under the assumption that you already have your system properly setup to create new virtual environments.\n\n#### Create a DeepSpeech virtual environment\n\nIn creating a virtual environment you will create a directory containing a `python` binary and everything needed to run deepspeech. You can use whatever directory you want. For the purpose of the documentation, we will rely on `$HOME/tmp/deepspeech-venv`. You can create it using this command:\n\n```\n$ virtualenv $HOME/tmp/deepspeech-venv/\n```\n\nOnce this command completes successfully, the environment will be ready to be activated.\n\n#### Activating the environment\n\nEach time you need to work with DeepSpeech, you have to *activate*, *load* this virtual environment. This is done with this simple command:\n\n```\n$ source $HOME/tmp/deepspeech-venv/bin/activate\n```\n\n#### Installing DeepSpeech Python bindings\n\nOnce your environment has been setup and loaded, you can use `pip` to manage packages locally. On a fresh setup of the virtualenv, you will have to install the DeepSpeech wheel. You can check if it is already installed by taking a look at the output of `pip list`. To perform the installation, just issue:\n\n```\n$ pip install deepspeech\n```\n\nIf it is already installed, you can also update it:\n```\n$ pip install --upgrade deepspeech\n```\n\nAlternatively, if you have a supported NVIDIA GPU on Linux (See the release notes to find which GPU's are supported.), you can install the GPU specific package as follows:\n\n```\n$ pip install deepspeech-gpu\n```\n\nor update it as follows:\n```\n$ pip install --upgrade deepspeech-gpu\n```\n\nIn both cases, it should take care of installing all the required dependencies. Once it is done, you should be able to call the sample binary using `deepspeech` on your command-line.\n\nNote: the following command assumes you [downloaded the pre-trained model](#getting-the-pre-trained-model).\n\n```bash\ndeepspeech models/output_graph.pb my_audio_file.wav models/alphabet.txt models/lm.binary models/trie\n```\n\nThe last two arguments are optional, and represent a language model.\n\nSee [client.py](native_client/python/client.py) for an example of how to use the package programatically.\n\n### Using the command-line client\n\nTo download the pre-built binaries, use `util/taskcluster.py`:\n\n```bash\npython util/taskcluster.py --target .\n```\n\nor if you're on macOS:\n\n```bash\npython util/taskcluster.py --arch osx --target .\n```\n\nThis will download `native_client.tar.xz` which includes the deepspeech binary and associated libraries, and extract it into the current folder. `taskcluster.py` will download binaries for Linux/x86_64 by default, but you can override that behavior with the `--arch` parameter. See the help info with `python util/taskcluster.py -h` for more details.\n\nNote: the following command assumes you [downloaded the pre-trained model](#getting-the-pre-trained-model).\n\n```bash\n./deepspeech models/output_graph.pb audio_input.wav models/alphabet.txt models/lm.binary models/trie\n```\n\n\nSee the help output with `./deepspeech -h` and the [native client README](native_client/README.md) for more details.\n\n### Using the Node.JS package\n\nYou can download the Node.JS bindings using `npm`:\n\n```bash\nnpm install deepspeech\n```\n\nAlternatively, if you're using Linux and have a supported NVIDIA GPU (See the release notes to find which GPU's are supported.), you can install the GPU specific package as follows:\n\n```bash\nnpm install deepspeech-gpu\n```\n\nSee [client.js](native_client/javascript/client.js) for an example of how to use the bindings.\n\n### Installing bindings from source\n\nIf pre-built binaries aren't available for your system, you'll need to install them from scratch. Follow [these instructions](native_client/README.md).\n\n### Third party bindings\n\nIn addition to the bindings above, third party developers have started to provide bindings to other languages:\n\n* [Asticode](https://github.com/asticode) provides [Golang](https://golang.org) bindings in its [go-astideepspeech](https://github.com/asticode/go-astideepspeech) repo.\n* [RustAudio](https://github.com/RustAudio) provide a [Rust](https://www.rust-lang.org) binding, the installation and use of which is described in their [deepspeech-rs](https://github.com/RustAudio/deepspeech-rs) repo.\n* [stes](https://github.com/stes) provides preliminary [PKGBUILDs](https://wiki.archlinux.org/index.php/PKGBUILD) to install the client and python bindings on [Arch Linux](https://www.archlinux.org/) in the [arch-deepspeech](https://github.com/stes/arch-deepspeech) repo.\n\n## Training\n\n### Installing prerequisites for training\n\nInstall the required dependencies using pip:\n\n```bash\ncd DeepSpeech\npython util/taskcluster.py --target /tmp --source tensorflow --artifact tensorflow_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whl\npip install /tmp/tensorflow_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whl\npip install -r requirements.txt\n```\n\nYou'll also need to download `native_client.tar.xz` or build the native client files yourself to get the custom TensorFlow OP needed for decoding the outputs of the neural network. You can use `util/taskcluster.py` to download the files for your architecture:\n\n```bash\npython util/taskcluster.py --target .\n```\n\nThis will download the native client files for the x86_64 architecture without CUDA support, and extract them into the current folder. If you prefer building the binaries from source, see the [native_client README file](native_client/README.md). We also have binaries with CUDA enabled (\"--arch gpu\") and for ARM7 (\"--arch arm\").\n\n### Recommendations\n\nIf you have a capable (Nvidia, at least 8GB of VRAM) GPU, it is highly recommended to install TensorFlow with GPU support. Training will likely be significantly quicker than using the CPU. To enable GPU support, you can do:\n\n```bash\npip uninstall tensorflow\npython util/taskcluster.py --target /tmp --source tensorflow --arch gpu --artifact tensorflow_gpu_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whl\npip install /tmp/tensorflow_gpu_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whl\n```\n\n### Common Voice training data\n\nThe Common Voice corpus consists of voice samples that were donated through [Common Voice](https://voice.mozilla.org/).\nWe provide an importer, that automates the whole process of downloading and preparing the corpus.\nYou just specify a target directory where all Common Voice contents should go.\nIf you already downloaded the Common Voice corpus archive from [here](https://voice.mozilla.org/data), you can simply run the import script on the directory where the corpus is located.\nThe importer will then skip downloading it and immediately proceed to unpackaging and importing.\nTo start the import process, you can call:\n\n```bash\nbin/import_cv.py path/to/target/directory\n```\n\nPlease be aware that this requires at least 70GB of free disk space and quite some time to conclude.\nAs this process creates a huge number of small files, using an SSD drive is highly recommended.\nIf the import script gets interrupted, it will try to continue from where it stopped the next time you run it.\nUnfortunately, there are some cases where it will need to start over.\nOnce the import is done, the directory will contain a bunch of CSV files.\n\nThe following files are official user-validated sets for training, validating and testing:\n\n- `cv-valid-train.csv`\n- `cv-valid-dev.csv`\n- `cv-valid-test.csv`\n\nThe following files are the non-validated unofficial sets for training, validating and testing:\n\n- `cv-other-train.csv`\n- `cv-other-dev.csv`\n- `cv-other-test.csv`\n\n`cv-invalid.csv` contains all samples that users flagged as invalid.\n\nA sub-directory called `cv_corpus_{version}` contains the mp3 and wav files that were extracted from an archive named `cv_corpus_{version}.tar.gz`.\nAll entries in the CSV files refer to their samples by absolute paths. So moving this sub-directory would require another import or tweaking the CSV files accordingly.\n\nTo use Common Voice data during training, validation and testing, you pass (comma separated combinations of) their filenames into `--train_files`, `--dev_files`, `--test_files` parameters of `DeepSpeech.py`.\nIf, for example, Common Voice was imported into `../data/CV`, `DeepSpeech.py` could be called like this:\n\n```bash\n./DeepSpeech.py --train_files ../data/CV/cv-valid-train.csv,../data/CV/cv-other-train.csv --dev_files ../data/CV/cv-valid-dev.csv --test_files ../data/CV/cv-valid-test.csv\n```\n\n### Training a model\n\nThe central (Python) script is `DeepSpeech.py` in the project's root directory. For its list of command line options, you can call:\n\n```bash\n./DeepSpeech.py --help\n```\n\nTo get the output of this in a slightly better-formatted way, you can also look up the option definitions top of `DeepSpeech.py`.\n\nFor executing pre-configured training scenarios, there is a collection of convenience scripts in the `bin` folder. Most of them are named after the corpora they are configured for. Keep in mind that the other speech corpora are *very large*, on the order of tens of gigabytes, and some aren't free. Downloading and preprocessing them can take a very long time, and training on them without a fast GPU (GTX 10 series recommended) takes even longer.\n\n**If you experience GPU OOM errors while training, try reducing the batch size with the `--train_batch_size`, `--dev_batch_size` and `--test_batch_size` parameters.**\n\nAs a simple first example you can open a terminal, change to the directory of the DeepSpeech checkout and run:\n\n```bash\n./bin/run-ldc93s1.sh\n```\n\nThis script will train on a small sample dataset called LDC93S1, which can be overfitted on a GPU in a few minutes for demonstration purposes. From here, you can alter any variables with regards to what dataset is used, how many training iterations are run and the default values of the network parameters.\nFeel also free to pass additional (or overriding) `DeepSpeech.py` parameters to these scripts.\nThen, just run the script to train the modified network.\n\nEach dataset has a corresponding importer script in `bin/` that can be used to download (if it's freely available) and preprocess the dataset. See `bin/import_librivox.py` for an example of how to import and preprocess a large dataset for training with Deep Speech.\n\nIf you've run the old importers (in `util/importers/`), they could have removed source files that are needed for the new importers to run. In that case, simply remove the extracted folders and let the importer extract and process the dataset from scratch, and things should work.\n\n### Checkpointing\n\nDuring training of a model so-called checkpoints will get stored on disk. This takes place at a configurable time interval. The purpose of checkpoints is to allow interruption (also in the case of some unexpected failure) and later continuation of training without losing hours of training time. Resuming from checkpoints happens automatically by just (re)starting training with the same `--checkpoint_dir` of the former run.\n\nBe aware however that checkpoints are only valid for the same model geometry they had been generated from. In other words: If there are error messages of certain `Tensors` having incompatible dimensions, this is most likely due to an incompatible model change. One usual way out would be to wipe all checkpoint files in the checkpoint directory or changing it before starting the training.\n\n### Exporting a model for inference\n\nIf the `--export_dir` parameter is provided, a model will have been exported to this directory during training.\nRefer to the corresponding [README.md](native_client/README.md) for information on building and running a client that can use the exported model.\n\n### Distributed training across more than one machine\n\nDeepSpeech has built-in support for [distributed TensorFlow](https://www.tensorflow.org/deploy/distributed). To get an idea on how this works, you can use the script `bin/run-cluster.sh` for running a cluster with workers just on the local machine.\n\n```bash\n$ bin/run-cluster.sh --help\nUsage: run-cluster.sh [--help] [--script script] [p:w:g] \u003carg\u003e*\n\n--help      print this help message\n--script    run the provided script instead of DeepSpeech.py\np           number of local parameter servers\nw           number of local workers\ng           number of local GPUs per worker\n\u003carg\u003e*      remaining parameters will be forwarded to DeepSpeech.py or a provided script\n\nExample usage - The following example will create a local DeepSpeech.py cluster\nwith 1 parameter server, and 2 workers with 1 GPU each:\n$ run-cluster.sh 1:2:1 --epoch 10\n```\n\nBe aware that for the help example to be able to run, you need at least two `CUDA` capable GPUs (2 workers times 1 GPU). The script utilizes environment variable `CUDA_VISIBLE_DEVICES` for `DeepSpeech.py` to see only the provided number of GPUs per worker.\nThe script is meant to be a template for your own distributed computing instrumentation. Just modify the startup code for the different servers (workers and parameter servers) accordingly. You could use SSH or something similar for running them on your remote hosts.\n\n### Continuing training from a frozen graph\n\nIf you'd like to use one of the pre-trained models released by Mozilla to bootstrap your training process (transfer learning, fine tuning), you can do so by using the `--initialize_from_frozen_model` flag in `DeepSpeech.py`. For best results, make sure you're passing an empty `--checkpoint_dir` when resuming from a frozen model.\n\nFor example, if you want to fine tune the entire graph using your own data in `my-train.csv`, `my-dev.csv` and `my-test.csv`, for three epochs, you can something like the following, tuning the hyperparameters as needed:\n\n```bash\nmkdir fine_tuning_checkpoints\npython DeepSpeech.py --n_hidden 2048 --initialize_from_frozen_model path/to/model/output_graph.pb --checkpoint_dir fine_tuning_checkpoints --epoch 3 --train_files my-train.csv --dev_files my-dev.csv --test_files my_dev.csv --learning_rate 0.0001\n```\n\nNote: the released models were trained with `--n_hidden 2048`, so you need to use that same value when initializing from the release models.\n\n## Code documentation\n\nDocumentation (incomplete) for the code can be found here: http://deepspeech.readthedocs.io/en/latest/\n\n## Contact/Getting Help\n\nThere are several ways to contact us or to get help:\n\n1. [**FAQ**](https://github.com/mozilla/DeepSpeech/wiki#frequently-asked-questions) - We have a list of common questions, and their answers, in our [FAQ](https://github.com/mozilla/DeepSpeech/wiki#frequently-asked-questions). When just getting started, it's best to first check the [FAQ](https://github.com/mozilla/DeepSpeech/wiki#frequently-asked-questions) to see if your question is addressed.\n\n2. [**Discourse Forums**](https://discourse.mozilla.org/c/deep-speech) - If your question is not addressed in the [FAQ](https://github.com/mozilla/DeepSpeech/wiki#frequently-asked-questions), the [Discourse Forums](https://discourse.mozilla.org/c/deep-speech) is the next place to look. They contain conversations on [General Topics](https://discourse.mozilla.org/t/general-topics/21075), [Using Deep Speech](https://discourse.mozilla.org/t/using-deep-speech/21076/4), and [Deep Speech Development](https://discourse.mozilla.org/t/deep-speech-development/21077).\n\n3. [**IRC**](https://wiki.mozilla.org/IRC) - If your question is not addressed by either the [FAQ](https://github.com/mozilla/DeepSpeech/wiki#frequently-asked-questions) or [Discourse Forums](https://discourse.mozilla.org/c/deep-speech), you can contact us on the `#machinelearning` channel on [Mozilla IRC](https://wiki.mozilla.org/IRC); people there can try to answer/help\n\n4. [**Issues**](https://github.com/mozilla/deepspeech/issues) - Finally, if all else fails, you can open an issue in our repo.\n","remote_repo_id":60273704,"sha":"30da306a077e837b1f3f96aa384218ea3bf181eb","size":20517}
,{"name":"homebrew-core","owner":"Homebrew","path":"README.md","readme":"# Homebrew Core\nCore formulae for the Homebrew package manager.\n\n## How do I install these formulae?\nJust `brew install \u003cformula\u003e`. This is the default tap for Homebrew and is installed by default.\n\n## Troubleshooting\nFirst, please run `brew update` (twice) and `brew doctor`.\n\nSecond, read the [Troubleshooting Checklist](https://docs.brew.sh/Troubleshooting.html).\n\n**If you don’t read these it will take us far longer to help you with your problem.**\n\n## Contributing\nRead [CONTRIBUTING.md](/CONTRIBUTING.md).\n\nCreating new formulae, updating existing ones, and fixing build issues is easier than you think!\n\nTry `brew edit $FORMULA` and see how you fare.\n\n## Documentation\n`brew help`, `man brew`, [Homebrew/brew's README](https://github.com/Homebrew/brew#homebrew) or check [Homebrew's documentation](https://github.com/Homebrew/brew/tree/master/docs#readme).\n\n## License\nCode is under the [BSD 2-clause \"Simplified\" License](https://github.com/Homebrew/homebrew-core/blob/master/LICENSE.txt).\n","remote_repo_id":52855516,"sha":"8e8aad88bbec9479a891298b8afd409b283f7ec8","size":1001}
,{"name":"Spots","owner":"hyperoslo","path":"README.md","readme":"![Spots logo](https://raw.githubusercontent.com/hyperoslo/Spots/master/Images/cover_v6.jpg)\n\u003cdiv align=\"center\"\u003e\n\u003ca href=\"https://travis-ci.org/hyperoslo/Spots\" target=\"_blank\"\u003e\n\u003cimg src=\"http://img.shields.io/travis/hyperoslo/Spots.svg?style=flat\"\u003e\n\u003c/a\u003e\n\n\u003ca href=\"http://cocoadocs.org/docsets/Spots\" target=\"_blank\"\u003e\n\u003cimg src=\"https://img.shields.io/cocoapods/v/Spots.svg?style=flat\"\u003e\n\u003c/a\u003e\n\n\u003ca href=\"https://github.com/Carthage/Carthage\" target=\"_blank\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Carthage-Compatible-brightgreen.svg?style=flat\"\u003e\n\u003c/a\u003e\n\n\u003ca href=\"http://cocoadocs.org/docsets/Spots\" target=\"_blank\"\u003e\n\u003cimg src=\"https://img.shields.io/cocoapods/l/Spots.svg?style=flat\"\u003e\n\u003c/a\u003e\n\n\u003ca href=\"http://cocoadocs.org/docsets/Spots\" target=\"_blank\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/platform-ios | macos | tvos-lightgrey.svg\"\u003e\n\u003c/a\u003e\n\u003cbr/\u003e\n\u003ca href=\"http://cocoadocs.org/docsets/Spots\" target=\"_blank\"\u003e\n\u003cimg src=\"https://img.shields.io/cocoapods/metrics/doc-percent/Spots.svg?style=flat\"\u003e\n\u003c/a\u003e\n\n\u003ca href=\"https://codecov.io/github/hyperoslo/Spots?branch=master\"\u003e\u003cimg src=\"https://codecov.io/github/hyperoslo/Spots/coverage.svg?branch=master\" alt=\"Coverage Status\" data-canonical-src=\"https://codecov.io/github/hyperoslo/Spots/coverage.svg?branch=master\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\n\u003cimg src=\"https://img.shields.io/badge/%20in-swift%203.0-orange.svg\"\u003e\n\n\u003ca href=\"https://gitter.im/hyperoslo/Spots?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge\u0026utm_content=badge\"\u003e\n\u003cimg src=\"https://badges.gitter.im/hyperoslo/Spots.svg\"\u003e\n\u003c/a\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003c/div\u003e\n\n**Spots** is a cross-platform view controller framework for building component-based UIs. The internal architecture is built using generic view models that can be transformed both to and from JSON. So, moving your UI declaration to a backend is as easy as pie.\nData source and delegate setup is handled by **Spots**, so there is no need for you to do that manually. The public API is jam-packed with convenience methods for performing mutation, it is as easy as working with a regular collection type.\n\n## Table of Contents\n\n\u003cimg src=\"https://raw.githubusercontent.com/hyperoslo/Spots/master/Images/icon_v5.png\" alt=\"Spots Icon\" align=\"right\" /\u003e\n\n* [Getting started with Spots](#getting-started-with-spots)\n* [Origin Story](#origin-story)\n* [Universal support](#universal-support)\n* [Usage](#usage)\n* [Key features](#key-features)\n* [Programmatic approach](#programmatic-approach)\n* [The many faces of Spots](#the-many-faces-of-components)\n* [Installation](#installation)\n* [Dependencies](#dependencies)\n* [Author](#author)\n* [Credits](#credits)\n* [Contributing](#contributing)\n* [License](#license)\n\n## Getting started with Spots\n\nIf you are looking for a way to get started with `Spots`, we recommend taking a look at our [Getting started guide](https://github.com/hyperoslo/Spots/blob/master/Documentation/Getting%20started%20guide.md).\n\n## Origin Story\n\nWe wrote a Medium article about how and why we built `Spots`.\nYou can find it here: [Hitting the sweet spot of inspiration](https://medium.com/@zenangst/hitting-the-sweet-spot-of-inspiration-637d387bc629#.b9a1mun2i)\n\n## Universal support\n\nApple's definition of a universal applications is iPhone and iPad. Spots takes this a step further with one controller tailored to each platform to support all your UI related update needs. Internally, everything conforms to the same shared protocol. What this means for you, is that get a unified experience when developing for iOS, tvOS or macOS.\n\n## Usage\n\nUse the following links to dive a bit deeper into how Spots works.\n\n* [Building views in Spots](https://github.com/hyperoslo/Spots/blob/master/Documentation/Building%20views%20in%20Spots.md)\n* [Caching](https://github.com/hyperoslo/Spots/blob/master/Documentation/Caching.md)\n* [Delegates](https://github.com/hyperoslo/Spots/blob/master/Documentation/Delegates.md)\n* [Live Editing](https://github.com/hyperoslo/Spots/blob/master/Documentation/Live%20Editing.md)\n* [JSON Structure](https://github.com/hyperoslo/Spots/blob/master/Documentation/JSON%20Structure.md)\n* [Models](https://github.com/hyperoslo/Spots/blob/master/Documentation/Models.md)\n* [Performing mutation](https://github.com/hyperoslo/Spots/blob/master/Documentation/Performing%20mutation.md)\n* [Working with layout](https://github.com/hyperoslo/Spots/blob/master/Documentation/Layout.md)\n* [Working with the SpotsController](https://github.com/hyperoslo/Spots/blob/master/Documentation/SpotsController.md)\n\n\n## How does it work?\n\nAt the top level of **Spots**, you have the **SpotsController** which is the replacement for your view controller.\n\nInside of the **SpotsController**, you have a **SpotsScrollView** that handles the linear layout of the components that you add to your data source. It is also in charge of giving the user a unified scrolling experience. Scrolling is disabled on all underlaying components except for components that have horizontal scrolling.\n\nSo how does scrolling work? Whenever a user scrolls, the **SpotsScrollView** computes the offset and size of its children. By using this technique you can easily create screens that contain lists, grids and carousels with a scrolling experience as smooth as proverbial butter. By dynamically changing the size and offset of the children, **SpotsScrollView** also ensures that reusable views are allocated and deallocated like you would expect them to.\n**SpotsScrollView** uses KVO on any view that gets added so if one component changes height or position, the entire layout will invalidate itself and redraw it like it was intended.\n\n**SpotsController** supports multiple **Component**'s, each represent their own UI container and hold their own data source. Components all share the same data model called `ComponentModel`, it includes layout, interaction and view model data. **Component** gets its super-powers from protocol extensions, powers like mutation, layout processing and convenience methods for accessing model information. \n\n## Key features\n\n- JSON based views that could be served up by your backend.\n- Live editing.\n- View based caching for controllers, table and collection views.\n- Supports displaying multiple collections, tables and regular views in the same container.\n- Features both infinity scrolling and pull to refresh (on iOS), all you have to do is to\nsetup delegates that conform to the public protocols on `SpotsController`.\n- No need to implement your own data source, every `Component` has its\nown set of `Item`s,\nwhich is maintained internally and is there at your disposal if you decide to\nmake changes to them.\n- Easy configuration for registering views.\nThis improves code reuse and helps to theme your app and ultimately keep your application consistent.\n- A rich public API for appending, prepending, inserting, updating or\ndeleting `Item`s.\n- Has built-in support for regular views inside of both collection and table views.\nWrite one view and use it across your application, when and where you want to use it.\n- Supports view states such as normal, highlighted and selected.\n- View height caching that improves performance as each view has its height stored as a calculated value.\non the view model.\n- Supports multiple views inside the same data source, no more ugly if-statements in your implementation;\n- Soft \u0026 hard updates to UI components.\n- Supports both views made programmatically and nib-based views.\n**Spots** handles this for you by using a view registry.\n\n## Installation\n\n**Spots** is available through [CocoaPods](http://cocoapods.org). To install\nit, simply add the following line to your Podfile:\n\n```ruby\npod 'Spots'\n```\n\n**Spots** is also available through [Carthage](https://github.com/Carthage/Carthage). To install it, add the following to your `Cartfile`:\n\n```ruby\ngithub \"hyperoslo/Spots\"\n```\n\n## Changelog\n\nLooking for a change log? You can find it [here](https://github.com/hyperoslo/Spots/blob/master/CHANGELOG.md)\n\n## Dependencies\n\n- **[Cache](https://github.com/hyperoslo/Cache)**\nUsed for `ComponentModel` and `Item` caching when initializing a `SpotsController` or `CoreComponent` object with a cache key.\n\n## Author\n\n[Hyper](http://hyper.no) made this with ❤️. If you’re using this library we probably want to [hire you](https://github.com/hyperoslo/iOS-playbook/blob/master/HYPER_RECIPES.md)! Send us an email at ios@hyper.no.\n\n## Contribute\n\nWe would love you to contribute to **Spots**, check the [CONTRIBUTING](https://github.com/hyperoslo/Spots/blob/master/CONTRIBUTING.md) file for more info.\n\n## Credits\n\n- Infinite scrolling on tvOS was greatly inspired by [willowtreeapps/ouroboros](https://github.com/willowtreeapps/ouroboros), if you haven't check it out. You should!\n- The idea behind Spot came from [John Sundell](https://github.com/johnsundell)'s tech talk \"ComponentModels \u0026 View Models in the Cloud - how Spotify builds native, dynamic UIs\".\n- [Ole Begemanns](https://github.com/ole/) implementation of [OLEContainerScrollView](https://github.com/ole/OLEContainerScrollView) is the basis for `SpotsScrollView`, we salute you.\nReference: http://oleb.net/blog/2014/05/scrollviews-inside-scrollviews/\n\n## License\n\n**Spots** is available under the MIT license. See the LICENSE file for more info.\n","remote_repo_id":43603611,"sha":"0e20c0c120b074e7757e2e87a8b07d11b9440e78","size":9237}
,{"name":"admin-on-rest","owner":"marmelab","path":"README.md","readme":"# admin-on-rest [![Build Status](https://travis-ci.org/marmelab/admin-on-rest.svg?branch=master)](https://travis-ci.org/marmelab/admin-on-rest)\n\nA frontend Framework for building admin applications running in the browser on top of REST services, using ES6, [React](https://facebook.github.io/react/) and [Material Design](https://material.io/). Open sourced and maintained by [marmelab](https://marmelab.com/).\n\n[Demo](https://marmelab.com/admin-on-rest-demo/) - [Documentation](https://marmelab.com/admin-on-rest/) - [Releases](https://github.com/marmelab/admin-on-rest/releases) - [Support](http://stackoverflow.com/questions/tagged/admin-on-rest)\n\n[![admin-on-rest-demo](https://marmelab.com/admin-on-rest/img/admin-on-rest-demo-still.png)](https://vimeo.com/205118063)\n\n## Features\n\n* Adapts to any REST backend\n* Complete documentation\n* Optimistic rendering (renders before the server returns)\n* Relationships (many to one, one to many)\n* Internationalization (i18n)\n* Conditional formatting\n* Themeable\n* Supports any authentication provider (REST API, OAuth, Basic Auth, ...)\n* Full-featured Datagrid (sort, pagination, filters)\n* Filter-as-you-type\n* Supports any form layout (simple, tabbed, etc.)\n* Data Validation\n* Custom actions\n* Large library of components for various data types: boolean, number, rich text, etc.\n* WYSIWYG editor\n* Customize dashboard, menu, layout\n* Super easy to extend and override (it's just React components)\n* Highly customizable interface\n* Can connect to multiple backends\n* Leverages the best libraries in the React ecosystem (Redux, redux-form, redux-saga, material-ui, recompose)\n* Can be included in another React app\n* Inspired by the popular [ng-admin](https://github.com/marmelab/ng-admin) library (also by marmelab)\n\n## Versions In This Repository\n\n* [master](https://github.com/marmelab/admin-on-rest/commits/master) - commits that will be included in the next _patch_ release\n\n* [next](https://github.com/marmelab/admin-on-rest/commits/next) - commits that will be included in the next _major_ or _minor_ release\n\nBugfix PRs that don't break BC should be made against **master**. All other PRs (new features, bugfix with BC break) should be made against **next**.\n\n## Installation\n\nAdmin-on-rest is available from npm. You can install it (and its required dependencies)\nusing:\n\n```sh\nnpm install --save-dev admin-on-rest\n```\n\n## Documentation\n\nRead the [Tutorial](http://marmelab.com/admin-on-rest//Tutorial.html) for a 15 minutes introduction. After that, head to the [Documentation](http://marmelab.com/admin-on-rest//index.html), or checkout the [source code of the demo](https://github.com/marmelab/admin-on-rest-demo) for an example usage.\n\n## At a Glance\n\n```jsx\n// in app.js\nimport React from 'react';\nimport { render } from 'react-dom';\nimport { simpleRestClient, Admin, Resource } from 'admin-on-rest';\n\nimport { PostList, PostEdit, PostCreate, PostIcon } from './posts';\n\nrender(\n    \u003cAdmin restClient={simpleRestClient('http://localhost:3000')}\u003e\n        \u003cResource name=\"posts\" list={PostList} edit={PostEdit} create={PostCreate} icon={PostIcon}/\u003e\n    \u003c/Admin\u003e,\n    document.getElementById('root')\n);\n```\n\nThe `\u003cResource\u003e` component is a configuration component that allows to define sub components for each of the admin view: `list`, `edit`, and `create`. These components use Material UI and custom components from admin-on-rest:\n\n```jsx\n// in posts.js\nimport React from 'react';\nimport { List, Datagrid, Edit, Create, SimpleForm, DateField, TextField, EditButton, DisabledInput, TextInput, LongTextInput, DateInput } from 'admin-on-rest';\nexport PostIcon from 'material-ui/svg-icons/action/book';\n\nexport const PostList = (props) =\u003e (\n    \u003cList {...props}\u003e\n        \u003cDatagrid\u003e\n            \u003cTextField source=\"id\" /\u003e\n            \u003cTextField source=\"title\" /\u003e\n            \u003cDateField source=\"published_at\" /\u003e\n            \u003cTextField source=\"average_note\" /\u003e\n            \u003cTextField source=\"views\" /\u003e\n            \u003cEditButton basePath=\"/posts\" /\u003e\n        \u003c/Datagrid\u003e\n    \u003c/List\u003e\n);\n\nconst PostTitle = ({ record }) =\u003e {\n    return \u003cspan\u003ePost {record ? `\"${record.title}\"` : ''}\u003c/span\u003e;\n};\n\nexport const PostEdit = (props) =\u003e (\n    \u003cEdit title={\u003cPostTitle /\u003e} {...props}\u003e\n        \u003cSimpleForm\u003e\n            \u003cDisabledInput source=\"id\" /\u003e\n            \u003cTextInput source=\"title\" /\u003e\n            \u003cTextInput source=\"teaser\" options={{ multiLine: true }} /\u003e\n            \u003cLongTextInput source=\"body\" /\u003e\n            \u003cDateInput label=\"Publication date\" source=\"published_at\" /\u003e\n            \u003cTextInput source=\"average_note\" /\u003e\n            \u003cDisabledInput label=\"Nb views\" source=\"views\" /\u003e\n        \u003c/SimpleForm\u003e\n    \u003c/Edit\u003e\n);\n\nexport const PostCreate = (props) =\u003e (\n    \u003cCreate title=\"Create a Post\" {...props}\u003e\n        \u003cSimpleForm\u003e\n            \u003cTextInput source=\"title\" /\u003e\n            \u003cTextInput source=\"teaser\" options={{ multiLine: true }} /\u003e\n            \u003cLongTextInput source=\"body\" /\u003e\n            \u003cTextInput label=\"Publication date\" source=\"published_at\" /\u003e\n            \u003cTextInput source=\"average_note\" /\u003e\n        \u003c/SimpleForm\u003e\n    \u003c/Create\u003e\n);\n```\n\n## Does It Work With My REST API?\n\nYes.\n\nAdmin-on-rest uses an adapter approach, with a concept called *REST client*. Existing rest clients can be used as a blueprint to design your API, or you can write your own REST client to query an existing API. Writing a custom REST client is a matter of hours.\n\n![REST client architecture](https://marmelab.com/admin-on-rest/img/rest-client.png)\n\nSee the [REST clients documentation](https://marmelab.com/admin-on-rest/RestClients.html) for details.\n\n## Batteries Included But Removable\n\nAdmin-on-rest is designed as a library of loosely coupled React components built on top of [material-ui](http://www.material-ui.com/#/), in addition to controller functions implemented the Redux way. It is very easy to replace one part of admin-on-rest with your own, e.g. to use a custom datagrid, GraphQL instead of REST, or bootstrap instead of Material Design.\n\n## Run the example\n\nYou can run the example app by calling:\n\n```sh\nnpm install\nmake run\n```\n\nAnd then browse to [http://localhost:8080/](http://localhost:8080/).\nThe credentials are **login/password**\n\n## Contributing\n\nPull requests are welcome. You must follow the coding style of the existing files (based on [prettier](https://github.com/prettier/prettier)), and include unit tests and documentation. Be prepared for a thorough code review, and be patient for the merge - this is an open-source initiative.\n\nYou can run the tests (linting, unit and functional tests) by calling\n\n```sh\nmake test\n```\n\nIf you have coding standards problems, you can fix them automatically using `prettier` by calling\n\n```sh\nmake prettier\n```\n\nIf you want to contribute to the documentation, install jekyll, then call\n\n```sh\nmake doc\n```\n\nAnd then browse to [http://localhost:4000/](http://localhost:4000/)\n\n*Note*: if you have added a section with heading to the docs, you also have to add it to `docs/_layouts/default.html` (the links on the left) manually.\n\nIf you are using admin-on-rest as a dependency, and if you want to try and hack it, here is the advised process:\n\n```sh\n# in myapp\n# install admin-on-rest from GitHub in another directory\n$ cd ..\n$ git clone git@github.com:marmelab/admin-on-rest.git \u0026\u0026 cd admin-on-rest \u0026\u0026 make install\n# replace your node_modules/admin-on-rest by a symbolic link to the github checkout\n$ cd ../myapp\n$ npm link ../admin-on-rest\n# go back to the checkout, and replace the version of react by the one in your app\n$ cd ../admin-on-rest\n$ npm link ../myapp/node_modules/react\n$ make watch\n# in another terminal, go back to your app, and start it as usual\n$ cd ../myapp\n$ npm run\n```\n\n**Tip**: If you're on Windows and can't use `make`, try [this Gist](https://gist.github.com/mantis/bb5d9f7d492f86e94341816321500934).\n\n## License\n\nAdmin-on-rest is licensed under the [MIT Licence](https://github.com/marmelab/admin-on-rest/blob/master/LICENSE.md), sponsored and supported by [marmelab](http://marmelab.com).\n\n## Donate\n\nThis library is free to use, even for commercial purpose. If you want to give back, please talk about it, [help newcomers](https://stackoverflow.com/questions/tagged/admin-on-rest), or contribute code. But the best way to give back is to **donate to a charity**. We recommend [Doctors Without Borders](http://www.doctorswithoutborders.org/).\n","remote_repo_id":63226588,"sha":"1ff55709608f44cab326e13662c8894b9e5d88a3","size":8375}
,{"name":"vespa","owner":"vespa-engine","path":"README.md","readme":"\u003c!-- Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root. --\u003e\n# Vespa\nVespa is an engine for low-latency computation over large data sets.\nIt stores and indexes your data such that queries, selection and processing over the\ndata can be performed at serving time.\n\nThis README describes how to build and develop the Vespa engine. To get started, read the\n[quick start](http://docs.vespa.ai/documentation/vespa-quick-start.html), or find the full\ndocumentation at http://docs.vespa.ai/.\n\nCode licensed under the Apache 2.0 license. See [LICENSE](LICENSE) for terms.\n\nTravis-CI build status: [![Build Status](https://travis-ci.org/vespa-engine/vespa.svg?branch=master)](https://travis-ci.org/vespa-engine/vespa)\n\n## Get started developing\n\n### Setup build environment\nC++ building is supported on CentOS 7. The Java source can be built on any platform having Java 8 and Maven installed. \nWe recommend using the following environment: [Create C++ dev environment on CentOS using VirtualBox and Vagrant](vagrant/README.md).\nYou can also setup CentOS 7 natively and install the following build dependencies:\n\n    sudo yum-config-manager --add-repo https://copr.fedorainfracloud.org/coprs/g/vespa/vespa/repo/epel-7/group_vespa-vespa-epel-7.repo\n    sudo yum -y install epel-release centos-release-scl yum-utils\n    sudo yum -y install ccache \\\n        rpm-build\n    yum-builddep -y \u003cvespa-source\u003e/dist/vespa.spec\n\n### Build Java modules\n\n    export MAVEN_OPTS=\"-Xms128m -Xmx512m\"\n    source /opt/rh/rh-maven33/enable\n    bash bootstrap.sh java\n    mvn -T \u003cnum-threads\u003e install\n\n### Build C++ modules\nReplace `\u003cbuild-dir\u003e` with the name of the directory in which you'd like to build Vespa.\nReplace `\u003csource-dir\u003e` with the directory in which you've cloned/unpacked the source tree.\n\n    bash bootstrap-cpp.sh \u003csource-dir\u003e \u003cbuild-dir\u003e\n    cd \u003cbuild-dir\u003e\n    make -j \u003cnum-threads\u003e\n    ctest3 -j \u003cnum-threads\u003e\n\n### Create RPM packages\n    sh dist.sh VERSION \u0026\u0026 rpmbuild -ba ~/rpmbuild/SPECS/vespa-VERSION.spec\n\n\n## Run Vespa on a local machine\nA basic, single-node install is found in the \n[quick start](http://docs.vespa.ai/documentation/vespa-quick-start.html).\nFor multi-node and using Node Admin, read [node-admin/README.md](node-admin/README.md).\n\n## Write documentation\nUpdate user documentation at https://github.com/vespa-engine/documentation\n","remote_repo_id":60377070,"sha":"97c4bf69bc39d4146ac5befee1bf094277fccf2e","size":2402}
,{"name":"arangodb","owner":"arangodb","path":"README.md","readme":"![ArangoDB-Logo](https://docs.arangodb.com/assets/arangodb_logo_2016_inverted.png)\n\nArangoDB\n========\n\n1.4: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=1.4)](http://travis-ci.org/arangodb/arangodb)\n\n2.3: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=2.3)](http://travis-ci.org/arangodb/arangodb)\n2.4: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=2.4)](http://travis-ci.org/arangodb/arangodb)\n2.5: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=2.5)](http://travis-ci.org/arangodb/arangodb)\n2.6: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=2.6)](http://travis-ci.org/arangodb/arangodb)\n2.7: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=2.7)](http://travis-ci.org/arangodb/arangodb)\n2.8: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=2.8)](http://travis-ci.org/arangodb/arangodb)\n\n3.0: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=3.0)](http://travis-ci.org/arangodb/arangodb)\n3.1: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=3.1)](http://travis-ci.org/arangodb/arangodb)\n3.2: [![Build Status](https://secure.travis-ci.org/arangodb/arangodb.png?branch=3.2)](http://travis-ci.org/arangodb/arangodb)\n\nSlack: [![ArangoDB-Logo](https://slack.arangodb.com/badge.svg)](https://slack.arangodb.com)\n\nArangoDB is a multi-model, open-source database with flexible data models for\ndocuments, graphs, and key-values. Build high performance applications using a\nconvenient SQL-like query language or JavaScript extensions. Use ACID\ntransactions if you require them. Scale horizontally with a few mouse clicks.\n\nThe supported data models can be mixed in queries and allow ArangoDB to be the\naggregation point for your data.\n\nTo get started, try one of our 10 minutes [tutorials](https://www.arangodb.com/tutorials)\nin your favorite programming language or try one of our [ArangoDB Cookbook recipes](https://docs.arangodb.com/cookbook).\n\nFor the impatient: [download](https://www.arangodb.com/download) and install\nArangoDB. Start the server `arangod` and point your browser to `http://127.0.0.1:8529/`.\n\nKey Features in ArangoDB\n------------------------\n\n- **Multi-Model**: Documents, graphs and key-value pairs — model your data as\n  you see fit for your application.\n- **Joins**: Conveniently join what belongs together for flexible ad-hoc\n  querying, less data redundancy.\n- **Transactions**: Easy application development keeping your data consistent\n  and safe. No hassle in your client.\n\nHere is an AQL query that makes use of all those features:\n\n![AQL Query Example](https://docs.arangodb.com/assets/aql_query_with_traversal.png)\n\nJoins and transactions are key features for flexible, secure data designs,\nwidely used in relational databases but lacking in many NoSQL products. However,\nthere is no need to forgo them in ArangoDB. You decide how and when to use joins\nand strong consistency guarantees, without sacrificing performance and scalability. \n\nFurthermore, ArangoDB offers a JavaScript framework called [Foxx](https://www.arangodb.com/foxx)\nthat is executed in the database server with direct access to the data. Build your\nown data-centric microservices with a few lines of code:\n\nMicroservice Example\n\n![Microservice Example](https://www.arangodb.com/wp-content/uploads/2015/03/microservice.png)\n\nBy extending the HTTP API with user code written in JavaScript, ArangoDB can be\nturned into a strict schema-enforcing persistence engine.\n\nNext step, bundle your Foxx application as a [docker container](https://docs.arangodb.com/cookbook/Cloud/NodeJsDocker.html)\nand get it running in the cloud.\n\nOther features of ArangoDB include:\n\n- Use a **data-centric microservices** approach with ArangoDB Foxx and fuse your\n  application-logic and database together for maximal throughput\n- JavaScript for all: **no language zoo**, you can use one language from your\n  browser to your back-end\n- **Flexible data modeling**: model your data as combination of key-value pairs,\n  documents or graphs - perfect for social relations\n- Different **storage engines**: ArangoDB provides a storage engine for mostly\n  in-memory operations and an alternative storage engine based on RocksDB which \n  handle datasets that are much bigger than RAM.\n- **Powerful query language** (AQL) to retrieve and modify data \n- **Transactions**: run queries on multiple documents or collections with\n  optional transactional consistency and isolation\n- **Replication** and **Sharding**: set up the database in a master-slave\n  configuration or spread bigger datasets across multiple servers\n- Configurable **durability**: let the application decide if it needs more\n  durability or more performance\n- **Schema-free schemata** let you combine the space efficiency of MySQL with the\n  performance power of NoSQL\n- Free **index choice**: use the correct index for your problem, be it a skiplist \n  or a fulltext search\n- ArangoDB is **multi-threaded** - exploit the power of all your cores\n- It is **open source** (Apache License 2.0)\n\nFor more in-depth information read the [design goals of ArangoDB](https://www.arangodb.com/2012/03/07/avocadodbs-design-objectives)\n\n\nLatest Release\n--------------\n\nPackages for all supported platforms can be downloaded from [https://www.arangodb.com/download](https://www.arangodb.com/download/).\n\nPlease also check [what's new in ArangoDB](https://docs.arangodb.com/latest/Manual/ReleaseNotes/).\n\n\nMore Information\n----------------\n\nPlease check the [Installation Manual](https://docs.arangodb.com/latest/Manual/GettingStarted/Installing/)\nfor installation and compilation instructions.\n\nThe [User Manual](https://docs.arangodb.com/latest/Manual/GettingStarted/) has an\nintroductory chapter showing the basic operations of ArangoDB.\n\n\nStay in Contact\n---------------\n\nWe really appreciate feature requests and bug reports. Please use our Github\nissue tracker for reporting them:\n\n[https://github.com/arangodb/arangodb/issues](https://github.com/arangodb/arangodb/issues)\n\nYou can use our Google group for improvements, feature requests, comments:\n\n[https://www.arangodb.com/community](https://www.arangodb.com/community)\n\nStackOverflow is great for questions about AQL, usage scenarios etc.\n\n[https://stackoverflow.com/questions/tagged/arangodb](https://stackoverflow.com/questions/tagged/arangodb)\n\nTo chat with the community and the developers we offer a Slack chat:\n\n[https://slack.arangodb.com/](https://slack.arangodb.com/)\n","remote_repo_id":2649214,"sha":"721062b1988946f2a2dee840596d5c7c81c353cc","size":6602}
,{"name":"clam","owner":"proycon","path":"README.rst","readme":"=======================================================\nCLAM: Computational Linguistics Application Mediator\n=======================================================\n\n.. image:: https://travis-ci.org/proycon/clam.svg?branch=master\n    :target: https://travis-ci.org/proycon/clam\n\n.. image:: https://readthedocs.org/projects/clam/badge/?version=latest\n    :target: http://clam.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. image:: https://api.codacy.com/project/badge/grade/860767a6b995425bbb607fc852c418b7\n    :target: https://www.codacy.com/app/proycon/clam\n\n.. image:: https://zenodo.org/badge/doi/10.5281/zenodo.49081.svg\n   :target: http://dx.doi.org/10.5281/zenodo.49081\n\n.. image:: http://applejack.science.ru.nl/lamabadge.php/clam\n   :target: http://applejack.science.ru.nl/languagemachines/\n\n\n*by Maarten van Gompel, Centre for Language and Speech Technology, Radboud University Nijmegen*\n\n*Licensed under GPLv3*\n\t\t\n**Website:** https://proycon.github.io/clam \n**Source repository:** https://github.com/proycon/clam/\n\nCLAM allows you to quickly and transparently transform your Natural Language\nProcessing application into a RESTful webservice, with which both human\nend-users as well as automated clients can interact. CLAM takes a description\nof your system and wraps itself around the system, allowing end-users or\nautomated clients to upload input files to your application, start your\napplication with specific parameters of their choice, and download and view the\noutput of the application once it is completed.\n\nCLAM is set up in a universal fashion, requiring minimal effort on the part of\nthe service developer. Your actual NLP application is treated as a black box,\nof which only the parameters, input formats and output formats need to be\ndescribed. Your application itself needs not be network aware in any way, nor\naware of CLAM, and the handling and validation of input can be taken care of by\nCLAM.\n\nCLAM is entirely written in Python, runs on UNIX-derived systems, and is\navailable as open source under the GNU Public License (v3). It is set up in a\nmodular fashion, and offers an API, and as such is easily extendable. CLAM\ncommunicates in a transparent XML format, and using XSL transformation offers a\nfull web 2.0 web-interface for human end users. \n\nInstallation instruction can be found below. For full documentation see the\nmanual in ``docs/clam_manual.pdf`` , also accessible through the CLAM website\nat http://proycon.github.io/clam . It is recommended to read this prior to\nstarting with CLAM. \n\nAPI Documentation is available on http://clam.readthedocs.io\n\nInstallation\n----------------\n\nIt's discouraged to download the zip packages or tarballs\nfrom github, install CLAM from the `Python\nPackage Index \u003chttp://pypi.python.org/pypi/CLAM\u003e`_ or use git properly.\n\nInstallation On Linux \n~~~~~~~~~~~~~~~~~~~~~~~~\n\nInstallation from the Python Package Index using the  package manager *pip* it the recommended way to\nintall CLAM. This is the easiest method\nof installing CLAM, as it will automatically fetch and install any\ndependencies. We recommend to use a virtual environment (``virtualenv``) if you\nwant to install CLAM locally as a user, if you want to install globally,\nprepend the following commands with ``sudo``:\n\nCLAM can be installed from the Python Package Index using pip. Pip is usually\npart of the ``python3-pip`` package or similar. It downloads CLAM and all dependencies\nautomatically:::\n\n  $ pip3 install clam\n\nIf you already downloaded CLAM manually (from github), you can do::\n\n  $ python3 setup.py install\n\nIf pip3 is not yet installed on your system, install it using: \n on debian-based linux systems (including Ubuntu)::\n\n  $ apt-get install python3-pip \n  \non RPM-based linux systems::\n\n  $ yum install python3-pip\n\nNote that sudo/root access is needed to install globally. Ask your system administrator\nto install it if you do not own the system. Alternatively, you can install it locally in a Python virtual\nenvironment:\n\n  $ virtualenv --python=python3 clamenv\n\n  $ . clamenv/bin/activate\n\n  (clamenv)$ pip3 install clam\n\nIt is also possible to use Python 2.7 instead of Python 3, adapt the commands\nas necessary.\n\nCLAM also has some optional dependencies. For MySQL support, install\n``mysqlclient`` using pip. For `FoLiA \u003chttps://proycon.github.io/folia\u003e`_\nsupport, install ``FoLiA-Tools`` using pip.\n\nInstallation on Mac OS X\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nInstall a Python distribution such as `Anaconda \u003chttp://continuum.io/\u003e`_ and follow the Linux instructions above.\n\n\nInstallation on Windows\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCLAM does not support Windows, i.e. you can't run CLAM webservices on Windows.\nHowever, the CLAM Data API and client API will work, so clients connecting to\nCLAM webservices can run on Windows. Follow the same instructions as for Mac\nOS X.\n\nRunning a test webservice\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIf you installed CLAM using the above method, then you can launch a clam test\nwebservice using the development server as follows::\n\n  $ clamservice -H localhost -p 8080 clam.config.textstats\n \nNavigate your browser to http://localhost:8080 and verify everything works\n\nNote: It is important to regularly keep CLAM up to date as fixes and\nimprovements are implemented on a regular basis. Update CLAM using::\n\n  $ pip install -U clam\n\nor if you used easy_install::\n\n  $ easy_install -U clam\n\n\nInstalling a particular clam webservice for production use\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWhen installating a particular CLAM webservice on a new server, it is first\nnecessary to edit the service configuration file of the webservice and make\nsure all the paths in there are set correctly for the new server. Of interest\nis in particular the ROOT path, which is where user data will be stored, this\ndirectory must exist and be writable by the webserver.\n\nFor testing, the built-in development server can be used. Suppose the\nwebservice configuration is in /path/to/mywebservice/ and is called\nmywebservice.py, then the development server can be started as follows::\n\n  $ clamservice -P /path/to/mywebservice mywebservice\n\nFor production, however, it is strongly recommended to embed CLAM in Apache or\nnginx. This is the typically task of a system administrator, as certain skills are\nnecessary and assumed. All this is explained in detail in the CLAM\nManual, obtainable from https://proycon.github.io/clam/ . \n\n\n\n\n\n","remote_repo_id":760072,"sha":"5bb299c1d311ad3bbeb1c9db39a39e05c855c6f4","size":6444}
,{"name":"botodb","owner":"themalkolm","path":"README.md","readme":"# botodb [![Build Status](https://travis-ci.org/themalkolm/botodb.svg?branch=master)](https://travis-ci.org/themalkolm/botodb) [![Go Report Card](https://goreportcard.com/badge/github.com/themalkolm/botodb)](https://goreportcard.com/report/github.com/themalkolm/botodb)\n\nBoto database.\n","remote_repo_id":113098547,"sha":"8162eee89e14fc2623571b4b4120832227a6e3c6","size":286}
,{"name":"MixedRealityToolkit-Unity","owner":"Microsoft","path":"README.md","readme":"\u003cimg src=\"External/ReadMeImages/MRTK_Logo_Rev.png\"\u003e\n\n# What is MixedRealityToolkit-Unity?\nThe Mixed Reality Toolkit is a collection of scripts and components intended to accelerate development of applications targeting Microsoft HoloLens and Windows Mixed Reality headsets.\nThe project is aimed at reducing barriers to entry to create mixed reality applications and contribute back to the community as we all grow.\n\nMixedRealityToolkit-Unity uses code from the base [MixedRealityToolkit](https://github.com/Microsoft/MixedRealityToolkit) and makes it easier to consume in [Unity](https://unity3d.com/).\n\n[![Mixed Reality Academy](External/ReadMeImages/MixedRealityStack-Apps.png)](https://developer.microsoft.com/en-us/windows/mixed-reality/academy)\n[![View the Mixed Reality Companion Kit](External/ReadMeImages/MixedRealityStack-MRTK-Unity.png)](https://github.com/Microsoft/MixedRealityCompanionKit)\n[![Mixed Reality Toolkit GitHub Repo](External/ReadMeImages/MixedRealityStack-MRTK.png)](https://github.com/Microsoft/MixedRealityToolkit)\n[![Read the Mixed Reality Developer Guides](External/ReadMeImages/MixedRealityStack-UWP.png)](https://developer.microsoft.com/en-us/windows/mixed-reality)\n\n\u003e Learn more about [Windows Mixed Reality](https://www.microsoft.com/en-gb/windows/windows-mixed-reality) here.\n\n_Note: The latest release should work for both HoloLens and Windows Mixed Reality development._\n\n[github-rel]:                    https://github.com/Microsoft/MixedRealityToolkit-Unity/releases/latest\n[mrtk-version-badge]:            https://img.shields.io/github/tag/microsoft/MixedRealityToolkit-unity.svg?label=Latest%20Master%20Branch%20Release\u0026colorB=9acd32\n[![Github Release][mrtk-version-badge]][github-rel]\n\n[unity-download]:                 https://unity3d.com/unity/whats-new/unity-2017.2.1\n[unity-version-badge]:            https://img.shields.io/badge/Current%20Unity%20Editor%20Version-2017.2.1f1-green.svg\n[![Github Release][unity-version-badge]][unity-download]\n\n\u003e Check out the MRTK [Roadmap](/Roadmap.md) for Unity.\n\u003e\n\u003e Check out the updates from the [Fall Creators update](/FallCreatorsUpdate.md) for Windows Mixed Reality.\n\u003e\n\u003e Check out the [Breaking Changes](/BreakingChanges.md) from the previous release.\n\nLooking to upgrade your projects to Windows Mixed Reality? [Follow the Upgrade Guide](/UpgradeGuide.md).\n\n# Feature areas\nThe Mixed Reality Toolkit for Unity includes many API's to accelerate the development of Mixed Reality projects for both HoloLens and the newer Immersive Headsets (IHMD)\n\n| [![Input](External/ReadMeImages/MRTK170802_Short_03.png)](Assets/HoloToolkit/Input/README.md)  [Input](Assets/HoloToolkit/Input/README.md)                                               | [![Sharing](External/ReadMeImages/MRTK170802_Short_04.png)](Assets/HoloToolkit/Sharing/README.md) [Sharing](Assets/HoloToolkit/Sharing/README.md)   | [![Spatial Mapping](External/ReadMeImages/MRTK170802_Short_05.png)](Assets/HoloToolkit/SpatialMapping/README.md) [Spatial Mapping](Assets/HoloToolkit/SpatialMapping/README.md)| \n| :--- | :--- | :--- |\n| Scripts that leverage inputs such as gaze, gesture, voice and motion controllers. Includes the Mixed Reality camera prefabs. | Sharing library enables collaboration across multiple devices. | Scripts that allow applications to bring the real world into the digital using HoloLens. | \n| [![Spatial Sound](External/ReadMeImages/MRTK170802_Short_09.png)](Assets/HoloToolkit/SpatialSound/README.md) [Spatial Sound](Assets/HoloToolkit/SpatialSound/README.md) | [![UX Controls](External/ReadMeImages/MRTK170802_Short_10.png)](Assets/HoloToolkit/UX/README.md) [UX Controls](Assets/HoloToolkit/UX/README.md)| [![Utilities](External/ReadMeImages/MRTK170802_Short_11.png)](Assets/HoloToolkit/Utilities/README.md) [Utilities](Assets/HoloToolkit/Utilities/README.md) | \n| Scripts to help plug spatial audio into your application. | Building blocks for creating good UX in your application like common controls. | Common helpers and tools that you can leverage in your application. |\n| [![Spatial Understanding](External/ReadMeImages/MRTK170802_Short_06.png)](Assets/HoloToolkit/SpatialUnderstanding/README.md) [Spatial Understanding](Assets/HoloToolkit/SpatialUnderstanding/README.md)| [![Build](External/ReadMeImages/MRTK170802_Short_12.png)](Assets/HoloToolkit/BuildAndDeploy/README.md) [Build](Assets/HoloToolkit/BuildAndDeploy/README.md)| [![Boundary](External/ReadMeImages/MRTK170802_Short_07.png)](Assets/HoloToolkit/Boundary/README.md) [Boundary](Assets/HoloToolkit/Boundary/README.md)                       |\n| Tailor experiences based on room semantics like couch, wall etc.                                                                                  | Build and deploy automation window for Unity Editor.                                                        | Scripts that help with rendering the floor and boundaries for Immersive Devices.\n\n# Required Software\n| [![Windows 10 Creators Update](External/ReadMeImages/MRTK170802_Short_17.png)](https://www.microsoft.com/software-download/windows10) [Windows 10 FCU](https://www.microsoft.com/software-download/windows10)| [![Unity](External/ReadMeImages/MRTK170802_Short_18.png)](https://unity3d.com/get-unity/download/archive) [Unity 3D](https://unity3d.com/get-unity/download/archive)| [![Visual Studio 2017](External/ReadMeImages/MRTK170802_Short_19.png)](http://dev.windows.com/downloads) [Visual Studio 2017](http://dev.windows.com/downloads)| [![Simulator (optional)](External/ReadMeImages/MRTK170802_Short_20.png)](https://go.microsoft.com/fwlink/?linkid=852626) [Simulator (optional)](https://go.microsoft.com/fwlink/?linkid=852626)|\n| :--- | :--- | :--- | :--- |\n| To develop apps for mixed reality headsets, you need the Windows 10 Fall Creators Update | The Unity 3D engine provides support for building mixed reality projects in Windows 10 | Visual Studio is used for code editing, deploying and building UWP app packages | The Emulators allow you test your app without the device in a simulated environment |\n\n# Getting started with MRTK\nTo get up and going as quickly as possible, here are some guides to help you get started building Mixed Reality Projects\n\n| [![Quick Start Guide](External/ReadMeImages/MRTK170802c_Short_22.png)](GettingStarted.md) [Quick start](GettingStarted.md) | [![Contributing to this project](External/ReadMeImages/MRTK170802c_Short_23.png)](CONTRIBUTING.md) [Contributing to this project](CONTRIBUTING.md) | [![Contributing to this project](External/ReadMeImages/MRTK170802c_Short_24.png)](FallCreatorsUpdate.md) [Fall Creators Update](FallCreatorsUpdate.md) |\n|:--- | :--- | :--- |\n| Please go over the [Getting started guide](GettingStarted.md) to learn more about getting off the ground quickly. | Please go over the [Contributing guidelines](CONTRIBUTING.md) to learn more about the process and thinking. | Check out the recent updates for Windows Mixed reality in the [Fall Creators update](/FallCreatorsUpdate.md) |\n\n# Examples and QuickStart scenes\nThe MRTK includes many great samples and starter scenes to demonstrate the uses of the MRTK API, these include:\n\n| [![Motion Controller tests](External/ReadMeImages/MRTK_MotionControllerTest.jpg)](/Assets/HoloToolkit-Examples) [Motion Controller tests](/Assets/HoloToolkit-Examples) | [![Input manager tests](External/ReadMeImages/MRTK_InputManagerTest.jpg)](/Assets/HoloToolkit-Examples) [Input manager tests](/Assets/HoloToolkit-Examples) | [![Grab Mechanics demo](External/ReadMeImages/MRTK_GrabMechanics.jpg)](/Assets/HoloToolkit-Examples/MotionControllers-GrabMechanics) [Grab Mechanics demo](/Assets/HoloToolkit-Examples/MotionControllers-GrabMechanics) |\n|:--- | :--- | :--- |\n| Motion controller test scene demonstrating controller input events | Several gaze interaction demos such as popups, buttons and more |   Examples of direct manipulation with Motion Controllers (IHMD Only) |\n| [![Interactable Objects](External/ReadMeImages/MRTK_InteractableObject.jpg)](/Assets/HoloToolkit-Examples/UX/Readme/README_InteractableObjectExample.md) [Interactable Objects](/Assets/HoloToolkit-Examples/UX/Readme/README_InteractableObjectExample.md) | [![Object Collection](External/ReadMeImages/MRTK_ObjectCollection.jpg)](/Assets/HoloToolkit-Examples/UX/Readme/README_ObjectCollection.md) [Object Collection](/Assets/HoloToolkit-Examples/UX/Readme/README_ObjectCollection.md) | [![App Bar and Bounding Box](External/ReadMeImages/MRTK_AppBar_BoundingBox.jpg)](/Assets/HoloToolkit-Examples/UX/Scenes) App Bar and Bounding Box |\n| Example of modular and extensible interactable objects with visual states, including Holographic button  | Object collection helps you lay out an array of objects in a three-dimensional shape | **[Coming Soon]** Standard UI for move/rotate/scale 3D objects |\n| [![Keyboard input sample](External/ReadMeImages/MRTK_Keyboard.jpg)](/Assets/HoloToolkit-Examples) [Keyboard input sample](/Assets/HoloToolkit-Examples) | [![Interactive button demos](External/ReadMeImages/MRTK_InteractiveButtons.jpg)](/Assets/HoloToolkit-Examples/UX/Readme/README_InteractiveButtonComponents.md) [Interactive button demos](/Assets/HoloToolkit-Examples/UX/Readme/README_InteractiveButtonComponents.md) | [![Scene occulsion demo](External/ReadMeImages/MRTK_OcclusionExample.jpg)](/Assets/HoloToolkit-Examples) [Scene occlusion demo](/Assets/HoloToolkit-Examples) |\n| A sample virtual keyboard, similar to system keyboard in Windows Mixed Reality shell  | Example UI buttons and controls for use in Mixed Reality | Scene construction demo on how to make occluded windows |\n\nCheck out the [Examples](/Assets/HoloToolkit-Examples) folder for more details.\n\n**External\\How To** docs folder is meant to help everyone with migrating forward or any simple doubts they might have about the process.\nPlease feel free to grow all these sections. We can't wait to see your additions!\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). \nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Useful resources on Microsoft Windows Dev Center\n| ![Academy](External/ReadMeImages/icon_academy.png) [Academy](https://developer.microsoft.com/en-us/windows/mixed-reality/academy)| ![Design](External/ReadMeImages/icon_design.png) [Design](https://developer.microsoft.com/en-us/windows/mixed-reality/design)| ![Development](External/ReadMeImages/icon_development.png) [Development](https://developer.microsoft.com/en-us/windows/mixed-reality/development)| ![Community)](External/ReadMeImages/icon_community.png) [Community](https://developer.microsoft.com/en-us/windows/mixed-reality/community)|\n| :--------------------- | :----------------- | :------------------ | :------------------------ |\n| See code examples. Do a coding tutorial. Watch guest lectures.          | Get design guides. Build user interface. Learn interactions and input.     | Get development guides. Learn the technology. Understand the science.       | Join open source projects. Ask questions on forums. Attend events and meetups. |\n","remote_repo_id":50605426,"sha":"c482836155d6b29dda5fb6165edd41b7ba28c94c","size":11245}
,{"name":"mega_GIT","owner":"RinatB2017","path":"README.md","readme":"mega_GIT\nвсе в одном месте\n","remote_repo_id":97226298,"sha":"778a54cc6100cc3a56aa7cfe347774e1f31e47e2","size":41}
,{"name":"nuxt.js","owner":"nuxt","path":"README.md","readme":"\u003cp align=\"center\"\u003e\u003cimg align=\"center\" src=\"http://imgur.com/V4LtoII.png\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://travis-ci.org/nuxt/nuxt.js\"\u003e\u003cimg src=\"https://img.shields.io/travis/nuxt/nuxt.js/master.svg\" alt=\"Build Status\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://ci.appveyor.com/project/Atinux/nuxt-js\"\u003e\u003cimg src=\"https://ci.appveyor.com/api/projects/status/gwab06obc6srx9g4?svg=true\" alt=\"Windows Build Status\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://codecov.io/gh/nuxt/nuxt.js\"\u003e\u003cimg src=\"https://img.shields.io/codecov/c/github/nuxt/nuxt.js/master.svg\" alt=\"Coverage Status\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://www.npmjs.com/package/nuxt\"\u003e\u003cimg src=\"https://img.shields.io/npm/dm/nuxt.svg\" alt=\"Downloads\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://www.npmjs.com/package/nuxt\"\u003e\u003cimg src=\"https://img.shields.io/npm/v/nuxt.svg\" alt=\"Version\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://www.npmjs.com/package/nuxt\"\u003e\u003cimg src=\"https://img.shields.io/npm/l/nuxt.svg\" alt=\"License\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://gitter.im/nuxt/nuxt.js\"\u003e\u003cimg src=\"https://img.shields.io/badge/GITTER-join%20chat-green.svg\" alt=\"Gitter\"\u003e\u003c/a\u003e\n \u003c/p\u003e\n \u003cp align=\"center\"\u003e\n  \u003ca href=\"#backers\" alt=\"sponsors on Open Collective\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backers/badge.svg\" /\u003e\u003c/a\u003e\n  \u003ca href=\"#sponsors\" alt=\"Sponsors on Open Collective\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsors/badge.svg\" /\u003e\u003c/a\u003e\n  \u003ca href=\"https://opencollective.com/nuxtjs\"\u003e\u003cimg src=\"https://img.shields.io/badge/Support%20us-Open%20Collective-41B883.svg\" alt=\"Support us\"\u003e\u003c/a\u003e\n\n\u003c/p\u003e\n\n\u003e Vue.js Meta Framework to create complex, fast \u0026 universal web application *quickly*.\n\n## Links\n\n- 📘 Documentation: [https://nuxtjs.org](https://nuxtjs.org)\n- 🎬 Video: [1 minute demo](https://www.youtube.com/watch?v=kmf-p-pTi40)\n- 🐦 Twitter: [@nuxt_js](https://twitter.com/nuxt_js)\n- 👥 [Nuxt.js Community](https://github.com/nuxt-community)\n- 📦 [Nuxt.js Modules](https://github.com/nuxt-community/modules)\n- 👉 [Play with Nuxt.js online](https://glitch.com/edit/#!/nuxt-hello-world)\n\n## Features\n\n- Automatic transpilation and bundling (with webpack and babel)\n- Hot code reloading\n- Server-side rendering OR Single Page App OR Static Generated, you choose :fire:\n- Static file serving. `./static/` is mapped to `/`\n- Configurable with a `nuxt.config.js` file\n- Custom layouts with the `layouts/` directory\n- Middleware\n- Code splitting for every `pages/`\n\nLearn more at [nuxtjs.org](https://nuxtjs.org).\n\n## Sponsors\n\nBecome a sponsor and get your logo on our README on Github with a link to your site. [[Become a sponsor](https://opencollective.com/nuxtjs#sponsor)]\n\n\u003cp\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/0/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/0/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/1/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/1/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/2/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/2/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/3/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/3/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/4/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/4/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/5/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/5/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/6/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/6/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/7/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/7/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/8/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/8/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/9/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/9/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/10/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/10/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/11/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/11/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/12/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/12/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/13/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/13/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/14/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/14/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/15/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/15/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/16/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/16/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/17/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/17/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/18/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/18/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/19/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/19/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/20/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/20/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/21/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/21/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/22/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/22/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/23/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/23/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/24/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/24/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/25/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/25/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/26/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/26/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/27/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/27/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/28/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/28/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/sponsor/29/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/sponsor/29/avatar.svg\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\n## Backers\n\nSupport us with a monthly donation and help us continue our activities. [[Become a backer](https://opencollective.com/nuxtjs#backer)]\n\n\u003cp\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/0/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/0/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/1/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/1/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/2/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/2/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/3/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/3/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/4/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/4/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/5/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/5/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/6/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/6/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/7/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/7/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/8/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/8/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/9/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/9/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/10/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/10/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/11/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/11/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/12/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/12/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/13/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/13/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/14/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/14/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/15/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/15/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/16/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/16/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/17/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/17/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/18/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/18/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/19/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/19/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/20/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/20/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/21/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/21/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/22/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/22/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/23/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/23/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/24/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/24/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/25/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/25/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/26/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/26/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/27/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/27/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/28/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/28/avatar.svg\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opencollective.com/nuxtjs/backer/29/website\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://opencollective.com/nuxtjs/backer/29/avatar.svg\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\n## Getting started\n\n```\n$ npm install nuxt --save\n```\n\nAdd a script to your package.json like this:\n\n```json\n{\n  \"scripts\": {\n    \"start\": \"nuxt\"\n  }\n}\n```\n\nAfter that, the file-system is the main API. Every .vue file becomes a route that gets automatically processed and rendered.\n\nPopulate `./pages/index.vue` inside your project:\n\n```html\n\u003ctemplate\u003e\n  \u003ch1\u003eHello {{ name }}!\u003c/h1\u003e\n\u003c/template\u003e\n\n\u003cscript\u003e\nexport default {\n  data: () =\u003e {\n    return { name: 'world' }\n  }\n}\n\u003c/script\u003e\n```\n\nAnd then run:\n```bash\nnpm start\n```\n\nGo to [http://localhost:3000](http://localhost:3000)\n\n## Templates\n\n:point_right: We recommend to start directly with our cli [create-nuxt-app](https://github.com/nuxt-community/create-nuxt-app) for the lastest updates.\n\nOr you can start by using one of our starter templates:\n- [starter](https://github.com/nuxt-community/starter-template): Basic Nuxt.js project template\n- [express](https://github.com/nuxt-community/express-template): Nuxt.js + Express\n- [koa](https://github.com/nuxt-community/koa-template): Nuxt.js + Koa\n- [adonuxt](https://github.com/nuxt-community/adonuxt-template): Nuxt.js + AdonisJS\n- [micro](https://github.com/nuxt-community/micro-template): Nuxt.js + Micro\n- [nuxtent](https://github.com/nuxt-community/nuxtent-template): Nuxt.js + Nuxtent module for content heavy sites\n\n## Using nuxt.js programmatically\n\n```js\nconst { Nuxt, Builder } = require('nuxt')\n\n// Import and set nuxt.js options\nlet config = require('./nuxt.config.js')\nconfig.dev = (process.env.NODE_ENV !== 'production')\n\nlet nuxt = new Nuxt(config)\n\n// Start build process (only in development)\nif (config.dev) {\n  new Builder(nuxt).build()\n}\n\n// You can use nuxt.render(req, res) or nuxt.renderRoute(route, context)\n```\n\nLearn more: https://nuxtjs.org/api/nuxt\n\n## Using nuxt.js as a middleware\n\nYou might want to use your own server with you configurations, your API and everything awesome your created with. That's why you can use nuxt.js as a middleware. It's recommended to use it at the end of your middleware since it will handle the rendering of your web application and won't call next().\n\n```js\napp.use(nuxt.render)\n```\n\nLearn more: https://nuxtjs.org/api/nuxt-render\n\n## Render a specific route\n\nThis is mostly used for `nuxt generate` and test purposes but you might find another utility!\n\n```js\nnuxt.renderRoute('/about', context)\n.then(function ({ html, error }) {\n  // You can check error to know if your app displayed the error page for this route\n  // Useful to set the correct status code if an error appended:\n  if (error) {\n    return res.status(error.statusCode || 500).send(html)\n  }\n  res.send(html)\n})\n.catch(function (error) {\n  // And error appended while rendering the route\n})\n```\n\nLearn more: https://nuxtjs.org/api/nuxt-render-route\n\n## Examples\n\nPlease take a look at https://nuxtjs.org/examples or directly in https://github.com/nuxt/nuxt.js/tree/dev/examples.\n\n## Production deployment\n\nTo deploy, instead of running nuxt, you probably want to build ahead of time. Therefore, building and starting are separate commands:\n\n```bash\nnuxt build\nnuxt start\n```\n\nFor example, to deploy with [`now`](https://zeit.co/now) a `package.json` like follows is recommended:\n```json\n{\n  \"name\": \"my-app\",\n  \"dependencies\": {\n    \"nuxt\": \"latest\"\n  },\n  \"scripts\": {\n    \"dev\": \"nuxt\",\n    \"build\": \"nuxt build\",\n    \"start\": \"nuxt start\"\n  }\n}\n```\nThen run `now` and enjoy!\n\nNote: we recommend putting `.nuxt` in `.npmignore` or `.gitignore`.\n\n## Core team\n\n| [Sebastien Chopin](https://github.com/Atinux) | [Alexandre Chopin](https://github.com/alexchopin) | [Pooya Parsa](https://github.com/pi0) | [Clark Du](https://github.com/clarkdo) |\n| --- | --- | --- | --- |\n| [![Atinux](https://avatars1.githubusercontent.com/u/904724?s=150\u0026v=4)](https://github.com/Atinux) | [![alexchopin](https://avatars1.githubusercontent.com/u/4084277?s=150\u0026v=4)](https://github.com/alexchopin) | [![pi0](https://avatars1.githubusercontent.com/u/5158436?s=150\u0026v=4)](https://github.com/pi0) | [![clarkdo](https://avatars3.githubusercontent.com/u/4312154?s=150\u0026v=4)](https://github.com/clarkdo) |\n\n## Contributors\n\nThank you to all our [contributors](https://github.com/nuxt/nuxt.js/graphs/contributors)!\n\n## Contributing\n\nPlease see our [CONTRIBUTING.md](./CONTRIBUTING.md)\n\n\n## Roadmap\n\nhttps://trello.com/b/lgy93IOl/nuxtjs-10\n","remote_repo_id":71995937,"sha":"99a2157791841f0a3beb49efc77f2e7e2f46bd05","size":17588}
,{"name":"pupil","owner":"pupil-labs","path":"README.md","readme":"# Pupil\nOpen source eye tracking software platform that started as a thesis project at MIT. Pupil is a project in active, community driven development. Pupil mobile eye tracking hardware is accessible, hackable, and affordable. The software is open source and written in `Python` and `C++` when speed is an issue.\n\nOur vision is to create tools for a diverse group of people interested in learning about eye tracking and conducting their eye tracking projects.\n\nChat with us on [Discord](https://pupil-labs.com/chat \"#pupil channel on DiscordApp\").\n\n## Project Website\nFor an intro to the Pupil mobile eye tracking platform have a look at the [Pupil Labs Website](http://pupil-labs.com \"Pupil Labs\").\n\n## Getting Started\n\u003ctable\u003e\n\u003ctr\u003e\n\t\u003ctd align=\"center\" width=\"20%\"\u003e\u003cimg width=\"100\" src=\"https://github.com/pupil-labs/pupil/wiki/media/icons/Pupil_Logo_wiki-01.png\" /\u003e\u003c/td\u003e\n\t\u003ctd  align=\"center\" width=\"20%\"\u003e\u003cimg width=\"100\" src=\"https://github.com/pupil-labs/pupil/wiki/media/icons/Pupil_Logo_wiki-03.png\" /\u003e\u003c/td\u003e\n\t\u003ctd align=\"center\" width=\"20%\"\u003e\u003cimg width=\"100\" src=\"https://github.com/pupil-labs/pupil/wiki/media/icons/Pupil_Logo_wiki-04.png\" /\u003e\u003c/td\u003e\n\t\u003ctd align=\"center\" width=\"20%\"\u003e\u003cimg width=\"100\" src=\"https://github.com/pupil-labs/pupil/wiki/media/icons/Pupil_Logo_wiki-05.png\" /\u003e\u003c/td\u003e\n\t\u003ctd align=\"center\" width=\"20%\"\u003e\u003cimg width=\"100\" src=\"https://github.com/pupil-labs/pupil/wiki/media/icons/Pupil_Logo_wiki-02.png\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\t\u003ctd\u003e\u003ca href=\"http://docs.pupil-labs.com/#pupil-hardware\" title=\"Pupil Labs Docs - Pupil Hardware\"\u003ePupil Hardware\u003c/a\u003e\u003c/td\u003e\n\t\u003ctd\u003e\u003ca href=\"http://docs.pupil-labs.com/#getting-started\" title=\"Pupil Labs Docs - Getting Started With Pupil\"\u003eGetting Started\u003c/a\u003e\u003c/td\u003e\n\t\u003ctd\u003e\u003ca href=\"http://docs.pupil-labs.com/#user-docs\" title=\"Pupil Labs Docs - User Docs\"\u003eUser Docs\u003c/a\u003e\u003c/td\u003e\n\t\u003ctd\u003e\u003ca href=\"http://docs.pupil-labs.com/#developer-docs\" title=\"Pupil Labs Docs - Dev Docs\"\u003eDeveloper Docs\u003c/a\u003e\u003c/td\u003e\n\t\u003ctd\u003e\u003ca href=\"http://docs.pupil-labs.com/#community\" title=\"Pupil Labs Docs - Community\"\u003eCommunity\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\t\u003ctd valign=\"top\"\u003eGet and setup your Pupil eye tracking hardware\u003c/td\u003e\n\t\u003ctd valign=\"top\"\u003eGet up and running and learn the basic Pupil workflow\u003c/td\u003e\n\t\u003ctd valign=\"top\"\u003eLearn more about Pupil Capture and Pupil Player software settings and workflows here\u003c/td\u003e\n\t\u003ctd valign=\"top\"\u003eWant to write code? Read the developer docs here\u003c/td\u003e\n\t\u003ctd valign=\"top\"\u003eConnect with the Pupil community. Chat with us on \u003ca href=\"https://pupil-labs.com/chat\" title=\"#pupil channel on DiscordApp\"\u003eDiscord\u003c/a\u003e\u003c/td\u003e\t\t\n\u003c/tr\u003e\n\u003c/table\u003e\n\n\n## License\nAll source code written by Pupil Labs is open for use in compliance with the [GNU Lesser General Public License (LGPL v3.0)](http://www.gnu.org/licenses/lgpl-3.0.en.html). We want you to change and improve the code -- make a fork! Make sure to share your work with the community! See the docs for more info on the [license](http://docs.pupil-labs.com/#license \"License\"). For support and custom licencing [contact us!](https://docs.pupil-labs.com/#email \"email us\")\n","remote_repo_id":12173486,"sha":"1ef78b8669a6ea845404ea63e4e5c10305d2e813","size":3028}
,{"name":"sbt","owner":"sbt","path":"README.md","readme":"[![Gitter Chat](https://badges.gitter.im/sbt/sbt.svg)](https://gitter.im/sbt/sbt)\n\n  [sbt/sbt-zero-seven]: https://github.com/sbt/sbt-zero-seven\n  [CONTRIBUTING]: CONTRIBUTING.md\n  [Setup]: http://www.scala-sbt.org/release/docs/Getting-Started/Setup\n  [FAQ]: http://www.scala-sbt.org/release/docs/Faq.html\n  [sbt-dev]: https://groups.google.com/d/forum/sbt-dev\n  [searching]: http://stackoverflow.com/tags/sbt\n  [asking]: https://stackoverflow.com/questions/ask?tags=sbt\n  [LICENSE]: LICENSE\n  [sbt/io]: https://github.com/sbt/io\n  [sbt/util]: https://github.com/sbt/util\n  [sbt/librarymanagement]: https://github.com/sbt/librarymanagement\n  [sbt/zinc]: https://github.com/sbt/zinc\n  [sbt/sbt]: https://github.com/sbt/sbt\n\nsbt\n===\n\nsbt is a build tool for Scala, Java, and more.\n\nFor general documentation, see http://www.scala-sbt.org/.\n\nsbt 1.0.x\n---------\n\nThis is the 1.0.x series of sbt. The source code of sbt is split across\nseveral Github repositories, including this one.\n\n- [sbt/io][sbt/io] hosts `sbt.io` module.\n- [sbt/util][sbt/util] hosts a collection of internally used modules.\n- [sbt/librarymanagement][sbt/librarymanagement] hosts `sbt.librarymanagement` module that wraps Ivy.\n- [sbt/zinc][sbt/zinc] hosts Zinc, an incremental compiler for Scala.\n- [sbt/sbt][sbt/sbt], this repository hosts modules that implements the build tool.\n\n### Other links\n\n * [Setup]: Describes getting started with the latest binary release.\n * [FAQ]: Explains how to get help and more.\n * [sbt/sbt-zero-seven]: hosts sbt 0.7.7 and earlier versions\n\nIssues and Pull Requests\n------------------------\n\nPlease read [CONTRIBUTING] carefully before opening a GitHub Issue.\n\nThe short version: try [searching] or [asking] on StackOverflow.\n\nlicense\n-------\n\nSee [LICENSE].\n","remote_repo_id":279553,"sha":"dab1a3eee33782cf0a290b6e333ab8e6d814ff9d","size":1764}
,{"name":"go-ethereum","owner":"ethereum","path":"README.md","readme":"## Go Ethereum\n\nOfficial golang implementation of the Ethereum protocol.\n\n[![API Reference](\nhttps://camo.githubusercontent.com/915b7be44ada53c290eb157634330494ebe3e30a/68747470733a2f2f676f646f632e6f72672f6769746875622e636f6d2f676f6c616e672f6764646f3f7374617475732e737667\n)](https://godoc.org/github.com/ethereum/go-ethereum)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/ethereum/go-ethereum?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge)\n\nAutomated builds are available for stable releases and the unstable master branch.\nBinary archives are published at https://geth.ethereum.org/downloads/.\n\n## Building the source\n\nFor prerequisites and detailed build instructions please read the\n[Installation Instructions](https://github.com/ethereum/go-ethereum/wiki/Building-Ethereum)\non the wiki.\n\nBuilding geth requires both a Go (version 1.7 or later) and a C compiler.\nYou can install them using your favourite package manager.\nOnce the dependencies are installed, run\n\n    make geth\n\nor, to build the full suite of utilities:\n\n    make all\n\n## Executables\n\nThe go-ethereum project comes with several wrappers/executables found in the `cmd` directory.\n\n| Command    | Description |\n|:----------:|-------------|\n| **`geth`** | Our main Ethereum CLI client. It is the entry point into the Ethereum network (main-, test- or private net), capable of running as a full node (default) archive node (retaining all historical state) or a light node (retrieving data live). It can be used by other processes as a gateway into the Ethereum network via JSON RPC endpoints exposed on top of HTTP, WebSocket and/or IPC transports. `geth --help` and the [CLI Wiki page](https://github.com/ethereum/go-ethereum/wiki/Command-Line-Options) for command line options. |\n| `abigen` | Source code generator to convert Ethereum contract definitions into easy to use, compile-time type-safe Go packages. It operates on plain [Ethereum contract ABIs](https://github.com/ethereum/wiki/wiki/Ethereum-Contract-ABI) with expanded functionality if the contract bytecode is also available. However it also accepts Solidity source files, making development much more streamlined. Please see our [Native DApps](https://github.com/ethereum/go-ethereum/wiki/Native-DApps:-Go-bindings-to-Ethereum-contracts) wiki page for details. |\n| `bootnode` | Stripped down version of our Ethereum client implementation that only takes part in the network node discovery protocol, but does not run any of the higher level application protocols. It can be used as a lightweight bootstrap node to aid in finding peers in private networks. |\n| `evm` | Developer utility version of the EVM (Ethereum Virtual Machine) that is capable of running bytecode snippets within a configurable environment and execution mode. Its purpose is to allow isolated, fine-grained debugging of EVM opcodes (e.g. `evm --code 60ff60ff --debug`). |\n| `gethrpctest` | Developer utility tool to support our [ethereum/rpc-test](https://github.com/ethereum/rpc-tests) test suite which validates baseline conformity to the [Ethereum JSON RPC](https://github.com/ethereum/wiki/wiki/JSON-RPC) specs. Please see the [test suite's readme](https://github.com/ethereum/rpc-tests/blob/master/README.md) for details. |\n| `rlpdump` | Developer utility tool to convert binary RLP ([Recursive Length Prefix](https://github.com/ethereum/wiki/wiki/RLP)) dumps (data encoding used by the Ethereum protocol both network as well as consensus wise) to user friendlier hierarchical representation (e.g. `rlpdump --hex CE0183FFFFFFC4C304050583616263`). |\n| `swarm`    | swarm daemon and tools. This is the entrypoint for the swarm network. `swarm --help` for command line options and subcommands. See https://swarm-guide.readthedocs.io for swarm documentation. |\n| `puppeth`    | a CLI wizard that aids in creating a new Ethereum network. |\n\n## Running geth\n\nGoing through all the possible command line flags is out of scope here (please consult our\n[CLI Wiki page](https://github.com/ethereum/go-ethereum/wiki/Command-Line-Options)), but we've\nenumerated a few common parameter combos to get you up to speed quickly on how you can run your\nown Geth instance.\n\n### Full node on the main Ethereum network\n\nBy far the most common scenario is people wanting to simply interact with the Ethereum network:\ncreate accounts; transfer funds; deploy and interact with contracts. For this particular use-case\nthe user doesn't care about years-old historical data, so we can fast-sync quickly to the current\nstate of the network. To do so:\n\n```\n$ geth --fast --cache=512 console\n```\n\nThis command will:\n\n * Start geth in fast sync mode (`--fast`), causing it to download more data in exchange for avoiding\n   processing the entire history of the Ethereum network, which is very CPU intensive.\n * Bump the memory allowance of the database to 512MB (`--cache=512`), which can help significantly in\n   sync times especially for HDD users. This flag is optional and you can set it as high or as low as\n   you'd like, though we'd recommend the 512MB - 2GB range.\n * Start up Geth's built-in interactive [JavaScript console](https://github.com/ethereum/go-ethereum/wiki/JavaScript-Console),\n   (via the trailing `console` subcommand) through which you can invoke all official [`web3` methods](https://github.com/ethereum/wiki/wiki/JavaScript-API)\n   as well as Geth's own [management APIs](https://github.com/ethereum/go-ethereum/wiki/Management-APIs).\n   This too is optional and if you leave it out you can always attach to an already running Geth instance\n   with `geth attach`.\n\n### Full node on the Ethereum test network\n\nTransitioning towards developers, if you'd like to play around with creating Ethereum contracts, you\nalmost certainly would like to do that without any real money involved until you get the hang of the\nentire system. In other words, instead of attaching to the main network, you want to join the **test**\nnetwork with your node, which is fully equivalent to the main network, but with play-Ether only.\n\n```\n$ geth --testnet --fast --cache=512 console\n```\n\nThe `--fast`, `--cache` flags and `console` subcommand have the exact same meaning as above and they\nare equally useful on the testnet too. Please see above for their explanations if you've skipped to\nhere.\n\nSpecifying the `--testnet` flag however will reconfigure your Geth instance a bit:\n\n * Instead of using the default data directory (`~/.ethereum` on Linux for example), Geth will nest\n   itself one level deeper into a `testnet` subfolder (`~/.ethereum/testnet` on Linux). Note, on OSX\n   and Linux this also means that attaching to a running testnet node requires the use of a custom\n   endpoint since `geth attach` will try to attach to a production node endpoint by default. E.g.\n   `geth attach \u003cdatadir\u003e/testnet/geth.ipc`. Windows users are not affected by this.\n * Instead of connecting the main Ethereum network, the client will connect to the test network,\n   which uses different P2P bootnodes, different network IDs and genesis states.\n   \n*Note: Although there are some internal protective measures to prevent transactions from crossing\nover between the main network and test network, you should make sure to always use separate accounts\nfor play-money and real-money. Unless you manually move accounts, Geth will by default correctly\nseparate the two networks and will not make any accounts available between them.*\n\n### Configuration\n\nAs an alternative to passing the numerous flags to the `geth` binary, you can also pass a configuration file via:\n\n```\n$ geth --config /path/to/your_config.toml\n```\n\nTo get an idea how the file should look like you can use the `dumpconfig` subcommand to export your existing configuration:\n\n```\n$ geth --your-favourite-flags dumpconfig\n```\n\n*Note: This works only with geth v1.6.0 and above.*\n\n#### Docker quick start\n\nOne of the quickest ways to get Ethereum up and running on your machine is by using Docker:\n\n```\ndocker run -d --name ethereum-node -v /Users/alice/ethereum:/root \\\n           -p 8545:8545 -p 30303:30303 \\\n           ethereum/client-go --fast --cache=512\n```\n\nThis will start geth in fast sync mode with a DB memory allowance of 512MB just as the above command does.  It will also create a persistent volume in your home directory for saving your blockchain as well as map the default ports. There is also an `alpine` tag available for a slim version of the image.\n\nDo not forget `--rpcaddr 0.0.0.0`, if you want to access RPC from other containers and/or hosts. By default, `geth` binds to the local interface and RPC endpoints is not accessible from the outside.\n\n### Programatically interfacing Geth nodes\n\nAs a developer, sooner rather than later you'll want to start interacting with Geth and the Ethereum\nnetwork via your own programs and not manually through the console. To aid this, Geth has built in\nsupport for a JSON-RPC based APIs ([standard APIs](https://github.com/ethereum/wiki/wiki/JSON-RPC) and\n[Geth specific APIs](https://github.com/ethereum/go-ethereum/wiki/Management-APIs)). These can be\nexposed via HTTP, WebSockets and IPC (unix sockets on unix based platforms, and named pipes on Windows).\n\nThe IPC interface is enabled by default and exposes all the APIs supported by Geth, whereas the HTTP\nand WS interfaces need to manually be enabled and only expose a subset of APIs due to security reasons.\nThese can be turned on/off and configured as you'd expect.\n\nHTTP based JSON-RPC API options:\n\n  * `--rpc` Enable the HTTP-RPC server\n  * `--rpcaddr` HTTP-RPC server listening interface (default: \"localhost\")\n  * `--rpcport` HTTP-RPC server listening port (default: 8545)\n  * `--rpcapi` API's offered over the HTTP-RPC interface (default: \"eth,net,web3\")\n  * `--rpccorsdomain` Comma separated list of domains from which to accept cross origin requests (browser enforced)\n  * `--ws` Enable the WS-RPC server\n  * `--wsaddr` WS-RPC server listening interface (default: \"localhost\")\n  * `--wsport` WS-RPC server listening port (default: 8546)\n  * `--wsapi` API's offered over the WS-RPC interface (default: \"eth,net,web3\")\n  * `--wsorigins` Origins from which to accept websockets requests\n  * `--ipcdisable` Disable the IPC-RPC server\n  * `--ipcapi` API's offered over the IPC-RPC interface (default: \"admin,debug,eth,miner,net,personal,shh,txpool,web3\")\n  * `--ipcpath` Filename for IPC socket/pipe within the datadir (explicit paths escape it)\n\nYou'll need to use your own programming environments' capabilities (libraries, tools, etc) to connect\nvia HTTP, WS or IPC to a Geth node configured with the above flags and you'll need to speak [JSON-RPC](http://www.jsonrpc.org/specification)\non all transports. You can reuse the same connection for multiple requests!\n\n**Note: Please understand the security implications of opening up an HTTP/WS based transport before\ndoing so! Hackers on the internet are actively trying to subvert Ethereum nodes with exposed APIs!\nFurther, all browser tabs can access locally running webservers, so malicious webpages could try to\nsubvert locally available APIs!**\n\n### Operating a private network\n\nMaintaining your own private network is more involved as a lot of configurations taken for granted in\nthe official networks need to be manually set up.\n\n#### Defining the private genesis state\n\nFirst, you'll need to create the genesis state of your networks, which all nodes need to be aware of\nand agree upon. This consists of a small JSON file (e.g. call it `genesis.json`):\n\n```json\n{\n  \"config\": {\n        \"chainId\": 0,\n        \"homesteadBlock\": 0,\n        \"eip155Block\": 0,\n        \"eip158Block\": 0\n    },\n  \"alloc\"      : {},\n  \"coinbase\"   : \"0x0000000000000000000000000000000000000000\",\n  \"difficulty\" : \"0x20000\",\n  \"extraData\"  : \"\",\n  \"gasLimit\"   : \"0x2fefd8\",\n  \"nonce\"      : \"0x0000000000000042\",\n  \"mixhash\"    : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"timestamp\"  : \"0x00\"\n}\n```\n\nThe above fields should be fine for most purposes, although we'd recommend changing the `nonce` to\nsome random value so you prevent unknown remote nodes from being able to connect to you. If you'd\nlike to pre-fund some accounts for easier testing, you can populate the `alloc` field with account\nconfigs:\n\n```json\n\"alloc\": {\n  \"0x0000000000000000000000000000000000000001\": {\"balance\": \"111111111\"},\n  \"0x0000000000000000000000000000000000000002\": {\"balance\": \"222222222\"}\n}\n```\n\nWith the genesis state defined in the above JSON file, you'll need to initialize **every** Geth node\nwith it prior to starting it up to ensure all blockchain parameters are correctly set:\n\n```\n$ geth init path/to/genesis.json\n```\n\n#### Creating the rendezvous point\n\nWith all nodes that you want to run initialized to the desired genesis state, you'll need to start a\nbootstrap node that others can use to find each other in your network and/or over the internet. The\nclean way is to configure and run a dedicated bootnode:\n\n```\n$ bootnode --genkey=boot.key\n$ bootnode --nodekey=boot.key\n```\n\nWith the bootnode online, it will display an [`enode` URL](https://github.com/ethereum/wiki/wiki/enode-url-format)\nthat other nodes can use to connect to it and exchange peer information. Make sure to replace the\ndisplayed IP address information (most probably `[::]`) with your externally accessible IP to get the\nactual `enode` URL.\n\n*Note: You could also use a full fledged Geth node as a bootnode, but it's the less recommended way.*\n\n#### Starting up your member nodes\n\nWith the bootnode operational and externally reachable (you can try `telnet \u003cip\u003e \u003cport\u003e` to ensure\nit's indeed reachable), start every subsequent Geth node pointed to the bootnode for peer discovery\nvia the `--bootnodes` flag. It will probably also be desirable to keep the data directory of your\nprivate network separated, so do also specify a custom `--datadir` flag.\n\n```\n$ geth --datadir=path/to/custom/data/folder --bootnodes=\u003cbootnode-enode-url-from-above\u003e\n```\n\n*Note: Since your network will be completely cut off from the main and test networks, you'll also\nneed to configure a miner to process transactions and create new blocks for you.*\n\n#### Running a private miner\n\nMining on the public Ethereum network is a complex task as it's only feasible using GPUs, requiring\nan OpenCL or CUDA enabled `ethminer` instance. For information on such a setup, please consult the\n[EtherMining subreddit](https://www.reddit.com/r/EtherMining/) and the [Genoil miner](https://github.com/Genoil/cpp-ethereum)\nrepository.\n\nIn a private network setting however, a single CPU miner instance is more than enough for practical\npurposes as it can produce a stable stream of blocks at the correct intervals without needing heavy\nresources (consider running on a single thread, no need for multiple ones either). To start a Geth\ninstance for mining, run it with all your usual flags, extended by:\n\n```\n$ geth \u003cusual-flags\u003e --mine --minerthreads=1 --etherbase=0x0000000000000000000000000000000000000000\n```\n\nWhich will start mining blocks and transactions on a single CPU thread, crediting all proceedings to\nthe account specified by `--etherbase`. You can further tune the mining by changing the default gas\nlimit blocks converge to (`--targetgaslimit`) and the price transactions are accepted at (`--gasprice`).\n\n## Contribution\n\nThank you for considering to help out with the source code! We welcome contributions from\nanyone on the internet, and are grateful for even the smallest of fixes!\n\nIf you'd like to contribute to go-ethereum, please fork, fix, commit and send a pull request\nfor the maintainers to review and merge into the main code base. If you wish to submit more\ncomplex changes though, please check up with the core devs first on [our gitter channel](https://gitter.im/ethereum/go-ethereum)\nto ensure those changes are in line with the general philosophy of the project and/or get some\nearly feedback which can make both your efforts much lighter as well as our review and merge\nprocedures quick and simple.\n\nPlease make sure your contributions adhere to our coding guidelines:\n\n * Code must adhere to the official Go [formatting](https://golang.org/doc/effective_go.html#formatting) guidelines (i.e. uses [gofmt](https://golang.org/cmd/gofmt/)).\n * Code must be documented adhering to the official Go [commentary](https://golang.org/doc/effective_go.html#commentary) guidelines.\n * Pull requests need to be based on and opened against the `master` branch.\n * Commit messages should be prefixed with the package(s) they modify.\n   * E.g. \"eth, rpc: make trace configs optional\"\n\nPlease see the [Developers' Guide](https://github.com/ethereum/go-ethereum/wiki/Developers'-Guide)\nfor more details on configuring your environment, managing project dependencies and testing procedures.\n\n## License\n\nThe go-ethereum library (i.e. all code outside of the `cmd` directory) is licensed under the\n[GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html), also\nincluded in our repository in the `COPYING.LESSER` file.\n\nThe go-ethereum binaries (i.e. all code inside of the `cmd` directory) is licensed under the\n[GNU General Public License v3.0](https://www.gnu.org/licenses/gpl-3.0.en.html), also included\nin our repository in the `COPYING` file.\n","remote_repo_id":15452919,"sha":"61e36afec4bc4c99303fb2eb4a3f311de30010c1","size":17367}
,{"name":"kong","owner":"Kong","path":"README.md","readme":"[![][kong-logo]][kong-url]\n\n[![Build Status][badge-travis-image]][badge-travis-url]\n\nKong is a cloud-native, fast, scalable, and distributed Microservice\nAbstraction Layer *(also known as an API Gateway, API Middleware or in some\ncases Service Mesh)*.\n\nBacked by the battle-tested **NGINX** with a focus on high performance, Kong\nwas made available as an open-source platform in 2015. Under active\ndevelopment, Kong is used in production at thousands of organizations from\nstartups, Global 5000 and Government organizations.\n\n[Installation](https://getkong.org/install) |\n[Documentation](https://getkong.org/docs) |\n[Forum](https://discuss.konghq.com) |\n[Blog](https://konghq.com/blog) |\nIRC (freenode): [#kong](http://webchat.freenode.net/?channels=kong)\n\n## Summary\n\n- [**Why Kong?**](#why-kong)\n- [**Features**](#features)\n- [**Benchmarks**](#benchmarks)\n- [**Distributions**](#distributions)\n- [**Development**](#development)\n- [**Enterprise Support \u0026 Demo**](#enterprise-support--demo)\n- [**License**](#license)\n\n## Why Kong?\n\nIf you are building for web, mobile or IoT (Internet of Things) you will likely\nend up needing common functionality to run your actual software. Kong can\nhelp by acting as a gateway (or a sidecar) for microservices requests while\nproviding load balancing, logging, authentication, rate-limiting and more\nthrough plugins.\n\n[![][kong-benefits]][kong-url]\n\n## Features\n\n- **Cloud-Native**: Platform agnostic, Kong can run from bare metal to\n  Kubernetes.\n- **Dynamic Load Balancing**: Load balance traffic across multiple backend\n  services.\n- **Service Discovery**: Resolve SRV records in third-party DNS resolvers like\n  Consul.\n- **Serverless**: Invoke and secure AWS Lambda or OpenWhisk fuctions directly\n  from Kong.\n- **WebSockets**: Communicate to your upstream services via WebSockets.\n- **OAuth2.0**: Easily add OAuth2.0 authentication to your APIs.\n- **Logging**: Log requests and responses to your system over HTTP, TCP, UDP,\n  or to disk.\n- **Security**: ACL, Bot detection, whitelist/blacklist IPs, etc...\n- **Syslog**: Logging to System log.\n- **SSL**: Setup a Specific SSL Certificate for an underlying service or API.\n- **Monitoring**: Live monitoring provides key load and performance server\n  metrics.\n- **Authentications**: HMAC, JWT, Basic, and more.\n- **Rate-limiting**: Block and throttle requests based on many variables.\n- **Transformations**: Add, remove, or manipulate HTTP requests and responses.\n- **Caching**: Cache and serve responses at the proxy layer.\n- **CLI**: Control your Kong cluster from the command line.\n- **REST API**: Kong can be operated with its RESTful API for maximum\n  flexibility.\n- **Geo-Replicated**: Configs are always up-to-date across different regions.\n- **Failure Detection \u0026 Recovery**: Kong is unaffected if one of your Cassandra\n  nodes goes down.\n- **Clustering**: All Kong nodes auto-join the cluster keeping their config\n  updated across nodes.\n- **Scalability**: Distributed by nature, Kong scales horizontally by simply\n  adding nodes.\n- **Performance**: Kong handles load with ease by scaling and using NGINX at\n  the core.\n- **Plugins**: Extendable architecture for adding functionality to Kong and\n  APIs.\n\nFor more info about plugins, you can check out the [Plugins\nHub](https://konghq.com/plugins/).\n\n## Benchmarks\n\nWe've load tested Kong and Cassandra on AWS; you can see our [benchmark report\nhere](https://getkong.org/about/benchmark/).\n\n## Distributions\n\nKong comes in many shapes. While this repository contains its core's source\ncode, other repos are also under active development:\n\n- [Kong Docker](https://github.com/Kong/docker-kong): A Dockerfile for\n  running Kong in Docker.\n- [Kong Packages](https://github.com/Kong/kong/releases): Pre-built packages\n  for Debian, Red Hat, and OS X distributions (shipped with each release).\n- [Kong Vagrant](https://github.com/Kong/kong-vagrant): A Vagrantfile for\n  provisioning a development ready environment for Kong.\n- [Kong Homebrew](https://github.com/Kong/homebrew-kong): Homebrew Formula\n  for Kong.\n- [Kong CloudFormation](https://github.com/Kong/kong-dist-cloudformation):\n  Kong in a 1-click deployment for AWS EC2\n- [Kong AWS AMI](https://aws.amazon.com/marketplace/pp/B014GHERVU): Kong AMI on\n  the AWS Marketplace.\n- [Kong on Microsoft Azure](https://github.com/Kong/kong-dist-azure): Run Kong\n  using Azure Resource Manager.\n- [Kong on Heroku](https://github.com/heroku/heroku-kong): Deploy Kong on\n  Heroku in one click.\n- [Kong and Instaclustr](https://www.instaclustr.com/solutions/managed-cassandra-for-kong/): Let\n  Instaclustr manage your Cassandra cluster.\n\n\n## Development\n\nIf you are planning on developing on Kong, you'll need a development\ninstallation. The `next` branch holds the latest unreleased source code.\n\nYou can read more about writing your own plugins in the [Plugin Development\nGuide](https://getkong.org/docs/latest/plugin-development/), or browse an\nonline version of Kong's source code documentation in the [Public Lua API\nReference](https://getkong.org/docs/latest/lua-reference/).\n\n#### Vagrant\n\nYou can use a Vagrant box running Kong and Postgres that you can find at\n[Mashape/kong-vagrant](https://github.com/Kong/kong-vagrant).\n\n#### Source Install\n\nKong mostly is an OpenResty application made of Lua source files, but also\nrequires some additional third-party dependencies. We recommend installing\nthose by following the source install instructions at\nhttps://getkong.org/install/source/.\n\nInstead of following the second step (Install Kong), clone this repository\nand install the latest Lua sources instead of the currently released ones:\n\n```shell\n$ git clone https://github.com/Kong/kong\n$ cd kong/\n\n# you might want to switch to the development branch. See CONTRIBUTING.md\n$ git checkout next\n\n# install the Lua sources\n$ luarocks make\n```\n\n#### Running for development\n\nCheck out the [development section](https://github.com/Kong/kong/blob/next/kong.conf.default#L244)\nof the default configuration file for properties to tweak in order to ease\nthe development process for Kong.\n\nModifying the [`lua_package_path`](https://github.com/openresty/lua-nginx-module#lua_package_path)\nand [`lua_package_cpath`](https://github.com/openresty/lua-nginx-module#lua_package_cpath)\ndirectives will allow Kong to find your custom plugin's source code wherever it\nmight be in your system.\n\n#### Tests\n\nInstall the development dependencies ([busted], [luacheck]) with:\n\n```shell\n$ make dev\n```\n\nKong relies on three test suites using the [busted] testing library:\n\n* Unit tests\n* Integration tests, which require Postgres and Cassandra to be up and running\n* Plugins tests, which require Postgres to be running\n\nThe first can simply be run after installing busted and running:\n\n```\n$ make test\n```\n\nHowever, the integration and plugins tests will spawn a Kong instance and\nperform their tests against it. As so, consult/edit the `spec/kong_tests.conf`\nconfiguration file to make your test instance point to your Postgres/Cassandra\nservers, depending on your needs.\n\nYou can run the integration tests (assuming **both** Postgres and Cassandra are\nrunning and configured according to `spec/kong_tests.conf`) with:\n\n```\n$ make test-integration\n```\n\nAnd the plugins tests with:\n\n```\n$ make test-plugins\n```\n\nFinally, all suites can be run at once by simply using:\n\n```\n$ make test-all\n```\n\nConsult the [run_tests.sh](.ci/run_tests.sh) script for a more advanced example\nusage of the tests suites and the Makefile.\n\nFinally, a very useful tool in Lua development (as with many other dynamic\nlanguages) is performing static linting of your code. You can use [luacheck]\n\\(installed with `make dev`\\) for this:\n\n```\n$ make lint\n```\n\n#### Makefile\n\nWhen developing, you can use the `Makefile` for doing the following operations:\n\n| Name               | Description                                            |\n| ------------------:| -------------------------------------------------------|\n| `install`          | Install the Kong luarock globally                      |\n| `dev`              | Install development dependencies                       |\n| `lint`             | Lint Lua files in `kong/` and `spec/`                  |\n| `test`             | Run the unit tests suite                               |\n| `test-integration` | Run the integration tests suite                        |\n| `test-plugins`     | Run the plugins test suite                             |\n| `test-all`         | Run all unit + integration + plugins tests at once     |\n\n## Enterprise Support \u0026 Demo\n\nIf you are working in a large organization you should learn more about [Kong\nEnterprise](https://konghq.com/kong-enterprise-edition/).\n\n## License\n\n```\nCopyright 2016-2018 Kong Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n[kong-url]: https://konghq.com/\n[kong-logo]: https://cl.ly/030V1u02090Q/unnamed.png\n[kong-benefits]: https://cl.ly/002i2Z432A1s/Image%202017-10-16%20at%2012.30.08%20AM.png\n[google-groups-url]: https://groups.google.com/forum/#!forum/konglayer\n[badge-travis-url]: https://travis-ci.org/Kong/kong/branches\n[badge-travis-image]: https://travis-ci.org/Kong/kong.svg?branch=master\n\n[busted]: https://github.com/Olivine-Labs/busted\n[luacheck]: https://github.com/mpeterv/luacheck\n[Luarocks]: https://luarocks.org\n\n","remote_repo_id":26783295,"sha":"0a26b8d2c1529840181314126395aab6bdd9a1ff","size":9774}
,{"name":"Qix","owner":"ty4z2008","path":"README.md","readme":"\n\n## About Me\n\nWeiBo: [@廖君_Jun](http://weibo.com/ty4z2008)\n\nTwitter: [@廖君](https://twitter.com/ty4z2008)\n\nE-Mail: ty4z2008@gmail.com\n\nScale System Channel: [https://t.me/scalesystem](https://t.me/scalesystem)\n\n**NOTE** \n\nThere may be some incorrect information in the article. I hope i can correct error with you.  you can contact me with Email or PR\n\n## Pull Request welcome:blush:\n\n## My translation\n\n### node-mysql document translate\n\nnode-mysql offcial document:https://github.com/felixge/node-mysql/blob/master/Readme.md\n\nnode-mysql Chinese document:https://github.com/ty4z2008/Qix/blob/master/node.md\n\n## Machine Learning And deep learning Resources\n\nChapter 1:https://github.com/ty4z2008/Qix/blob/master/dl.md\n\nChapter 2:https://github.com/ty4z2008/Qix/blob/master/dl2.md\n\n## Golang learning resources\n\nLink ：https://github.com/ty4z2008/Qix/blob/master/golang.md\n\n\n## PostgreSQL database resources\n\nLink  ：https://github.com/ty4z2008/Qix/blob/master/pg.md\n\n## Distributed system resource\n\nLinks ：https://github.com/ty4z2008/Qix/blob/master/ds.md\n\n## Additional notes\n\nDear friends. In order to respect to  the efforts   of authorship. In the reading process, when you find that resource the authorship is incorrect I also want you to[Submit feedback](https://github.com/ty4z2008/Qix/issues)。Thanks buddy！\n\n## License\n\n[MIT License](https://github.com/ty4z2008/Qix/blob/master/License.md)\n","remote_repo_id":18962767,"sha":"ce349f1850ae3849024180e3aec4008a08f5bafd","size":1413}
,{"name":"vuestic-admin","owner":"epicmaxco","path":"README.md","readme":"# Vuestic Admin Dashboard\n\nResponsive admin dashboard template built with [Vue.js](https://vuejs.org) and [Bootstrap 4](https://v4-alpha.getbootstrap.com). Developed by [Epicmax](http://epicmax.co). Designed by [Vasili Savitski](https://xxsavitski.myportfolio.com/)\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"http://vuestic.epicmax.co\" target=\"_blank\"\u003e\n    \u003cimg src=\"http://i.imgur.com/pMuJVVc.png\" align=\"center\" width=\"888px\"/\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n## Demo\nCheck it out [live](http://vuestic.epicmax.co)!\n\n## Prerequisites:\n\n- [Node.js](https://nodejs.org/en/) (\u003e=4.x or 6.x preferred)\n- npm version 3+ and [Git](https://git-scm.com/).\n- [vuestic-installer](https://github.com/epicmaxco/vuestic-installer) `npm install vuestic-installer -g`.\n\n## Browser Support\n* Latest Chrome, Firefox, Safari, Edge\n* IE11 is not supported\n\n## Installation\n\n``` bash\n# create new project via vuestic-installer command.\n$ vuestic myproject\n\nor\n\n# clone the repo\n$ git clone https://github.com/epicmaxco/vuestic-admin.git myproject\n\n# go into app's directory and install dependencies:\n$ cd myproject\n$ npm install\n\n# serve with hot reload at localhost:8080.\n$ npm run dev\n\n# build for production with minification\n$ npm run build\n\n# build for production and view the bundle analyzer report.\n$ npm run build --report\n```\n\n## Documentation\n\nGot stuck? Check out our [documentation](https://github.com/epicmaxco/vuestic-admin/wiki) 🤓\n\n## Features\n* Vue.js\n* Bootstrap 4\n* Webpack\n* Responsive layout\n* Charts (Chart.js)\n* Maps (Google, Leaflet, amMap)\n* Progress bars\n* Material forms with beautiful validation\n* 4 Form wizard types\n* Static tables and datatables\n* Login/signup pages templates\n* and many more!\n\n## How can I support developers?\n- Star our GitHub repo :star:\n- Create pull requests, submit bugs, suggest new features or documentation updates :wrench:\n- Follow us on [Twitter](https://twitter.com/epicmaxco) :feet:\n- Like our page on [Facebook](https://www.facebook.com/epicmaxco) :thumbsup:\n\n## Can I hire you guys?\nYes!  Visit [our homepage](http://epicmax.co/) or simply leave us a message to [hello@epicmax.co](mailto:hello@epicmax.co). We will be happy to work with you!\n\n## License\n[MIT](https://github.com/epicmaxco/vuestic-admin/blob/master/LICENSE) license.\n","remote_repo_id":98883508,"sha":"0659c927599bfccbb67a7c1e15f40c922193b824","size":2248}
,{"name":"skydive","owner":"skydive-project","path":"README.md","readme":"[![Build Status](https://ci.skydive.network/job/skydive-create-binaries/badge/icon)](https://ci.skydive.network/job/skydive-create-binaries/)\n[![Go Report Card](https://goreportcard.com/badge/github.com/skydive-project/skydive)](https://goreportcard.com/report/github.com/skydive-project/skydive)\n[![Coverage Status](https://coveralls.io/repos/github/skydive-project/skydive/badge.svg?branch=master)](https://coveralls.io/github/skydive-project/skydive?branch=master)\n\n# Skydive\n\nSkydive is an open source real-time network topology and protocols analyzer.\nIt aims to provide a comprehensive way of understanding what is happening in\nthe network infrastructure.\n\nSkydive agents collect topology informations and flows and forward them to a\ncentral agent for further analysis. All the informations are stored in an\nElasticsearch database.\n\nSkydive is SDN-agnostic but provides SDN drivers in order to enhance the\ntopology and flows informations.\n\n![](https://github.com/skydive-project/skydive.network/raw/images/overview.gif)\n\n## Key features\n\n* Captures network topology and flows\n* Full history of network topology and flows\n* Distributed\n* Ability to follow a flow along a path in the topology\n* Supports VMs and Containers infrastructure\n* Unified query language for topology and flows (Gremlin)\n* Web and command line interfaces\n* REST API\n* Easy to deploy (standalone executable)\n* Connectors to OpenStack, Docker, OpenContrail\n\n## Quick start\n\n### Docker Compose\n\nTo quick set up a working environment, [Docker Compose](https://docs.docker.com/compose/)\ncan be used to automatically start an Elasticsearch container, a Skydive analyzer\ncontainer and a Skydive agent container.\n\n```console\ncurl -o docker-compose.yml https://raw.githubusercontent.com/skydive-project/skydive/master/contrib/docker/docker-compose.yml\ndocker-compose up\n```\n\nOpen a browser to http://localhost:8082 to access the analyzer Web UI.\n\nYou can also use the Skydive [command line client](https://skydive-project.github.io/skydive/getting-started/client/) with:\n```console\ndocker run --net=host -ti skydive/skydive client query \"g.V()\"\n```\n\n### All-in-one\n\nYou can also download the latest release and use the `all-in-one` mode which\nwill start an Agent and an Analyzer at once.\n\n```console\nsudo skydive allinone [-c skydive.yml]\n```\n\n## Documentation\n\nSkydive documentation can be found here:\n\n* http://skydive-project.github.io/skydive\n\n## Contributing\n\nYour contributions are more than welcome. Please check\nhttps://github.com/skydive-project/skydive/blob/master/CONTRIBUTING.md\nto know about the process.\n\n## Contact\n\n* IRC: #skydive-project on irc.freenode.net\n* Mailing list: https://www.redhat.com/mailman/listinfo/skydive-dev\n\n## License\n\nThis software is licensed under the Apache License, Version 2.0 (the\n\"License\"); you may not use this software except in compliance with the\nLicense.\nYou may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n","remote_repo_id":44610195,"sha":"e9d13122cf4dd1603e54e78667ad8c52e6f4f56c","size":3266}
,{"name":"opsdroid","owner":"opsdroid","path":"README.md","readme":"![opsdroid](https://github.com/opsdroid/style-guidelines/raw/master/logos/logo-wide-light.png)\n\n[![Build Status](https://travis-ci.org/opsdroid/opsdroid.svg?branch=release)](https://travis-ci.org/opsdroid/opsdroid) [![codecov](https://codecov.io/gh/opsdroid/opsdroid/branch/master/graph/badge.svg)](https://codecov.io/gh/opsdroid/opsdroid) [![Updates](https://pyup.io/repos/github/opsdroid/opsdroid/shield.svg)](https://pyup.io/repos/github/opsdroid/opsdroid/) [![Dependency Status](https://dependencyci.com/github/opsdroid/opsdroid/badge)](https://dependencyci.com/github/opsdroid/opsdroid)\n[![Docker Image](https://img.shields.io/badge/docker-ready-blue.svg)](https://hub.docker.com/r/opsdroid/opsdroid/) [![Docker Layers](https://images.microbadger.com/badges/image/opsdroid/opsdroid.svg)](https://microbadger.com/#/images/opsdroid/opsdroid) [![Documentation Status](https://readthedocs.org/projects/opsdroid/badge/?version=stable)](http://opsdroid.readthedocs.io/en/stable/?badge=stable) [![Gitter Badge](https://badges.gitter.im/opsdroid.png)](https://gitter.im/opsdroid)\n\nAn open source chat bot framework written in python. It is designed to be extendable, scalable and simple.\n\nThis application is designed to take messages from chat services and execute python functions (skills) based on their contents. Those functions can be anything you like, from simple conversational responses to running complex tasks. The true power of this project is to act as a glue library to bring the multitude of natural language APIs, chat services and third party APIs together.\n\n## ChatOps\n_\"ChatOps is an operational paradigm where work that is already happening in the background today is brought into a common chatroom. By doing this, you are unifying the communication about what work should get done with actual history of the work being done.\"_ - [StackStorm](https://docs.stackstorm.com/chatops/chatops.html)\n\nIn the new frontier of DevOps it is becoming more and more popular to interact with your automation tools via an instant messenger. opsdroid is a framework to make creating and extending your ChatOps workflows powerful but simple.\n\n## Why use opsdroid?\n\n * It's open source\n * Simple to modify and extend\n * Add your own skills in under 10 lines of python\n * Easy to install\n * Designed with Docker in mind for simple deployment\n * Configurable with a single YAML file\n * Can connect to multiple chat services simultaneously\n * No coding necessary if using the official modules\n\n## Quick start\n\n```\npip3 install opsdroid\nopsdroid\n```\n\n## Installation\n\nCheck out the [Getting Started](https://www.youtube.com/watch?v=7wyIi_cpodE\u0026list=PLViQCHlMbEq5nZL6VNrUxu--Of1uCpflq) video series on YouTube.\n\n### Docker\n\n```bash\n# Pull the container image\ndocker pull opsdroid/opsdroid:latest\n\n# Run the container\ndocker run --rm -v /path/to/configuration.yaml:/etc/opsdroid/configuration.yaml:ro opsdroid/opsdroid:latest\n```\n\n### Ubuntu 16.04 LTS\n\n```bash\n# Update apt-get\nsudo apt-get update\n\n# Install pip for python3 and locales\nsudo apt-get install python3-pip language-pack-en git\n\n# Enure pip is up-to-date\npip3 install --upgrade pip\n\n# Install opsdroid\nsudo pip3 install opsdroid\n\n# Run opsdroid\nopsdroid\n```\n\n\n## Contributing\n\n[Stickers for contributors!](https://medium.com/opsdroid/stickers-for-contributors-a0a1f9c30ec1)\n\nContributing to the opsdroid ecosystem is strongly encouraged and every little bit counts! You can do this by creating modules to be used by opsdroid or by contributing to the project itself.\n\nAll contributors to the project, including the project founder [jacobtomlinson](https://github.com/jacobtomlinson), contribute using the following process:\n\n * Fork the main project to your own account\n * Work on your changes on a feature branch\n * Create a pull request back to the main project\n * Tests and test coverage will be checked automatically\n * A project maintainer will review and merge the pull request\n\nFor more information see the [contribution documentation](http://opsdroid.readthedocs.io/en/latest/contributing/).\n\nDo you need help? Do you want to chat? [Join our Gitter channel](https://gitter.im/opsdroid/)\n\n-------\n\n_\\* databases are optional, however bot memory will not persist between different connectors or system reboots without one_\n","remote_repo_id":64034523,"sha":"9569aeae44f63774bf4874ce5cc0eb3050b20a85","size":4285}
,{"name":"prometheus","owner":"prometheus","path":"README.md","readme":"# Prometheus [![Build Status](https://travis-ci.org/prometheus/prometheus.svg)][travis]\n\n[![CircleCI](https://circleci.com/gh/prometheus/prometheus/tree/master.svg?style=shield)][circleci]\n[![Docker Repository on Quay](https://quay.io/repository/prometheus/prometheus/status)][quay]\n[![Docker Pulls](https://img.shields.io/docker/pulls/prom/prometheus.svg?maxAge=604800)][hub]\n[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus/prometheus)](https://goreportcard.com/report/github.com/prometheus/prometheus)\n\nVisit [prometheus.io](https://prometheus.io) for the full documentation,\nexamples and guides.\n\nPrometheus, a [Cloud Native Computing Foundation](https://cncf.io/) project, is a systems and service monitoring system. It collects metrics\nfrom configured targets at given intervals, evaluates rule expressions,\ndisplays the results, and can trigger alerts if some condition is observed\nto be true.\n\nPrometheus' main distinguishing features as compared to other monitoring systems are:\n\n- a **multi-dimensional** data model (timeseries defined by metric name and set of key/value dimensions)\n- a **flexible query language** to leverage this dimensionality\n- no dependency on distributed storage; **single server nodes are autonomous**\n- timeseries collection happens via a **pull model** over HTTP\n- **pushing timeseries** is supported via an intermediary gateway\n- targets are discovered via **service discovery** or **static configuration**\n- multiple modes of **graphing and dashboarding support**\n- support for hierarchical and horizontal **federation**\n\n## Architecture overview\n\n![](https://cdn.rawgit.com/prometheus/prometheus/c34257d069c630685da35bcef084632ffd5d6209/documentation/images/architecture.svg)\n\n## Install\n\nThere are various ways of installing Prometheus.\n\n### Precompiled binaries\n\nPrecompiled binaries for released versions are available in the\n[*download* section](https://prometheus.io/download/)\non [prometheus.io](https://prometheus.io). Using the latest production release binary\nis the recommended way of installing Prometheus.\nSee the [Installing](https://prometheus.io/docs/introduction/install/)\nchapter in the documentation for all the details.\n\nDebian packages [are available](https://packages.debian.org/sid/net/prometheus).\n\n### Docker images\n\nDocker images are available on [Quay.io](https://quay.io/repository/prometheus/prometheus).\n\nYou can launch a Prometheus container for trying it out with\n\n    $ docker run --name prometheus -d -p 127.0.0.1:9090:9090 quay.io/prometheus/prometheus\n\nPrometheus will now be reachable at http://localhost:9090/.\n\n### Building from source\n\nTo build Prometheus from the source code yourself you need to have a working\nGo environment with [version 1.9 or greater installed](http://golang.org/doc/install).\n\nYou can directly use the `go` tool to download and install the `prometheus`\nand `promtool` binaries into your `GOPATH`:\n\n    $ go get github.com/prometheus/prometheus/cmd/...\n    $ prometheus --config.file=your_config.yml\n\nYou can also clone the repository yourself and build using `make`:\n\n    $ mkdir -p $GOPATH/src/github.com/prometheus\n    $ cd $GOPATH/src/github.com/prometheus\n    $ git clone https://github.com/prometheus/prometheus.git\n    $ cd prometheus\n    $ make build\n    $ ./prometheus --config.file=your_config.yml\n\nThe Makefile provides several targets:\n\n  * *build*: build the `prometheus` and `promtool` binaries\n  * *test*: run the tests\n  * *test-short*: run the short tests\n  * *format*: format the source code\n  * *vet*: check the source code for common errors\n  * *assets*: rebuild the static assets\n  * *docker*: build a docker container for the current `HEAD`\n\n## More information\n\n  * The source code is periodically indexed: [Prometheus Core](http://godoc.org/github.com/prometheus/prometheus).\n  * You will find a Travis CI configuration in `.travis.yml`.\n  * See the [Community page](https://prometheus.io/community) for how to reach the Prometheus developers and users on various communication channels.\n\n## Contributing\n\nRefer to [CONTRIBUTING.md](https://github.com/prometheus/prometheus/blob/master/CONTRIBUTING.md)\n\n## License\n\nApache License 2.0, see [LICENSE](https://github.com/prometheus/prometheus/blob/master/LICENSE).\n\n\n[travis]: https://travis-ci.org/prometheus/prometheus\n[hub]: https://hub.docker.com/r/prom/prometheus/\n[circleci]: https://circleci.com/gh/prometheus/prometheus\n[quay]: https://quay.io/repository/prometheus/prometheus\n","remote_repo_id":6838921,"sha":"388ef759d2fc5ce00af2f7be634e0841faaf6071","size":4482}
,{"name":"ApertusVR","owner":"MTASZTAKI","path":"README.md","readme":"# ApertusVR\nFree virtual and augmented reality engine\n\n[website](http://www.apertusvr.org)\n\n[forum](http://forum.apertusvr.org/)\n\n![Overview](http://www.apertusvr.org/wp-content/uploads/2017/04/overview-998x1024.png)\n\n## About\nApertusVR offers a brand new \"no vendor lock-in\" approach for\nvirtual and augmented reality on different operating systems\nand on different virtual and augmented reality hardware.\n\nThis higher abstraction level enables that the business logic\nhas to be implemented once and then it works on any platform.\nMoreover these different virtual and augmented reality hardware\ncan be shared a same virtual reality scene at the same time.\n\nThe ApertusVR engine only contains libraries in order to \neasily integrate the virtual and augmented reality technologies\ninto an already existing product.\nBy the help of the factory plugins and samples\nApertusVR could boosts up the creation of a minimum viable product from scratch.\n\n## How to use\n### From Source\nCurrently, tested only on Windows Visual Studio Community 2015\nand Windows Visual Studio Community 2017\n\n1. Clone the [repository](https://github.com/MTASZTAKI/ApertusVR)\n2. Build with [cmake](https://cmake.org/)\n\n### Windows 10 Visual Studio 2015 64bit SDK\n1. Download a SDK [downloads](http://apertusvr.org/?page_id=41)\n2. Build with [Visual Stduio 2015 Community](https://imagine.microsoft.com/en-us/Catalog/Product/101)\n\n### Windows 10 Visual Studio 2017 64bit SDK\n1. Download a SDK [downloads](http://apertusvr.org/?page_id=41)\n2. Build with [Visual Stduio 2017 Community](https://www.visualstudio.com/downloads/)\n\n### Precompiled binaries\n[Precompiled binaries](http://www.apertusvr.org/downloads/binaries) Coming soon...\n\n\n## Community\n* [Source](https://github.com/MTASZTAKI/ApertusVR)\n* [Website](http://www.apertusvr.org)\n* [Forum](http://forum.apertusvr.org/)\n* [IssueTracking](https://github.com/MTASZTAKI/ApertusVR/issues)\n* [UseCases](http://apertusvr.org/#usecase)\n* [SDKs](http://apertusvr.org/sdk/)\n\n\n## Versions\nVersion | Release Date\n------- | ------------\n0.1.0   | 2017.05.09.\n\n\n##License\nApertusVR is released under the MIT License, which is a permissive open source license. The only condition is that you distribute the [license](https://github.com/MTASZTAKI/ApertusVR/blob/master/LICENSE) text included in our distribution with any software that uses ApertusVR.\n","remote_repo_id":73708854,"sha":"5b9c33348bf1fc06425696c73b3988a9e6ac4a11","size":2360}
,{"name":"cockroach","owner":"cockroachdb","path":"README.md","readme":"![CockroachDB](docs/media/cockroach_db.png?raw=true \"CockroachDB logo\")\n=======================================================================\n\nCockroachDB is a cloud-native SQL database for building global, scalable cloud services that survive disasters.\n\n[![TeamCity CI](https://teamcity.cockroachdb.com/guestAuth/app/rest/builds/buildType:(id:Cockroach_UnitTests)/statusIcon.svg)](https://teamcity.cockroachdb.com/viewLog.html?buildTypeId=Cockroach_UnitTests\u0026buildId=lastFinished\u0026guest=1)\n[![GoDoc](https://godoc.org/github.com/cockroachdb/cockroach?status.svg)](https://godoc.org/github.com/cockroachdb/cockroach)\n![Version](https://img.shields.io/badge/version-1.0-brightgreen.svg)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/cockroachdb/cockroach?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge)\n\n- [What is CockroachDB?](#what-is-cockroachdb)\n- [Docs](#docs)\n- [Quickstart](#quickstart)\n- [Client Drivers](#client-drivers)\n- [Deployment](#deployment)\n- [Need Help?](#need-help)\n- [Contributing](#contributing)\n- [Design](#design)\n- [Comparison with Other Databases](#comparison-with-other-databases)\n- [See Also](#see-also)\n\n## What is CockroachDB?\n\nCockroachDB is a distributed SQL database built on a transactional and\nstrongly-consistent key-value store. It **scales** horizontally;\n**survives** disk, machine, rack, and even datacenter failures with\nminimal latency disruption and no manual intervention; supports\n**strongly-consistent** ACID transactions; and provides a familiar\n**SQL** API for structuring, manipulating, and querying data.\n\nFor more details, see our [FAQ](https://cockroachlabs.com/docs/stable/frequently-asked-questions.html) and original [design document](\nhttps://github.com/cockroachdb/cockroach#design).\n\n## Status\n\nCockroachDB is production-ready. See our\n[1.1 milestone](https://github.com/cockroachdb/cockroach/milestone/10) for a list of features planned or in development.\n\n## Docs\n\nFor guidance on installation, development, deployment, and administration, see our [User Documentation](https://cockroachlabs.com/docs/stable/).\n\n## Quickstart\n\n1. [Install CockroachDB](https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html).\n\n1. [Start a local cluster](https://www.cockroachlabs.com/docs/stable/start-a-local-cluster.html)\n   and talk to it via the [built-in SQL client](https://www.cockroachlabs.com/docs/stable/use-the-built-in-sql-client.html).\n\n1. [Learn more about CockroachDB SQL](https://www.cockroachlabs.com/docs/stable/learn-cockroachdb-sql.html).\n\n1. Use a PostgreSQL-compatible driver or ORM to\n   [build an app with CockroachDB](https://www.cockroachlabs.com/docs/stable/build-an-app-with-cockroachdb.html).\n\n1. [Explore core features](https://www.cockroachlabs.com/docs/stable/demo-data-replication.html),\n   such as data replication, automatic rebalancing, and fault tolerance and recovery.\n\n## Client Drivers\n\nCockroachDB supports the PostgreSQL wire protocol, so you can use any available PostgreSQL client drivers to connect from various languages.\n\n- For recommended drivers that we've tested, see [Install Client Drivers](https://www.cockroachlabs.com/docs/stable/install-client-drivers.html).\n\n- For tutorials using these drivers, as well as supported ORMs, see [Build an App with CockroachDB](https://www.cockroachlabs.com/docs/stable/build-an-app-with-cockroachdb.html).\n\n## Deployment\n\n- [Manual Deployment](https://www.cockroachlabs.com/docs/stable/manual-deployment.html) - Steps to deploy a CockroachDB cluster manually on multiple machines.\n\n- [Cloud Deployment](https://www.cockroachlabs.com/docs/stable/cloud-deployment.html) - Guides for deploying CockroachDB on various cloud platforms.\n\n- [Orchestration](https://www.cockroachlabs.com/docs/stable/orchestration.html) - Guides for running CockroachDB with popular open-source orchestration systems.\n\n## Need Help?\n\n- [Troubleshooting documentation](https://www.cockroachlabs.com/docs/stable/troubleshooting-overview.html) -\n  Learn how to troubleshoot common errors, cluster and node setup, and SQL query behavior,\n  and how to use debug and error logs.\n\n- [CockroachDB Forum](https://forum.cockroachlabs.com/) and\n  [Stack Overflow](https://stackoverflow.com/questions/tagged/cockroachdb) - Ask questions,\n  find answers, and help other users.\n\n- [Join us on Gitter](https://gitter.im/cockroachdb/cockroach) - This is the most immediate\n  way to connect with CockroachDB engineers.\n\n- For filing bugs, suggesting improvements, or requesting new features, help us out by\n  [opening an issue](https://github.com/cockroachdb/cockroach/issues/new).\n\n## Contributing\n\nWe're an open source project and welcome contributions.\n\n1.  See [CONTRIBUTING.md](https://github.com/cockroachdb/cockroach/blob/master/CONTRIBUTING.md) to get your local environment set up.\n\n2.  Take a look at our [open issues](https://github.com/cockroachdb/cockroach/issues/), in particular those with the [help wanted label](https://github.com/cockroachdb/cockroach/labels/help%20wanted).\n\n3.  Review our [style guide](https://github.com/cockroachdb/cockroach/blob/master/CONTRIBUTING.md#style-guide) and follow our [code reviews](https://github.com/cockroachdb/cockroach/pulls) to learn about our style and conventions.\n\n4.  Make your changes according to our [code review workflow](https://github.com/cockroachdb/cockroach/blob/master/CONTRIBUTING.md#code-review-workflow).\n\n## Design\n\nThis is an overview. For an in-depth discussion of the design and architecture, see the full [design doc](https://github.com/cockroachdb/cockroach/blob/master/docs/design.md).\n\nFor another quick design overview, see the [CockroachDB tech talk slides](https://docs.google.com/presentation/d/1tPPhnpJ3UwyYMe4MT8jhqCrE9ZNrUMqsvXAbd97DZ2E/edit#slide=id.p).\n\n### Design Goals\n\nCockroachDB is a distributed SQL database built on top of a\ntransactional and consistent key:value store.\n\nThe primary design goals are support for ACID transactions, horizontal scalability and survivability, hence the name.\n\nIt aims to tolerate disk, machine, rack, and even datacenter failures with minimal latency disruption and no manual intervention.\n\nCockroachDB nodes are symmetric; a design goal is homogeneous deployment (one binary) with minimal configuration.\n\n### How it Works in a Nutshell\n\nCockroachDB implements a single, monolithic sorted map from key to value\nwhere both keys and values are byte strings (not unicode).\n\nThe map is composed of one or more ranges and each range is backed by\ndata stored in [RocksDB][0] (a variant of [LevelDB][1]), and is\nreplicated to a total of three or more CockroachDB servers. This\nenables CockroachDB to scale linearly — theoretically up to 4 exabytes\n(4E) of logical data.\n\nRanges are defined by start and end keys. Ranges are merged and split\nto maintain total byte size within a globally configurable min/max\nsize interval. Range sizes default to target 64M in order to\nfacilitate quick splits and merges and to distribute load at hotspots\nwithin a key range. Range replicas are intended to be located in\ndisparate datacenters for survivability (e.g. `{ US-East, US-West,\nJapan }`, `{ Ireland, US-East, US-West}` , `{ Ireland, US-East,\nUS-West, Japan, Australia }`).\n\nSingle mutations to ranges are mediated via an instance of a\ndistributed consensus algorithm to ensure consistency. We’ve chosen to\nuse the [Raft consensus algorithm][2]. All consensus state is also\nstored in [RocksDB][0].\n\nA single logical mutation may affect multiple key/value pairs. Logical\nmutations have ACID transactional semantics. If all keys affected by a\nlogical mutation fall within the same range, atomicity and consistency\nare guaranteed by [Raft][2]; this is the fast commit path. Otherwise, a\nnon-locking distributed commit protocol is employed between affected\nranges.\n\nCockroachDB provides snapshot isolation (SI) and serializable snapshot\nisolation (SSI) semantics, allowing externally consistent, lock-free\nreads and writes--both from an historical snapshot timestamp and from\nthe current wall clock time. SI provides lock-free reads and writes\nbut still allows write skew. SSI eliminates write skew, but introduces\na performance hit in the case of a contentious system. SSI is the\ndefault isolation; clients must consciously decide to trade\ncorrectness for performance. CockroachDB implements a limited form of\nlinearalizability, providing ordering for any observer or chain of\nobservers.\n\nSimilar to [Spanner][3] directories, CockroachDB allows configuration of\narbitrary zones of data. This allows replication factor, storage\ndevice type, and/or datacenter location to be chosen to optimize\nperformance and/or availability. Unlike Spanner, zones are monolithic\nand don’t allow movement of fine grained data on the level of entity\ngroups.\n\n## Comparison with Other Databases\n\nTo see how key features of CockroachDB stack up against other databases,\nvisit the [CockroachDB in Comparison](https://www.cockroachlabs.com/docs/stable/cockroachdb-in-comparison.html) page on our website.\n\n## See Also\n\n- [Tech Talks](https://www.cockroachlabs.com/community/tech-talks/) by CockroachDB founders and engineers\n- [The CockroachDB User documentation](https://cockroachlabs.com/docs/stable/)\n- [The CockroachDB Blog](https://www.cockroachlabs.com/blog/)\n- Key Design documents:\n  - [Serializable, Lockless, Distributed: Isolation in CockroachDB](https://www.cockroachlabs.com/blog/serializable-lockless-distributed-isolation-cockroachdb/)\n  - [Consensus, Made Thrive](https://www.cockroachlabs.com/blog/consensus-made-thrive/)\n  - [Trust, But Verify: How CockroachDB Checks Replication](https://www.cockroachlabs.com/blog/trust-but-verify-cockroachdb-checks-replication/)\n  - [Living Without Atomic Clocks](https://www.cockroachlabs.com/blog/living-without-atomic-clocks/)\n  - [The CockroachDB Architecture Document](https://github.com/cockroachdb/cockroach/blob/master/docs/design.md)\n\n[0]: http://rocksdb.org/\n[1]: https://github.com/google/leveldb\n[2]: https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf\n[3]: http://research.google.com/archive/spanner.html\n","remote_repo_id":16563587,"sha":"38ae5d95d47002380fd4beb3a32af85aacf13c5c","size":10127}
,{"name":"pandas","owner":"pandas-dev","path":"README.md","readme":"\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://github.com/pandas-dev/pandas/blob/master/doc/logo/pandas_logo.png\"\u003e\u003cbr\u003e\n\u003c/div\u003e\n\n-----------------\n\n# pandas: powerful Python data analysis toolkit\n\n\u003ctable\u003e\n\u003ctr\u003e\n  \u003ctd\u003eLatest Release\u003c/td\u003e\n  \u003ctd\u003e\u003cimg src=\"https://img.shields.io/pypi/v/pandas.svg\" alt=\"latest release\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n  \u003ctd\u003e\u003c/td\u003e\n  \u003ctd\u003e\u003cimg src=\"https://anaconda.org/conda-forge/pandas/badges/version.svg\" alt=\"latest release\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003ePackage Status\u003c/td\u003e\n  \u003ctd\u003e\u003cimg src=\"https://img.shields.io/pypi/status/pandas.svg\" alt=\"status\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eLicense\u003c/td\u003e\n  \u003ctd\u003e\u003cimg src=\"https://img.shields.io/pypi/l/pandas.svg\" alt=\"license\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eBuild Status\u003c/td\u003e\n  \u003ctd\u003e\n    \u003ca href=\"https://travis-ci.org/pandas-dev/pandas\"\u003e\n    \u003cimg src=\"https://travis-ci.org/pandas-dev/pandas.svg?branch=master\" alt=\"travis build status\" /\u003e\n    \u003c/a\u003e\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003e\u003c/td\u003e\n  \u003ctd\u003e\n    \u003ca href=\"https://circleci.com/gh/pandas-dev/pandas\"\u003e\n    \u003cimg src=\"https://circleci.com/gh/circleci/mongofinil/tree/master.svg?style=shield\u0026circle-token=223d8cafa7b02902c3e150242520af8944e34671\" alt=\"circleci build status\" /\u003e\n    \u003c/a\u003e\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003e\u003c/td\u003e\n  \u003ctd\u003e\n    \u003ca href=\"https://ci.appveyor.com/project/pandas-dev/pandas\"\u003e\n    \u003cimg src=\"https://ci.appveyor.com/api/projects/status/86vn83mxgnl4xf1s/branch/master?svg=true\" alt=\"appveyor build status\" /\u003e\n    \u003c/a\u003e\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eCoverage\u003c/td\u003e\n  \u003ctd\u003e\u003cimg src=\"https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=master\" alt=\"coverage\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eConda\u003c/td\u003e\n  \u003ctd\u003e\n    \u003ca href=\"https://pandas.pydata.org\"\u003e\n    \u003cimg src=\"http://pubbadges.s3-website-us-east-1.amazonaws.com/pkgs-downloads-pandas.png\" alt=\"conda default downloads\" /\u003e\n    \u003c/a\u003e\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003eConda-forge\u003c/td\u003e\n  \u003ctd\u003e\n    \u003ca href=\"https://pandas.pydata.org\"\u003e\n    \u003cimg src=\"https://anaconda.org/conda-forge/pandas/badges/downloads.svg\" alt=\"conda-forge downloads\" /\u003e\n    \u003c/a\u003e\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd\u003ePyPI\u003c/td\u003e\n  \u003ctd\u003e\n    \u003ca href=\"https://pypi.python.org/pypi/pandas/\"\u003e\n    \u003cimg src=\"https://img.shields.io/pypi/dm/pandas.svg\" alt=\"pypi downloads\" /\u003e\n    \u003c/a\u003e\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\n\n[![https://gitter.im/pydata/pandas](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/pydata/pandas?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge\u0026utm_content=badge)\n\n## What is it\n\n**pandas** is a Python package providing fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way toward this goal.\n\n## Main Features\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of [**missing data**][missing-data] (represented as\n    `NaN`) in floating point as well as non-floating point data\n  - Size mutability: columns can be [**inserted and\n    deleted**][insertion-deletion] from DataFrame and higher dimensional\n    objects\n  - Automatic and explicit [**data alignment**][alignment]: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let `Series`, `DataFrame`, etc. automatically\n    align the data for you in computations\n  - Powerful, flexible [**group by**][groupby] functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\n  - Make it [**easy to convert**][conversion] ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\n  - Intelligent label-based [**slicing**][slicing], [**fancy\n    indexing**][fancy-indexing], and [**subsetting**][subsetting] of\n    large data sets\n  - Intuitive [**merging**][merging] and [**joining**][joining] data\n    sets\n  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of\n    data sets\n  - [**Hierarchical**][mi] labeling of axes (possible to have multiple\n    labels per tick)\n  - Robust IO tools for loading data from [**flat files**][flat-files]\n    (CSV and delimited), [**Excel files**][excel], [**databases**][db],\n    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]\n  - [**Time series**][timeseries]-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    moving window linear regressions, date shifting and lagging, etc.\n\n\n   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/missing_data.html#working-with-missing-data\n   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/dsintro.html#column-selection-addition-deletion\n   [alignment]: https://pandas.pydata.org/pandas-docs/stable/dsintro.html?highlight=alignment#intro-to-data-structures\n   [groupby]: https://pandas.pydata.org/pandas-docs/stable/groupby.html#group-by-split-apply-combine\n   [conversion]: https://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n   [slicing]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#slicing-ranges\n   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#advanced-indexing-with-ix\n   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing\n   [merging]: https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n   [joining]: https://pandas.pydata.org/pandas-docs/stable/merging.html#joining-on-index\n   [reshape]: https://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-and-pivot-tables\n   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/reshaping.html#pivot-tables-and-cross-tabulations\n   [mi]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#hierarchical-indexing-multiindex\n   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/io.html#csv-text-files\n   [excel]: https://pandas.pydata.org/pandas-docs/stable/io.html#excel-files\n   [db]: https://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries\n   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables\n   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-series-date-functionality\n\n## Where to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\n\nBinary installers for the latest released version are available at the [Python\npackage index](https://pypi.python.org/pypi/pandas) and on conda.\n\n```sh\n# conda\nconda install pandas\n```\n\n```sh\n# or PyPI\npip install pandas\n```\n\n## Dependencies\n- [NumPy](http://www.numpy.org): 1.9.0 or higher\n- [python-dateutil](https://labix.org/python-dateutil): 2.5.0 or higher\n- [pytz](https://pythonhosted.org/pytz): 2011k or higher\n\nSee the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies)\nfor recommended and optional dependencies.\n\n## Installation from sources\nTo install pandas from source you need Cython in addition to the normal\ndependencies above. Cython can be installed from pypi:\n\n```sh\npip install cython\n```\n\nIn the `pandas` directory (same one where you found this file after\ncloning the git repo), execute:\n\n```sh\npython setup.py install\n```\n\nor for installing in [development mode](https://pip.pypa.io/en/latest/reference/pip_install.html#editable-installs):\n\n```sh\npython setup.py develop\n```\n\nAlternatively, you can use `pip` if you want all the dependencies pulled\nin automatically (the `-e` option is for installing it in [development\nmode](https://pip.pypa.io/en/latest/reference/pip_install.html#editable-installs)):\n\n```sh\npip install -e .\n```\n\nSee the full instructions for [installing from source](https://pandas.pydata.org/pandas-docs/stable/install.html#installing-from-source).\n\n## License\n[BSD 3](LICENSE)\n\n## Documentation\nThe official documentation is hosted on PyData.org: https://pandas.pydata.org/pandas-docs/stable\n\n## Background\nWork on ``pandas`` started at AQR (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\n\n## Getting Help\n\nFor usage questions, the best place to go to is [StackOverflow](https://stackoverflow.com/questions/tagged/pandas).\nFurther, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).\n\n## Discussion and Development\nMost development discussion is taking place on github in this repo. Further, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Gitter channel](https://gitter.im/pydata/pandas) is available for quick development related questions.\n\n## Contributing to pandas\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements and ideas are welcome.\n\nA detailed overview on how to contribute can be found in the **[contributing guide.](https://pandas.pydata.org/pandas-docs/stable/contributing.html)**\n\nIf you are simply looking to start working with the pandas codebase, navigate to the [GitHub “issues” tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?labels=Docs\u0026sort=updated\u0026state=open) and [Difficulty Novice](https://github.com/pandas-dev/pandas/issues?q=is%3Aopen+is%3Aissue+label%3A%22Difficulty+Novice%22) where you could start out.\n\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking ‘this can be improved’...you can do something about it!\n\nFeel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Gitter](https://gitter.im/pydata/pandas).\n","remote_repo_id":858127,"sha":"4b9c9505e320ae8682917e2557f422f89b5ee949","size":9985}
,{"name":"ugene","owner":"ugeneunipro","path":"README.md","readme":"# UGENE\n\n## Building UGENE\n\n### Prerequisites\n\nMake sure the Qt (\u003e= 5.2.1 and \u003c 5.6) development libraries are installed:\n\n* Ubuntu 16.04: `sudo apt-get install qt5-default qttools5-dev-tools qtscript5-dev libqt5svg5-dev libqt5webkit5-dev libprocps4-dev`\n* Ubuntu 14.04: `sudo apt-get install qt5-default qttools5-dev-tools qtscript5-dev libqt5svg5-dev libqt5webkit5-dev libprocps3-dev`\n* Ubuntu 12.04:\n    * Download and install Qt 5.5.1: www.qt.io/download-open-source/\n    * Set the system variable: export PATH=$PATH:~/Qt5.5.1/5.5/gcc_64/bin\n    * `sudo apt-get install g++ libgl1-mesa-dev libproc-dev libglu1-mesa-dev`\n    * `sudo ln -s /usr/lib/libproc.so /usr/lib/libprocps.so`\n* Fedora:       `sudo yum install qt5-qtscript-devel qt5-qtbase-devel qt5-qtsvg-devel qt5-linguist qt5-qtwebkit-devel gcc-c++ redhat-rpm-config procps-ng-devel mesa-libGLU-devel`\n* Arch Linux:   `sudo pacman -S qt`\n* Mac OS X: download from Qt official site (http://www.qt.io/download/)\n* Windows: download from Qt official site (http://www.qt.io/download/)\n\n### For Windows users:\n\nTo build with devenv (Visual Studio)\n\n1. `qmake -r -tp vc ugene.pro`\n   1.1. add \"CONFIG+=x64\" to qmake command for 64-bit build\n2. open ugene.sln from Visual Studio or run `devenv.exe ugene.sln /Build` from MSVC command line\n\nTo build with nmake.exe:\n\n1. `qmake -r ugene.pro`\n   1.1. add \"CONFIG+=x64\" to qmake command for 64-bit build\n2. run `nmake`, `nmake debug` or `nmake release` to build UGENE\n\nAlso you need to add \"libeay.dll\" and \"ssleay.dll\" from OpenSSL ToolKit to \"../ugene/src/_debug\" folder\n\n### For *nix users:\n\n0. installation paths may be set up in ugene_globals.pri\n1. `qmake -r` (Fedora: `qmake-qt5 -r`)\n2. `make -j 4`\n3. `sudo make install`\n4. `ugene -ui`\n\n\u003e Note: usually, `make` builds a release version of UGENE.\n   However, on certain platforms default target is debug.\n   To enforce release build use `make release` or `make all`.\n\nSome more information you can see in installer/_common_data/README file.\n\n### Build with CUDA\n\n1. Download and install required software from http://www.nvidia.com/object/cuda_get.html for your OS\n2. Make sure that some system variable are set:\n   ```\n   CUDA_LIB_PATH=/path_where_cuda_installed/lib\n   CUDA_INC_PATH=/path_where_cuda_installed/include\n   PATH=$PATH:/path_where_cuda_installed/bin\n   ```\n   \n   for *nix: `LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_LIB_PATH`\n\n3. cd ./src and open ugene_globals.pri, find and set variable UGENE_CUDA_DETECTED = 1\n\n### Build with OpenCL\n\n1. Download and install video driver wich supports OpenCL\n2. Download OpenCL headers from http://www.khronos.org/registry/cl/\n   or find them in video vendor SDK directory.\n3. make sure that you have system variable is set correctly:\n          `OPENCL_INC_PATH=/path_where_open_cl_installed`\n4. cd ./src and open ugene_globals.pri, find and set variable `UGENE_OPENCL_DETECTED = 1`\n\n\u003e Notes: UGENE_CELL flag in ugene_globals should be uncommented when building on Cell BE platform\n","remote_repo_id":53667592,"sha":"474358aa15fb789fde2743f88152228c3aa58b2a","size":2989}
,{"name":"zulip","owner":"zulip","path":"README.md","readme":"# Zulip overview\n\nZulip is a powerful, open source group chat application that combines the\nimmediacy of real-time chat with the productivity benefits of threaded\nconversations. Zulip is used by open source projects, Fortune 500 companies,\nlarge standards bodies, and others who need a real-time chat system that\nallows users to easily process hundreds or thousands of messages a day. With\nover 300 contributors merging over 500 commits a month, Zulip is also the\nlargest and fastest growing open source group chat project.\n\n[![Build Status](https://travis-ci.org/zulip/zulip.svg?branch=master)](https://travis-ci.org/zulip/zulip)\n[![Coverage Status](https://img.shields.io/codecov/c/github/zulip/zulip.svg)](https://codecov.io/gh/zulip/zulip)\n[![Mypy coverage](https://img.shields.io/badge/mypy-100%25-green.svg)][mypy-coverage]\n[![docs](https://readthedocs.org/projects/zulip/badge/?version=latest)](https://zulip.readthedocs.io/en/latest/)\n[![Zulip chat](https://img.shields.io/badge/zulip-join_chat-brightgreen.svg)](https://chat.zulip.org)\n[![Twitter](https://img.shields.io/badge/twitter-@zulip-blue.svg?style=flat)](https://twitter.com/zulip)\n\n[mypy-coverage]: https://blog.zulip.org/2016/10/13/static-types-in-python-oh-mypy/\n\n## Getting started\n\nClick on the appropriate link below. If nothing seems to apply,\njoin us on the\n[Zulip community server](https://zulip.readthedocs.io/en/latest/contributing/chat-zulip-org.html)\nand tell us what's up!\n\nYou might be interested in:\n\n* **Contributing code**. Check out our\n  [guide for new contributors](https://zulip.readthedocs.io/en/latest/overview/contributing.html)\n  to get started. Zulip prides itself on maintaining a clean and\n  well-tested codebase, and a stock of hundreds of\n  [beginner-friendly issues][beginner-friendly].\n\n* **Contributing non-code**.\n  [Report an issue](https://zulip.readthedocs.io/en/latest/overview/contributing.html#reporting-issue),\n  [translate](https://zulip.readthedocs.io/en/latest/translating/translating.html) Zulip\n  into your language,\n  [write](https://zulip.readthedocs.io/en/latest/overview/contributing.html#zulip-outreach)\n  for the Zulip blog, or\n  [give us feedback](https://zulip.readthedocs.io/en/latest/overview/contributing.html#user-feedback). We\n  would love to hear from you, even if you're just trying the product out.\n\n* **Supporting Zulip**. Advocate for your organization to use Zulip, write a\n  review in the mobile app stores, or\n  [upvote Zulip](https://zulip.readthedocs.io/en/latest/overview/contributing.html#zulip-outreach) on\n  product comparison sites.\n\n* **Checking Zulip out**. The best way to see Zulip in action is to drop by\n  the\n  [Zulip community server](https://zulip.readthedocs.io/en/latest/contributing/chat-zulip-org.html). We\n  also recommend reading Zulip for\n  [open source](https://zulipchat.com/for/open-source/), Zulip for\n  [companies](https://zulipchat.com/for/companies/), or Zulip for\n  [working groups and part time communities](https://zulipchat.com/for/working-groups-and-communities/).\n\n* **Running a Zulip server**. Setting up a server takes just a couple of\n  minutes. Zulip runs on Ubuntu 16.04 Xenial and Ubuntu 14.04 Trusty. The\n  installation process is\n  [documented here](https://zulip.readthedocs.io/en/1.7.1/prod.html).\n  Commercial support is available; see \u003chttps://zulipchat.com/plans\u003e for\n  details.\n\n* **Using Zulip without setting up a server**. \u003chttps://zulipchat.com\u003e offers\n  free and commercial hosting.\n\n* **Applying for a Zulip internship**. Zulip runs internship programs with\n  [Outreachy](https://www.outreachy.org/),\n  [Google Summer of Code](https://developers.google.com/open-source/gsoc/),\n  and the\n  [MIT Externship program](https://alum.mit.edu/students/NetworkwithAlumni/ExternshipProgram). Zulip\n  also participates in\n  [Google Code-In](https://developers.google.com/open-source/gci/). More\n  information is available\n  [here](https://zulip.readthedocs.io/en/latest/overview/contributing.html#internship-programs).\n\nYou may also be interested in reading our [blog](http://blog.zulip.org/) or\nfollowing us on [twitter](https://twitter.com/zulip).\nZulip is distributed under the\n[Apache 2.0](https://github.com/zulip/zulip/blob/master/LICENSE) license.\n\n[beginner-friendly]: https://github.com/zulip/zulip/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22\n","remote_repo_id":43160685,"sha":"b2382afc71c009fe248b8ca262a01f15e8dd1436","size":4350}
,{"name":"kubernetes","owner":"kubernetes","path":"README.md","readme":"# Kubernetes\n\n[![Submit Queue Widget]][Submit Queue] [![GoDoc Widget]][GoDoc] [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/569/badge)](https://bestpractices.coreinfrastructure.org/projects/569)\n\n\u003cimg src=\"https://github.com/kubernetes/kubernetes/raw/master/logo/logo.png\" width=\"100\"\u003e\n\n----\n\nKubernetes is an open source system for managing [containerized applications]\nacross multiple hosts, providing basic mechanisms for deployment, maintenance,\nand scaling of applications.\n\nKubernetes builds upon a decade and a half of experience at Google running\nproduction workloads at scale using a system called [Borg],\ncombined with best-of-breed ideas and practices from the community.\n\nKubernetes is hosted by the Cloud Native Computing Foundation ([CNCF]).\nIf you are a company that wants to help shape the evolution of\ntechnologies that are container-packaged, dynamically-scheduled\nand microservices-oriented, consider joining the CNCF.\nFor details about who's involved and how Kubernetes plays a role,\nread the CNCF [announcement].\n\n----\n\n## To start using Kubernetes\n\nSee our documentation on [kubernetes.io].\n\nTry our [interactive tutorial].\n\nTake a free course on [Scalable Microservices with Kubernetes].\n\n## To start developing Kubernetes\n\nThe [community repository] hosts all information about\nbuilding Kubernetes from source, how to contribute code\nand documentation, who to contact about what, etc.\n\nIf you want to build Kubernetes right away there are two options:\n\n##### You have a working [Go environment].\n\n```\n$ go get -d k8s.io/kubernetes\n$ cd $GOPATH/src/k8s.io/kubernetes\n$ make\n```\n\n##### You have a working [Docker environment].\n\n```\n$ git clone https://github.com/kubernetes/kubernetes\n$ cd kubernetes\n$ make quick-release\n```\n\nFor the full story, head over to the [developer's documentation].\n\n## Support\n\nIf you need support, start with the [troubleshooting guide]\nand work your way through the process that we've outlined.\n\nThat said, if you have questions, reach out to us\n[one way or another][communication].\n\n[announcement]: https://cncf.io/news/announcement/2015/07/new-cloud-native-computing-foundation-drive-alignment-among-container\n[Borg]: https://research.google.com/pubs/pub43438.html\n[CNCF]: https://www.cncf.io/about\n[communication]: https://github.com/kubernetes/community/blob/master/communication.md\n[community repository]: https://github.com/kubernetes/community\n[containerized applications]: https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\n[developer's documentation]: https://github.com/kubernetes/community/tree/master/contributors/devel#readme\n[Docker environment]: https://docs.docker.com/engine\n[Go environment]: https://golang.org/doc/install\n[GoDoc]: https://godoc.org/k8s.io/kubernetes\n[GoDoc Widget]: https://godoc.org/k8s.io/kubernetes?status.svg\n[interactive tutorial]: http://kubernetes.io/docs/tutorials/kubernetes-basics\n[kubernetes.io]: http://kubernetes.io\n[Scalable Microservices with Kubernetes]: https://www.udacity.com/course/scalable-microservices-with-kubernetes--ud615\n[Submit Queue]: http://submit-queue.k8s.io/#/ci\n[Submit Queue Widget]: http://submit-queue.k8s.io/health.svg?v=1\n[troubleshooting guide]: https://kubernetes.io/docs/tasks/debug-application-cluster/troubleshooting/\n\n[![Analytics](https://kubernetes-site.appspot.com/UA-36037335-10/GitHub/README.md?pixel)]()\n","remote_repo_id":20580498,"sha":"d0bc7178e6178eb445c274261426c7ee99f974de","size":3388}
,{"name":"cpp-ethereum","owner":"ethereum","path":"README.md","readme":"# cpp-ethereum - Ethereum C++ client\n\nThis repository contains [cpp-ethereum](http://cpp-ethereum.org), the [Ethereum](https://ethereum.org) C++ client.\n\nIt is the third most popular of the Ethereum clients, behind [geth](https://github.com/ethereum/go-ethereum) (the [go](https://golang.org)\nclient) and [Parity](https://github.com/ethcore/parity) (the [rust](https://www.rust-lang.org/) client).  The code is exceptionally\n[portable](http://cpp-ethereum.org/portability.html) and has been used successfully on a very broad range\nof operating systems and hardware.\n\n\n## Contact\n\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/ethereum/cpp-ethereum)\n[![GitHub Issues](https://img.shields.io/github/issues-raw/badges/shields.svg)](https://github.com/ethereum/cpp-ethereum/issues)\n\n- Chat in [cpp-ethereum channel on Gitter](https://gitter.im/ethereum/cpp-ethereum).\n- Report bugs, issues or feature requests using [GitHub issues](issues/new).\n\n\n## Getting Started\n\nThe Ethereum Documentation site hosts the **[cpp-ethereum homepage](http://cpp-ethereum.org)**, which\nhas a Quick Start section.\n\n\nOperating system | Status\n---------------- | ----------\nUbuntu and macOS | [![TravisCI](https://img.shields.io/travis/ethereum/cpp-ethereum/develop.svg)](https://travis-ci.org/ethereum/cpp-ethereum)\nWindows          | [![AppVeyor](https://img.shields.io/appveyor/ci/ethereum/cpp-ethereum/develop.svg)](https://ci.appveyor.com/project/ethereum/cpp-ethereum)\n\n\n## Building from source\n\n### Get the source code\n\nGit and GitHub is used to maintain the source code. Clone the repository by:\n\n```shell\ngit clone --recursive https://github.com/ethereum/cpp-ethereum.git\ncd cpp-ethereum\n```\n\nThe `--recursive` option is important. It orders git to clone additional \nsubmodules which are required to build the project.\nIf you missed it you can correct your mistake with command \n`git submodule update --init`.\n\n### Install CMake\n\nCMake is used to control the build configuration of the project. Quite recent \nversion of CMake is required \n(at the time of writing [3.4.3 is the minimum](CMakeLists.txt#L25)).\nWe recommend installing CMake by downloading and unpacking the binary \ndistribution  of the latest version available on the \n[**CMake download page**](https://cmake.org/download/).\n\nThe CMake package available in your operating system can also be installed\nand used if it meets the minimum version requirement.\n\n\u003e **Alternative method**\n\u003e\n\u003e The repository contains the\n[scripts/install_cmake.sh](scripts/install_cmake.sh) script that downloads \n\u003e a fixed version of CMake and unpacks it to the given directory prefix. \n\u003e Example usage: `scripts/install_cmake.sh --prefix /usr/local`.\n\n### Install dependencies (Linux, macOS)\n\nThe following *libraries* are required to be installed in the system in their\ndevelopment variant:\n\n- leveldb\n\nThey usually can be installed using system-specific package manager.\nExamples for some systems:\n\nOperating system | Installation command\n---------------- | --------------------\nDebian-based     | `sudo apt-get install libleveldb-dev`\nRedHat-based     | `dnf install leveldb-devel`\nmacOS            | `brew install leveldb`\n\n\nWe also support a \"one-button\" shell script \n[scripts/install_deps.sh](scripts/install_deps.sh)\nwhich attempts to aggregate dependencies installation instructions for Unix-like\noperating systems. It identifies your distro and installs the external packages.\nSupporting the script is non-trivial task so please [inform us](#contact)\nif it does not work for your use-case.\n\n### Install dependencies (Windows)\n\nWe provide prebuilt dependencies required to build the project. Download them\nwith the [scripts/install_deps.bat](scripts/install_deps.bat) script.\n\n```shell\nscripts/install_deps.bat\n```\n\n### Build\n\nConfigure the project build with the following command. It will create the \n`build` directory with the configuration.\n\n```shell\nmkdir build; cd build  # Create a build directory.\ncmake ..               # Configure the project.\ncmake --build .        # Build all default targets.\n```\n\nOn **Windows** Visual Studio 2015 is required. You should generate Visual Studio \nsolution file (.sln) for 64-bit architecture by adding \n`-G \"Visual Studio 14 2015 Win64\"` argument to the CMake configure command.\nAfter configuration is completed the `cpp-ethereum.sln` can be found in the\n`build` directory.\n\n```shell\ncmake .. -G \"Visual Studio 14 2015 Win64\"\n```\n\n## Contributing\n\n[![Contributors](https://img.shields.io/github/contributors/ethereum/cpp-ethereum.svg)](https://github.com/ethereum/cpp-ethereum/graphs/contributors)\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/ethereum/cpp-ethereum)\n[![up-for-grabs](https://img.shields.io/github/issues-raw/ethereum/cpp-ethereum/up-for-grabs.svg)](https://github.com/ethereum/cpp-ethereum/labels/up-for-grabs)\n\nThe current codebase is the work of many, many hands, with nearly 100\n[individual contributors](https://github.com/ethereum/cpp-ethereum/graphs/contributors) over the course of its development.\n\nOur day-to-day development chat happens on the\n[cpp-ethereum](https://gitter.im/ethereum/cpp-ethereum) Gitter channel.\n\nAll contributions are welcome! We try to keep a list of tasks that are suitable\nfor newcomers under the tag \n[up-for-grabs](https://github.com/ethereum/cpp-ethereum/labels/up-for-grabs).\nIf you have any questions, please just ask.\n\nPlease read [CONTRIBUTING](CONTRIBUTING.md) and [CODING_STYLE](CODING_STYLE.md) \nthoroughly before making alterations to the code base.\n\nAll development goes in develop branch.\n\n\n## Mining\n\nThis project is **not suitable for Ethereum mining**. The support for GPU mining \nhas been dropped some time ago including the ethminer tool. Use the ethminer tool from https://github.com/ethereum-mining/ethminer.\n\n## Testing\n\nTo run the tests, make sure you clone https://github.com/ethereum/tests and point the environment variable\n`ETHEREUM_TEST_PATH` to that path.\n\n## Documentation\n\n- [Internal documentation for developers](doc/index.rst).\n- [Outdated documentation for end users](http://www.ethdocs.org/en/latest/ethereum-clients/cpp-ethereum/).\n\n\n## License\n\n[![License](https://img.shields.io/github/license/ethereum/cpp-ethereum.svg)](LICENSE)\n\nAll contributions are made under the [GNU General Public License v3](https://www.gnu.org/licenses/gpl-3.0.en.html). See [LICENSE](LICENSE).\n","remote_repo_id":15460666,"sha":"639ef3da3fadeb45cfc965dabb056b5c936087ca","size":6412}
,{"name":"chainerrl","owner":"chainer","path":"README.md","readme":"\u003cdiv align=\"center\"\u003e\u003cimg src=\"assets/ChainerRL.png\" width=\"400\"/\u003e\u003c/div\u003e\n\n# ChainerRL\n[![Build Status](https://travis-ci.org/chainer/chainerrl.svg?branch=master)](https://travis-ci.org/chainer/chainerrl)\n[![Coverage Status](https://coveralls.io/repos/github/chainer/chainerrl/badge.svg?branch=master)](https://coveralls.io/github/chainer/chainerrl?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/chainerrl/badge/?version=latest)](http://chainerrl.readthedocs.io/en/latest/?badge=latest)\n[![PyPI](https://img.shields.io/pypi/v/chainerrl.svg)](https://pypi.python.org/pypi/chainerrl)\n\nChainerRL is a deep reinforcement learning library that implements various state-of-the-art deep reinforcement algorithms in Python using [Chainer](https://github.com/pfnet/chainer), a flexible deep learning framework.\n\n![Breakout](assets/breakout.gif)\n![Humanoid](assets/humanoid.gif)\n\n## Installation\n\nChainerRL is tested with Python 2.7+ and 3.5.1+. For other requirements, see [requirements.txt](requirements.txt).\n\nChainerRL can be installed via PyPI:\n```\npip install chainerrl\n```\n\nIt can also be installed from the source code:\n```\npython setup.py install\n```\n\nRefer to [Installation](http://chainerrl.readthedocs.io/en/latest/install.html) for more information on installation. \n\n## Getting started\n\nYou can try [ChainerRL Quickstart Guide](examples/quickstart/quickstart.ipynb) first, or check the [examples](examples) ready for Atari 2600 and Open AI Gym.\n\nFor more information, you can refer to [ChainerRL's documentation](http://chainerrl.readthedocs.io/en/latest/index.html).\n\n## Algorithms\n\n| Algorithm | Discrete Action | Continous Action | Recurrent Model | CPU Async Training |\n|:----------|:---------------:|:----------------:|:---------------:|:------------------:|\n| DQN (including DoubleDQN etc.) | ✓ | ✓ (NAF) | ✓ | x |\n| DDPG | x | ✓ | ✓ | x |\n| A3C | ✓ | ✓ | ✓ | ✓ |\n| ACER | ✓ | ✓ | ✓ | ✓ |\n| NSQ (N-step Q-learning) | ✓ | ✓ (NAF) | ✓ | ✓ |\n| PCL (Path Consistency Learning) | ✓ | ✓ | ✓ | ✓ |\n\nFollowing algorithms have been implemented in ChainerRL:\n- A3C (Asynchronous Advantage Actor-Critic)\n- ACER (Actor-Critic with Experience Replay)\n- Asynchronous N-step Q-learning\n- DQN (including Double DQN, Persistent Advantage Learning (PAL), Double PAL, Dynamic Policy Programming (DPP))\n- DDPG (Deep Deterministic Poilcy Gradients) (including SVG(0))\n- PGT (Policy Gradient Theorem)\n- PCL (Path Consistency Learning)\n- PPO (Proximal Policy Optimization)\n\nQ-function based algorithms such as DQN can utilize a Normalized Advantage Function (NAF) to tackle continuous-action problems as well as DQN-like discrete output networks.\n\n## Environments\n\nEnvironments that support the subset of OpenAI Gym's interface (`reset` and `step` methods) can be used.\n\n## Contributing\n\nAny kind of contribution to ChainerRL would be highly appreciated! If you are interested in contributing to ChainerRL, please read [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## License\n\n[MIT License](LICENSE).\n","remote_repo_id":80394882,"sha":"0eecaf87384cba01ab481acb5919f6469cdf1dd3","size":3045}
,{"name":"public-things-api","owner":"Financial-Times","path":"README.md","readme":"# Public API for Things (public-things-api)\n__Provides a public API for Things stored in a Neo4J graph database__\n\n## Build \u0026 deployment etc:\n_NB You will need to tag a commit in order to build, since the UI asks for a tag to build / deploy_\n* [Jenkins view](http://ftjen10085-lvpr-uk-p:8181/view/JOBS-public-things-api/)\n* [Build and publish to forge](http://ftjen10085-lvpr-uk-p:8181/job/public-things-api-build)\n* [Deploy to test](http://ftjen10085-lvpr-uk-p:8181/job/public-things-api-deploy-to-test)\n* [Deploy to prod](http://ftjen10085-lvpr-uk-p:8181/job/public-things-api-deploy-to-prod)\n\n## Installation \u0026 running locally\n* `go get -u github.com/Financial-Times/public-things-api`\n* `cd $GOPATH/src/github.com/Financial-Times/public-things-api`\n* `go test ./...`\n* `go install`\n* `$GOPATH/bin/public-things-api --neo-url={neo4jUrl} --port={port} --log-level={DEBUG|INFO|WARN|ERROR}--cache-duration{e.g. 22h10m3s}`\n_Optional arguments are:\n--neo-url defaults to http://localhost:7474/db/data, which is the out of box url for a local neo4j instance.\n--port defaults to 8080.\n--cache-duration defaults to 1 hour._\n* `curl http://localhost:8080/things/143ba45c-2fb3-35bc-b227-a6ed80b5c517 | json_pp`\nOr using [httpie](https://github.com/jkbrzt/httpie)\n* `http GET http://localhost:8080/things/143ba45c-2fb3-35bc-b227-a6ed80b5c517`\n\n## API definition\nBased on the following [google doc](https://docs.google.com/document/d/15U8DoLN8vpTzDs3XmfjQ_lKf4tMp4G02cVpHP-QmOnk/edit#heading=h.qjo76xuvpj83)\n\n## Healthchecks\nHealthchecks: [http://localhost:8080/__health](http://localhost:8080/__health)\n\n## Go To Go\nGo to go: [http://localhost:8080/__gtg](http://localhost:8080/__gtg)\n\n\n### Logging\nThe application uses logrus, the logfile is initialised in main.go.\n\nLogging requires an env app parameter: for all environments other than local, logs are written to file. When running locally logging\nis written to console (if you want to log locally to file you need to pass in an env parameter that is != local).\n\nNOTE: http://localhost:8080/__gtg end point is not logged as it is called every second from varnish and this information is not needed in logs/splunk\n","remote_repo_id":53416319,"sha":"f3c4a6edec792f5039b483b18119b32a2d0aea4e","size":2158}
,{"name":"libraries.io","owner":"librariesio","path":"README.md","readme":"# Libraries.io \u0026#128218;\n\n[![Build Status](https://circleci.com/gh/librariesio/libraries.io.svg?style=shield)](https://circleci.com/gh/librariesio/libraries.io)\n[![Slack chat](https://slack.libraries.io/badge.svg)](https://slack.libraries.io)\n[![Code Climate](https://img.shields.io/codeclimate/github/librariesio/libraries.io.svg?style=flat)](https://codeclimate.com/github/librariesio/libraries.io)\n[![Test Coverage](https://codeclimate.com/github/librariesio/libraries.io/badges/coverage.svg)](https://codeclimate.com/github/librariesio/libraries.io/coverage)\n\nLibraries.io helps developers find new open source libraries, modules and frameworks and keep track of ones they depend upon.\n\n## Documentation\n\nProject wide documentation can be found on https://docs.libraries.io, which contains high level guides on:\n\n- [What Libraries.io is](https://docs.libraries.io/)\n- [The strategy driving the project](https://docs.libraries.io/strategy)\n- [The roadmap of future goals](https://docs.libraries.io/roadmap)\n- [Architecture overview](https://docs.libraries.io/overview)\n- [Contributing guide](https://docs.libraries.io/contributorshandbook)\n- [Labelling policy](https://docs.libraries.io/labelling)\n\nEach repository has more details documentation on getting setup and adding new features, for this repository check out the following guides:\n\n- [Setting up Libraries.io locally for Development](docs/development-setup.md)\n- [Adding support for a new package manager](docs/add-a-package-manager.md)\n\n## Contributors\n\nMany wonderful people have contributed to the project, you can see them all here: https://github.com/librariesio/libraries.io/graphs/contributors\n\n## Development\n\nSource hosted at [GitHub](https://github.com/librariesio/libraries.io).\nReport issues/feature requests on [GitHub Issues](https://github.com/librariesio/libraries.io/issues). Follow us on Twitter [@librariesio](https://twitter.com/librariesio). We also hangout on [Slack](https://slack.libraries.io).\n\n### Note on Patches/Pull Requests\n\n * Fork the project.\n * Make your feature addition or bug fix.\n * Add tests for it. This is important so we don't break it in a future version unintentionally.\n * Send a pull request. Bonus points for topic branches.\n\n### Code of Conduct\n\nPlease note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.\n\n## Copyright\n\nCopyright (c) 2017 Andrew Nesbitt. See [LICENSE](https://github.com/librariesio/libraries.io/blob/master/LICENSE.txt) for details.\n","remote_repo_id":24641222,"sha":"4c0dabe1ece5d8d09aa0d2e8cc1c42a7e1cb296b","size":2568}
,{"name":"tools","owner":"UniversalDependencies","path":"README.txt","readme":"This repository contains various scripts in Perl and Python that can be used as tools for Universal Dependencies.\n\n\n\n==============================\nvalidate.py\n==============================\n\nReads a CoNLL-U file and verifies that it complies with the UD specification. It must be run with the language /\ntreebank code and there must exist corresponding lists of treebank-specific features and dependency relations in order\nto check that they are valid, too.\n\n  cat la_proiel-ud-train.conllu | validate.py --lang la_proiel\n\n\n\n==============================\ncheck_sentence_ids.pl\n==============================\n\nReads CoNLL-U files from STDIN and verifies that every sentence has a unique id in the sent_id comment. All files of\none treebank (repository) must be supplied at once in order to test treebank-wide id uniqueness.\n\n  cat *.conllu | perl check_sentence_ids.pl\n\n\n\n==============================\nconllu-stats.py\nconllu-stats.pl\n==============================\n\nReads a CoNLL-U file, collects various statistics and prints them. These two scripts, one in Python and the other in\nPerl, are independent of each other. The statistics they collect overlap but are not the same. The Perl script\n(conllu-stats.pl) was used to generate the stats.xml files in each data repository.\n\n\n\n==============================\nmwtoken-stats.pl\n==============================\n\nReads a CoNLL-U file, collects statistics of multi-word tokens and prints them.\n\n  cat *.conllu | perl mwtoken-stats.pl \u003e mwtoken-stats.txt\n\n\n\n==============================\noverlap.py\n==============================\n\nCompares two CoNLL-U files and searches for sentences that occur in both (verbose duplicates of token sequences). Some\ntreebanks, especially those where the original text had been acquired from the web, contained duplicate documents that\nwere found at different addresses and downloaded twice. This tool helps to find out whether one of the duplicates fell\nin the training data and the other in development or test. The output has to be verified manually, as some “duplicates”\nare repetitions that occur naturally in the language (in particular short sentences such as “Thank you.”)\n\nThe script can also help to figure out whether training-dev-test data split has been changed between two releases so\nthat a previously training sentence is now in test or vice versa. That is something we want to avoid.\n\n\n\n==============================\nfind_duplicate_sentences.pl\nremove_duplicate_sentences.pl\n==============================\n\nSimilar to overlap.py but it works with the sentence-level\nattribute “text”. It remembers all sentences from STDIN or from\ninput files whose names are given as arguments. The find script\nprints the duplicate sentences (ordered by length and number of\noccurrences) to STDOUT. The remove script works as a filter: it\nprints the CoNLL-U data from the input, except for the second and\nany subsequent occurrence of the duplicate sentences.\n\n\n\n==============================\nconllu_to_conllx.pl\n==============================\n\nConverts a file in the CoNLL-U format to the old CoNLL-X format. Useful with old tools (e.g. parsers) that require\nCoNLL-X as their input. Usage:\n\n  perl conllu_to_conllx.pl \u003c file.conllu \u003e file.conll\n\n\n\n==============================\nrestore_conllu_lines.pl\n==============================\n\nMerges a CoNLL-X and a CoNLL-U file, taking only the CoNLL-U-specific lines from CoNLL-U. Can be used to merge the\noutput of an old parser that only works with CoNLL-X with the original annotation that the parser could not read.\n\n  restore_conllu_lines.pl file-parsed.conll file.conllu\n\n\n\n==============================\nconllu_to_text.pl\n==============================\n\nConverts a file in the CoNLL-U format to plain text, word-wrapped to lines of 80 characters (but the output line will\nbe longer if there is a word that is longer than the limit). The script can use either the sentence-level text\nattribute, or the word forms plus the SpaceAfter=No MISC attribute to output detokenized text. It also observes the\nsentence-level newdoc and newpar attributes, and the NewPar=Yes MISC attribute, if they are present, and prints an\nempty line between paragraphs or documents.\n\nOptionally, the script takes the language code as a parameter. Codes 'zh' and 'ja' will trigger a different\nword-wrapping algorithm that is more suitable for Chinese and Japanese.\n\nUsage:\n\n  perl conllu_to_text.pl --lang zh \u003c file.conllu \u003e file.txt\n\n\n\n==============================\nconll_convert_tags_to_uposf.pl\n==============================\n\nThis script takes the CoNLL columns CPOS, POS and FEAT and converts their combined values to the universal POS tag and\nfeatures.\n\nYou need Perl. On Linux, you probably already have it; on Windows, you may have to download and install Strawberry Perl.\nYou also need the Interset libraries. Once you have Perl, it is easy to get them via the following (call \"cpan\" instead\nof \"cpanm\" if you do not have cpanm).\n\n  cpanm Lingua::Interset\n\nThen use the script like this:\n\n  perl conll_convert_tags_to_uposf.pl -f source_tagset \u003c input.conll \u003e output.conll\n\nThe source tagset is the identifier of the tagset used in your data and known to Interset. Typically it is the language\ncode followed by two colons and \"conll\", e.g. \"sl::conll\" for the Slovenian data of CoNLL 2006. See the tagset conversion\ntables at http://universaldependencies.github.io/docs/tagset-conversion/index.html for more tagset codes.\n\nIMPORTANT:\nThe script assumes the CoNLL-X (2006 and 2007) file format. If your data is in another format (most notably CoNLL-U, but\nalso e.g. CoNLL 2008/2009, which is not identical to 2006/2007), you have to modify the data or the script. Furthermore,\nyou have to know something about the tagset driver (-f source_tagset above) you are going to use. Some drivers do not\nexpect to receive three values joined by TAB characters. Some expect two values and many expect just a single tag,\nperhaps the one you have in your POS column. These factors may also require you to adapt the script to your needs. You\nmay want to consult the documentation at https://metacpan.org/pod/Lingua::Interset. Go to Browse / Interset / Tagset,\nlook up your language code and tagset name, then locate the list() function in the source code. That will give you an\nidea of what the input tags should look like (usually the driver is able to decode even some tags that are not on the\nlist but have the same structure and feature values).\n\n\n\n==============================\ncheck_files.pl\n==============================\n\nThis script must be run in a folder where all the data repositories (UD_*) are stored as subfolders. It checks the\ncontents of the data repositories for various issues that we want to solve before a new release of UD is published.\n","remote_repo_id":19850189,"sha":"e8d215c6ec09b96346b5ce0ca0621cad79ecf248","size":6779}
,{"name":"Awesome-pytorch-list","owner":"bharathgs","path":"README.md","readme":"Awesome-Pytorch-list\n========================\n\n![pytorch-logo-dark](https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png)\n\n\u003cp align=\"center\"\u003e\n\t\u003cimg src=\"https://img.shields.io/badge/stars-1100+-brightgreen.svg?style=flat\"/\u003e\n\t\u003cimg src=\"https://img.shields.io/badge/forks-170+-brightgreen.svg?style=flat\"/\u003e\n\t\u003cimg src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\"\u003e\n\u003c/p\u003e\n\n## Pytorch \u0026 related libraries\n\n1. [pytorch](http://pytorch.org ) : Tensors and Dynamic neural networks in Python with strong GPU acceleration.\n\n### NLP \u0026 Speech Processing:\n\n1. [pytorch text](https://github.com/pytorch/text) : Torch text related contents.  \n2. [pytorch-seq2seq](https://github.com/IBM/pytorch-seq2seq): A framework for sequence-to-sequence (seq2seq) models implemented in PyTorch.  \n3. [anuvada](https://github.com/Sandeep42/anuvada): Interpretable Models for NLP using PyTorch.\n4. [audio](https://github.com/pytorch/audio): simple audio I/O for pytorch.\n5. [loop](https://github.com/facebookresearch/loop): A method to generate speech across multiple speakers\n6. [fairseq-py](https://github.com/facebookresearch/fairseq-py): Facebook AI Research Sequence-to-Sequence Toolkit written in Python.\n7. [speech](https://github.com/awni/speech): PyTorch ASR Implementation.\n8. [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py): Open-Source Neural Machine Translation in PyTorch http://opennmt.net \n9. [neuralcoref](https://github.com/huggingface/neuralcoref): State-of-the-art coreference resolution based on neural nets and spaCy huggingface.co/coref\n10. [sentiment-discovery](https://github.com/NVIDIA/sentiment-discovery): Unsupervised Language Modeling at scale for robust sentiment classification.\n11. [MUSE](https://github.com/facebookresearch/MUSE): A library for Multilingual Unsupervised or Supervised word Embeddings\n12. [nmtpytorch](https://github.com/lium-lst/nmtpytorch): Neural Machine Translation Framework in PyTorch.\n13. [pytorch-wavenet](https://github.com/vincentherrmann/pytorch-wavenet): An implementation of WaveNet with fast generation\n14. [Tacotron-pytorch](https://github.com/soobinseo/Tacotron-pytorch): Tacotron: Towards End-to-End Speech Synthesis\n\n### CV:\n\n1. [pytorch vision](https://github.com/pytorch/vision) : Datasets, Transforms and Models specific to Computer Vision.\n2. [pt-styletransfer](https://github.com/tymokvo/pt-styletransfer): Neural style transfer as a class in PyTorch.\n3. [OpenFacePytorch](https://github.com/thnkim/OpenFacePytorch):  PyTorch module to use OpenFace's nn4.small2.v1.t7 model\n4. [img_classification_pk_pytorch](https://github.com/felixgwu/img_classification_pk_pytorch): Quickly comparing your image classification models with the state-of-the-art models (such as DenseNet, ResNet, ...)\n5. [SparseConvNet](https://github.com/facebookresearch/SparseConvNet): Submanifold sparse convolutional networks.\n6. [Convolution_LSTM_pytorch](https://github.com/automan000/Convolution_LSTM_pytorch): A multi-layer convolution LSTM module\n7. [face-alignment](https://github.com/1adrianb/face-alignment): :fire: 2D and 3D Face alignment library build using pytorch adrianbulat.com\n8. [pytorch-semantic-segmentation](https://github.com/ZijunDeng/pytorch-semantic-segmentation): PyTorch for Semantic Segmentation.\n9. [RoIAlign.pytorch](https://github.com/longcw/RoIAlign.pytorch): This is a PyTorch version of RoIAlign. This implementation is based on crop_and_resize and supports both forward and backward on CPU and GPU.\n\n### Probabilistic/Generative Libraries:\n\n1. [ptstat](https://github.com/stepelu/ptstat): Probabilistic Programming and Statistical Inference in PyTorch\n2. [pyro](https://github.com/uber/pyro): Deep universal probabilistic programming with Python and PyTorch http://pyro.ai\n3. [probtorch](https://github.com/probtorch/probtorch): Probabilistic Torch is library for deep generative models that extends PyTorch.\n4. [paysage](https://github.com/drckf/paysage): Unsupervised learning and generative models in python/pytorch.\n\n### Other libraries:\n\n1. [pytorch extras](https://github.com/mrdrozdov/pytorch-extras) : Some extra features for pytorch.    \n2. [functional zoo](https://github.com/szagoruyko/functional-zoo) : PyTorch, unlike lua torch, has autograd in it's core, so using modular structure of torch.nn modules is not necessary, one can easily allocate needed Variables and write a function that utilizes them, which is sometimes more convenient. This repo contains model definitions in this functional way, with pretrained weights for some models. \n3. [torch-sampling](https://github.com/ncullen93/torchsample) : This package provides a set of transforms and data structures for sampling from in-memory or out-of-memory data. \n4. [torchcraft-py](https://github.com/deepcraft/torchcraft-py) : Python wrapper for TorchCraft, a bridge between Torch and StarCraft for AI research.\n5. [aorun](https://github.com/ramon-oliveira/aorun) : Aorun intend to be a Keras with PyTorch as backend. \n6. [logger](https://github.com/oval-group/logger) : A simple logger for experiments.\n7. [PyTorch-docset](https://github.com/iamaziz/PyTorch-docset) : PyTorch docset! use with Dash, Zeal, Velocity, or LovelyDocs.  \n8. [convert_torch_to_pytorch](https://github.com/clcarwin/convert_torch_to_pytorch) : Convert torch t7 model to pytorch model and source.\n9. [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch): The goal of this repo is to help to reproduce research papers results.  \n10. [pytorch_fft](https://github.com/locuslab/pytorch_fft) : PyTorch wrapper for FFTs\n11. [caffe_to_torch_to_pytorch](https://github.com/fanq15/caffe_to_torch_to_pytorch)\n12. [pytorch-extension](https://github.com/sniklaus/pytorch-extension): This is a CUDA extension for PyTorch which computes the Hadamard product of two tensors.\n13. [tensorboard-pytorch](https://github.com/lanpa/tensorboard-pytorch): This module saves PyTorch tensors in tensorboard format for inspection. Currently supports scalar, image, audio, histogram features in tensorboard.\n14. [gpytorch](https://github.com/jrg365/gpytorch): GPyTorch is a Gaussian Process library, implemented using PyTorch. It is designed for creating flexible and modular Gaussian Process models with ease, so that you don't have to be an expert to use GPs.\n15. [spotlight](https://github.com/maciejkula/spotlight): Deep recommender models using PyTorch.\n16. [pytorch-cns](https://github.com/awentzonline/pytorch-cns): Compressed Network Search with PyTorch\n17. [pyinn](https://github.com/szagoruyko/pyinn): CuPy fused PyTorch neural networks ops\n18. [inferno](https://github.com/nasimrahaman/inferno): A utility library around PyTorch\n19. [pytorch-fitmodule](https://github.com/henryre/pytorch-fitmodule): Super simple fit method for PyTorch modules\n20. [inferno-sklearn](https://github.com/dnouri/inferno): A scikit-learn compatible neural network library that wraps pytorch.\n21. [pytorch-caffe-darknet-convert](https://github.com/marvis/pytorch-caffe-darknet-convert): convert between pytorch, caffe prototxt/weights and darknet cfg/weights\n22. [pytorch2caffe](https://github.com/longcw/pytorch2caffe): Convert PyTorch model to Caffemodel\n23. [pytorch-tools](https://github.com/nearai/pytorch-tools): Tools for PyTorch\n24. [sru](https://github.com/taolei87/sru): Training RNNs as Fast as CNNs (arxiv.org/abs/1709.02755)\n25. [torch2coreml](https://github.com/prisma-ai/torch2coreml): Torch7 -\u003e CoreML\n26. [PyTorch-Encoding](https://github.com/zhanghang1989/PyTorch-Encoding): PyTorch Deep Texture Encoding Network http://hangzh.com/PyTorch-Encoding\n27. [pytorch-ctc](https://github.com/ryanleary/pytorch-ctc): PyTorch-CTC is an implementation of CTC (Connectionist Temporal Classification) beam search decoding for PyTorch. C++ code borrowed liberally from TensorFlow with some improvements to increase flexibility.\n28. [candlegp](https://github.com/t-vi/candlegp): Gaussian Processes in Pytorch. \n29. [dpwa](https://github.com/loudinthecloud/dpwa): Distributed Learning by Pair-Wise Averaging. \n30. [dni-pytorch](https://github.com/koz4k/dni-pytorch): Decoupled Neural Interfaces using Synthetic Gradients for PyTorch.\n31. [skorch](https://github.com/dnouri/skorch): A scikit-learn compatible neural network library that wraps pytorch\n32. [ignite](https://github.com/pytorch/ignite): Ignite is a high-level library to help with training neural networks in PyTorch.\n33. [Arnold](https://github.com/glample/Arnold): Arnold - DOOM Agent\n34. [pytorch-mcn](https://github.com/albanie/pytorch-mcn): Convert models from MatConvNet to PyTorch\n35. [simple-faster-rcnn-pytorch](https://github.com/chenyuntc/simple-faster-rcnn-pytorch): A simplified implemention of Faster R-CNN with competitive performance.\n36. [generative_zoo](https://github.com/DL-IT/generative_zoo): generative_zoo is a repository that provides working implementations of some generative models in PyTorch.\n\n\n## Tutorials \u0026 examples\n\n1. **[Practical Pytorch](https://github.com/spro/practical-pytorch)** : Tutorials explaining different RNN models\n2. [DeepLearningForNLPInPytorch](https://github.com/rguthrie3/DeepLearningForNLPInPytorch) : An IPython Notebook tutorial on deep learning, with an emphasis on Natural Language Processing. \n3. [pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) : tutorial for researchers to learn deep learning with pytorch.\n4.  [pytorch-exercises](https://github.com/keon/pytorch-exercises) : pytorch-exercises collection. \n5.  [pytorch tutorials](https://github.com/pytorch/tutorials) : Various pytorch tutorials. \n6.  [pytorch examples](https://github.com/pytorch/examples) :  A repository showcasing examples of using pytorch \n7. [pytorch practice](https://github.com/napsternxg/pytorch-practice) : Some example scripts on pytorch.  \n8.  [pytorch mini tutorials](https://github.com/vinhkhuc/PyTorch-Mini-Tutorials) :  Minimal tutorials for PyTorch adapted from Alec Radford's Theano tutorials. \n9.  [pytorch text classification](https://github.com/xiayandi/Pytorch_text_classification) : A simple implementation of CNN based text classification in Pytorch \n10. [cats vs dogs](https://github.com/desimone/pytorch-cat-vs-dogs) : Example of network fine-tuning in pytorch for the kaggle competition Dogs vs. Cats Redux: Kernels Edition. Currently #27 (0.05074) on the leaderboard.  \n11. [convnet](https://github.com/eladhoffer/convNet.pytorch) : This is a complete training example for Deep Convolutional Networks on various datasets (ImageNet, Cifar10, Cifar100, MNIST).\n12. [pytorch-generative-adversarial-networks](https://github.com/mailmahee/pytorch-generative-adversarial-networks) : simple generative adversarial network (GAN) using PyTorch.   \n13. [pytorch containers](https://github.com/amdegroot/pytorch-containers) : This repository aims to help former Torchies more seamlessly transition to the \"Containerless\" world of PyTorch by providing a list of PyTorch implementations of Torch Table Layers.  \n14. [T-SNE in pytorch](https://github.com/cemoody/topicsne) : t-SNE experiments in pytorch \n15. [AAE_pytorch](https://github.com/fducau/AAE_pytorch) : Adversarial Autoencoders (with Pytorch). \n16. [Kind_PyTorch_Tutorial](https://github.com/GunhoChoi/Kind_PyTorch_Tutorial): Kind PyTorch Tutorial for beginners.  \n17.  [pytorch-poetry-gen](https://github.com/justdark/pytorch-poetry-gen): a char-RNN based on pytorch.  \n18. [pytorch-REINFORCE](https://github.com/JamesChuanggg/pytorch-REINFORCE): PyTorch implementation of REINFORCE, This repo supports both continuous and discrete environments in OpenAI gym.\n19.  **[PyTorch-Tutorial](https://github.com/MorvanZhou/PyTorch-Tutorial)**: Build your neural network easy and fast  https://morvanzhou.github.io/tutorials/ \n20. [pytorch-intro](https://github.com/joansj/pytorch-intro): A couple of scripts to illustrate how to do CNNs and RNNs in PyTorch\n21. [pytorch-classification](https://github.com/bearpaw/pytorch-classification): A unified framework for the image classification task on CIFAR-10/100 and ImageNet.\n22. [pytorch_notebooks - hardmaru](https://github.com/hardmaru/pytorch_notebooks): Random tutorials created in NumPy and PyTorch.\n23. [pytorch_tutoria-quick](https://github.com/soravux/pytorch_tutorial): Quick PyTorch introduction and tutorial. Targets computer vision, graphics and machine learning researchers eager to try a new framework.  \n24. [Pytorch_fine_tuning_Tutorial](https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial): A short tutorial on performing fine tuning or transfer learning in PyTorch.\n25. [pytorch_exercises](https://github.com/Kyubyong/pytorch_exercises): pytorch-exercises \n26. [traffic-sign-detection](https://github.com/soumith/traffic-sign-detection-homework): nyu-cv-fall-2017 example\n27. [mss_pytorch](https://github.com/Js-Mim/mss_pytorch): Singing Voice Separation via Recurrent Inference and Skip-Filtering Connections - PyTorch Implementation. Demo: js-mim.github.io/mss_pytorch\n28. [DeepNLP-models-Pytorch](https://github.com/DSKSD/DeepNLP-models-Pytorch) Pytorch implementations of various Deep NLP models in cs-224n(Stanford Univ: NLP with Deep Learning)\n29. [Mila introductory tutorials](https://github.com/mila-udem/welcome_tutorials): Various tutorials given for welcoming new students at MILA.\n30. [pytorch.rl.learning](https://github.com/moskomule/pytorch.rl.learning): for learning reinforcement learning using PyTorch.\n31. [minimal-seq2seq](https://github.com/keon/seq2seq): Minimal Seq2Seq model with Attention for Neural Machine Translation in PyTorch\n32. [tensorly-notebooks](https://github.com/JeanKossaifi/tensorly-notebooks): Tensor methods in Python with TensorLy tensorly.github.io/dev\n33. [pytorch_bits](https://github.com/jpeg729/pytorch_bits): time-series prediction related examples.\n34. [skip-thoughts](https://github.com/sanyam5/skip-thoughts): An implementation of Skip-Thought Vectors in PyTorch.\n35. [video-caption-pytorch](https://github.com/xiadingZ/video-caption-pytorch): pytorch code for video captioning. \n36. [Capsule-Network-Tutorial](https://github.com/higgsfield/Capsule-Network-Tutorial): Pytorch easy-to-follow Capsule Network tutorial\n\n\n## Paper implementations\n\n1. [google_evolution](https://github.com/neuralix/google_evolution) : This implements one of result networks from Large-scale evolution of image classifiers by Esteban Real, et. al. \n2. [pyscatwave](https://github.com/edouardoyallon/pyscatwave) : Fast Scattering Transform with CuPy/PyTorch,read the paper [here](https://arxiv.org/abs/1703.08961)\n3. [scalingscattering](https://github.com/edouardoyallon/scalingscattering) : Scaling The Scattering Transform : Deep Hybrid Networks.  \n4. [deep-auto-punctuation](https://github.com/episodeyang/deep-auto-punctuation) : a pytorch implementation of auto-punctuation learned character by character.  \n5. [Realtime_Multi-Person_Pose_Estimation](https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation) : This is a pytorch version of Realtime_Multi-Person_Pose_Estimation, origin code is [here](https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation) .\n6. [PyTorch-value-iteration-networks](https://github.com/onlytailei/PyTorch-value-iteration-networks) : PyTorch implementation of the Value Iteration Networks (NIPS '16) paper  \n7. [pytorch_Highway](https://github.com/analvikingur/pytorch_Highway) : Highway network implemented in pytorch.\n8. [pytorch_NEG_loss](https://github.com/analvikingur/pytorch_NEG_loss) : NEG loss implemented in pytorch.  \n9. [pytorch_RVAE](https://github.com/analvikingur/pytorch_RVAE) : Recurrent Variational Autoencoder that generates sequential data implemented in pytorch.   \n10. [pytorch_TDNN](https://github.com/analvikingur/pytorch_TDNN) : Time Delayed NN implemented in pytorch.  \n11. [eve.pytorch](https://github.com/moskomule/eve.pytorch) : An implementation of Eve Optimizer, proposed in Imploving Stochastic Gradient Descent with Feedback, Koushik and Hayashi, 2016.  \n12. [e2e-model-learning](https://github.com/locuslab/e2e-model-learning) : Task-based end-to-end model learning.  \n13. [pix2pix-pytorch](https://github.com/mrzhu-cool/pix2pix-pytorch) : PyTorch implementation of \"Image-to-Image Translation Using Conditional Adversarial Networks\".   \n14. [Single Shot MultiBox Detector](https://github.com/amdegroot/ssd.pytorch) : A PyTorch Implementation of Single Shot MultiBox Detector.  \n15. [DiscoGAN](https://github.com/carpedm20/DiscoGAN-pytorch): PyTorch implementation of \"Learning to Discover Cross-Domain Relations with Generative Adversarial Networks\"  \n16. [official DiscoGAN implementation](https://github.com/SKTBrain/DiscoGAN) : Official implementation of \"Learning to Discover Cross-Domain Relations with Generative Adversarial Networks\".  \n17. [pytorch-es](https://github.com/atgambardella/pytorch-es) : This is a PyTorch implementation of [Evolution Strategies](https://arxiv.org/abs/1703.03864) .  \n18. [piwise](https://github.com/bodokaiser/piwise) : Pixel-wise segmentation on VOC2012 dataset using pytorch.  \n19. [pytorch-dqn](https://github.com/transedward/pytorch-dqn) : Deep Q-Learning Network in pytorch.  \n20. [neuraltalk2-pytorch](https://github.com/ruotianluo/neuraltalk2.pytorch) : image captioning model in pytorch(finetunable cnn in branch with_finetune)\n21. [vnet.pytorch](https://github.com/mattmacy/vnet.pytorch) : A Pytorch implementation for V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation.    \n22. [pytorch-fcn](https://github.com/wkentaro/pytorch-fcn) : PyTorch implementation of Fully Convolutional Networks.  \n23. [WideResNets](https://github.com/xternalz/WideResNet-pytorch) : WideResNets for CIFAR10/100 implemented in PyTorch. This implementation requires less GPU memory than what is required by the official Torch implementation: https://github.com/szagoruyko/wide-residual-networks .\n24. [pytorch_highway_networks](https://github.com/c0nn3r/pytorch_highway_networks) : Highway networks implemented in PyTorch.  \n25. [pytorch-NeuCom](https://github.com/ypxie/pytorch-NeuCom) : Pytorch implementation of DeepMind's differentiable neural computer paper.  \n26. [captionGen](https://github.com/eladhoffer/captionGen) : Generate captions for an image using PyTorch.  \n27. [AnimeGAN](https://github.com/jayleicn/animeGAN) : A simple PyTorch Implementation of Generative Adversarial Networks, focusing on anime face drawing. \n28. [Cnn-text classification](https://github.com/Shawn1993/cnn-text-classification-pytorch) : This is the implementation of Kim's Convolutional Neural Networks for Sentence Classification paper in PyTorch.  \n29. [deepspeech2](https://github.com/SeanNaren/deepspeech.pytorch) : Implementation of DeepSpeech2 using Baidu Warp-CTC. Creates a network based on the DeepSpeech2 architecture, trained with the CTC activation function.\n30. [seq2seq](https://github.com/MaximumEntropy/Seq2Seq-PyTorch) : This repository contains implementations of Sequence to Sequence (Seq2Seq) models in PyTorch  \n31. [Asynchronous Advantage Actor-Critic in PyTorch](https://github.com/rarilurelo/pytorch_a3c) : This is PyTorch implementation of A3C as described in Asynchronous Methods for Deep Reinforcement Learning. Since PyTorch has a easy method to control shared memory within multiprocess, we can easily implement asynchronous method like A3C.    \n32. [densenet](https://github.com/bamos/densenet.pytorch) : This is a PyTorch implementation of the DenseNet-BC architecture as described in the paper Densely Connected Convolutional Networks by G. Huang, Z. Liu, K. Weinberger, and L. van der Maaten. This implementation gets a CIFAR-10+ error rate of 4.77 with a 100-layer DenseNet-BC with a growth rate of 12. Their official implementation and links to many other third-party implementations are available in the liuzhuang13/DenseNet repo on GitHub.  \n33. [nninit](https://github.com/alykhantejani/nninit) : Weight initialization schemes for PyTorch nn.Modules. This is a port of the popular nninit for Torch7 by @kaixhin.  \n34. [faster rcnn](https://github.com/longcw/faster_rcnn_pytorch) : This is a PyTorch implementation of Faster RCNN. This project is mainly based on py-faster-rcnn and TFFRCNN.For details about R-CNN please refer to the paper Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks by Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. \n35. [doomnet](https://github.com/akolishchak/doom-net-pytorch) : PyTorch's version of Doom-net implementing some RL models in ViZDoom environment.  \n36. [flownet](https://github.com/ClementPinard/FlowNetPytorch) : Pytorch implementation of FlowNet by Dosovitskiy et al.  \n37. [sqeezenet](https://github.com/gsp-27/pytorch_Squeezenet) : Implementation of Squeezenet in pytorch, #### pretrained models on CIFAR10 data to come Plan to train the model on cifar 10 and add block connections too.  \n38. [WassersteinGAN](https://github.com/martinarjovsky/WassersteinGAN): wassersteinGAN in pytorch. \n39. [optnet](https://github.com/locuslab/optnet) : This repository is by Brandon Amos and J. Zico Kolter and contains the PyTorch source code to reproduce the experiments in our paper OptNet: Differentiable Optimization as a Layer in Neural Networks.  \n40. [qp solver](https://github.com/locuslab/qpth) : A fast and differentiable QP solver for PyTorch. Crafted by Brandon Amos and J. Zico Kolter.  \n41. [Continuous Deep Q-Learning with Model-based Acceleration ](https://github.com/ikostrikov/pytorch-naf) : Reimplementation of Continuous Deep Q-Learning with Model-based Acceleration.  \n42. [Learning to learn by gradient descent by gradient descent](https://github.com/ikostrikov/pytorch-meta-optimizer) : PyTorch implementation of Learning to learn by gradient descent by gradient descent.\n43. [fast-neural-style](https://github.com/darkstar112358/fast-neural-style) : pytorch implementation of fast-neural-style, The model uses the method described in [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155) along with Instance Normalization.\n44. [PytorchNeuralStyleTransfer](https://github.com/leongatys/PytorchNeuralStyleTransfer) : Implementation of Neural Style Transfer in Pytorch. \n45. [Fast Neural Style for Image Style Transform by Pytorch](https://github.com/bengxy/FastNeuralStyle) : Fast Neural Style for Image Style Transform by Pytorch .\n46. [neural style transfer](https://github.com/alexis-jacq/Pytorch-Tutorials) : An introduction to PyTorch through the Neural-Style algorithm (https://arxiv.org/abs/1508.06576) developed by Leon A. Gatys, Alexander S. Ecker and Matthias Bethge.   \n47. [VIN_PyTorch_Visdom](https://github.com/zuoxingdong/VIN_PyTorch_Visdom) : PyTorch implementation of Value Iteration Networks (VIN): Clean, Simple and Modular. Visualization in Visdom.  \n48. [YOLO2](https://github.com/longcw/yolo2-pytorch): YOLOv2 in PyTorch.   \n49. [attention-transfer](https://github.com/szagoruyko/attention-transfer): Attention transfer in pytorch, read the paper [here](https://arxiv.org/abs/1612.03928).  \n50. [SVHNClassifier](https://github.com/potterhsu/SVHNClassifier-PyTorch): A PyTorch implementation of [Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks](https://arxiv.org/pdf/1312.6082.pdf).  \n51. [pytorch-deform-conv](https://github.com/oeway/pytorch-deform-conv): PyTorch implementation of Deformable Convolution.  \n52. [BEGAN-pytorch](https://github.com/carpedm20/BEGAN-pytorch): PyTorch implementation of [BEGAN](https://arxiv.org/abs/1703.10717): Boundary Equilibrium Generative Adversarial Networks.  \n53. [treelstm.pytorch](https://github.com/dasguptar/treelstm.pytorch) : Tree LSTM implementation in PyTorch.\n54. [AGE](https://github.com/DmitryUlyanov/AGE): Code for paper \"Adversarial Generator-Encoder Networks\" by Dmitry Ulyanov, Andrea Vedaldi and Victor Lempitsky which can be found [here](http://sites.skoltech.ru/app/data/uploads/sites/25/2017/04/AGE.pdf) \n55. [ResNeXt.pytorch](https://github.com/prlz77/ResNeXt.pytorch): Reproduces ResNet-V3 (Aggregated Residual Transformations for Deep Neural Networks) with pytorch.\n56. [pytorch-rl](https://github.com/jingweiz/pytorch-rl): Deep Reinforcement Learning with pytorch \u0026 visdom  \n57. [Deep-Leafsnap](https://github.com/sujithv28/Deep-Leafsnap): LeafSnap replicated using deep neural networks to test accuracy compared to traditional computer vision methods.  \n58. [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix): PyTorch implementation for both unpaired and paired image-to-image translation.\n59. [A3C-PyTorch](https://github.com/onlytailei/A3C-PyTorch):PyTorch implementation of Advantage async actor-critic Algorithms (A3C) in PyTorch\n60. [pytorch-value-iteration-networks](https://github.com/kentsommer/pytorch-value-iteration-networks) : Pytorch implementation of Value Iteration Networks (NIPS 2016 best paper)  \n61. [PyTorch-Style-Transfer](https://github.com/zhanghang1989/PyTorch-Style-Transfer): PyTorch Implementation of Multi-style Generative Network for Real-time Transfer\n62. [pytorch-deeplab-resnet](https://github.com/isht7/pytorch-deeplab-resnet): pytorch-deeplab-resnet-model.\n63. [pointnet.pytorch](https://github.com/fxia22/pointnet.pytorch): pytorch implementation for \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" https://arxiv.org/abs/1612.00593  \n64. **[pytorch-playground](https://github.com/aaron-xichen/pytorch-playground): Base pretrained models and datasets in pytorch (MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)**.\n65. [pytorch-dnc](https://github.com/jingweiz/pytorch-dnc): Neural Turing Machine (NTM) \u0026 Differentiable Neural Computer (DNC) with pytorch \u0026 visdom. \n66. [pytorch_image_classifier](https://github.com/jinfagang/pytorch_image_classifier): Minimal But Practical Image Classifier Pipline Using Pytorch, Finetune on ResNet18, Got 99% Accuracy on Own Small Datasets.  \n67. [mnist-svhn-transfer](https://github.com/yunjey/mnist-svhn-transfer): PyTorch Implementation of CycleGAN and SGAN for Domain Transfer (Minimal).\n68. [pytorch-yolo2](https://github.com/marvis/pytorch-yolo2): pytorch-yolo2\n69. [dni](https://github.com/andrewliao11/dni.pytorch): Implement Decoupled Neural Interfaces using Synthetic Gradients in Pytorch\n70. [wgan-gp](https://github.com/caogang/wgan-gp): A pytorch implementation of Paper \"Improved Training of Wasserstein GANs\".\n71. [pytorch-seq2seq-intent-parsing](https://github.com/spro/pytorch-seq2seq-intent-parsing): Intent parsing and slot filling in PyTorch with seq2seq + attention\n72. [pyTorch_NCE](https://github.com/demelin/pyTorch_NCE): An implementation of the Noise Contrastive Estimation algorithm for pyTorch. Working, yet not very efficient.\n73. [molencoder](https://github.com/cxhernandez/molencoder): Molecular AutoEncoder in PyTorch\n74. [GAN-weight-norm](https://github.com/stormraiser/GAN-weight-norm): Code for \"On the Effects of Batch and Weight Normalization in Generative Adversarial Networks\"\n75. [lgamma](https://github.com/rachtsingh/lgamma): Implementations of polygamma, lgamma, and beta functions for PyTorch\n76. [bigBatch](https://github.com/eladhoffer/bigBatch) : Code used to generate the results appearing in \"Train longer, generalize better: closing the generalization gap in large batch training of neural networks\" \n77. [rl_a3c_pytorch](https://github.com/dgriff777/rl_a3c_pytorch): Reinforcement learning with implementation of A3C LSTM for Atari 2600. \n78. [pytorch-retraining](https://github.com/ahirner/pytorch-retraining): Transfer Learning Shootout for PyTorch's model zoo (torchvision)\n79. [nmp_qc](https://github.com/priba/nmp_qc): Neural Message Passing for Computer Vision\n80. [grad-cam](https://github.com/jacobgil/pytorch-grad-cam): Pytorch implementation of Grad-CAM\n81. [pytorch-trpo](https://github.com/mjacar/pytorch-trpo): PyTorch Implementation of Trust Region Policy Optimization (TRPO)\n82. [pytorch-explain-black-box](https://github.com/jacobgil/pytorch-explain-black-box): PyTorch implementation of Interpretable Explanations of Black Boxes by Meaningful Perturbation\n83. [vae_vpflows](https://github.com/jmtomczak/vae_vpflows): Code in PyTorch for the convex combination linear IAF and the Householder Flow, J.M. Tomczak \u0026 M. Welling https://jmtomczak.github.io/deebmed.html \n84. [relational-networks](https://github.com/kimhc6028/relational-networks): Pytorch implementation of \"A simple neural network module for relational reasoning\" (Relational Networks) https://arxiv.org/pdf/1706.01427.pdf\n85. [vqa.pytorch](https://github.com/Cadene/vqa.pytorch): Visual Question Answering in Pytorch\n86. [end-to-end-negotiator](https://github.com/facebookresearch/end-to-end-negotiator): Deal or No Deal? End-to-End Learning for Negotiation Dialogues\n87. [odin-pytorch](https://github.com/ShiyuLiang/odin-pytorch): Principled Detection of Out-of-Distribution Examples in Neural Networks. \n88. [FreezeOut](https://github.com/ajbrock/FreezeOut): Accelerate Neural Net Training by Progressively Freezing Layers. \n89. [ARAE](https://github.com/jakezhaojb/ARAE): Code for the paper \"Adversarially Regularized Autoencoders for Generating Discrete Structures\" by Zhao, Kim, Zhang, Rush and LeCun.\n90. [forward-thinking-pytorch](https://github.com/kimhc6028/forward-thinking-pytorch): Pytorch implementation of \"Forward Thinking: Building and Training Neural Networks One Layer at a Time\" https://arxiv.org/pdf/1706.02480.pdf  \n91. [context_encoder_pytorch](https://github.com/BoyuanJiang/context_encoder_pytorch): PyTorch Implement of Context Encoders\n92. [attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch): A PyTorch implementation of the Transformer model in \"Attention is All You Need\".https://github.com/thnkim/OpenFacePytorch\n93. [OpenFacePytorch](https://github.com/thnkim/OpenFacePytorch): PyTorch module to use OpenFace's nn4.small2.v1.t7 model \n94. [neural-combinatorial-rl-pytorch](https://github.com/pemami4911/neural-combinatorial-rl-pytorch):  PyTorch implementation of Neural Combinatorial Optimization with Reinforcement Learning.\n95.[pytorch-nec](https://github.com/mjacar/pytorch-nec): PyTorch Implementation of Neural Episodic Control (NEC)\n96. [seq2seq.pytorch](https://github.com/eladhoffer/seq2seq.pytorch): Sequence-to-Sequence learning using PyTorch\n97. [Pytorch-Sketch-RNN](https://github.com/alexis-jacq/Pytorch-Sketch-RNN): a pytorch implementation of arxiv.org/abs/1704.03477\n98. [pytorch-pruning](https://github.com/jacobgil/pytorch-pruning): PyTorch Implementation of [1611.06440] Pruning Convolutional Neural Networks for Resource Efficient Inference\n99. [DrQA](https://github.com/hitvoice/DrQA) : A pytorch implementation of Reading Wikipedia to Answer Open-Domain Questions.\n100. [YellowFin_Pytorch](https://github.com/JianGoForIt/YellowFin_Pytorch) : auto-tuning momentum SGD optimizer\n101. [samplernn-pytorch](https://github.com/deepsound-project/samplernn-pytorch) : PyTorch implementation of SampleRNN: An Unconditional End-to-End Neural Audio Generation Model. \n102. [AEGeAN](https://github.com/tymokvo/AEGeAN): Deeper DCGAN with AE stabilization\n103. [/pytorch-SRResNet](https://github.com/twtygqyy/pytorch-SRResNet): pytorch implementation for Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network arXiv:1609.04802v2 \n104. [vsepp](https://github.com/fartashf/vsepp): Code for the paper \"VSE++: Improved Visual Semantic Embeddings\"\n105. [Pytorch-DPPO](https://github.com/alexis-jacq/Pytorch-DPPO): Pytorch implementation of Distributed Proximal Policy Optimization: arxiv.org/abs/1707.02286\n106. [UNIT](https://github.com/mingyuliutw/UNIT): PyTorch Implementation of our Coupled VAE-GAN algorithm for Unsupervised Image-to-Image Translation\n107. [efficient_densenet_pytorch](https://github.com/gpleiss/efficient_densenet_pytorch): A memory-efficient implementation of DenseNets\n108. [tsn-pytorch](https://github.com/yjxiong/tsn-pytorch): Temporal Segment Networks (TSN) in PyTorch.\n109. [SMASH](https://github.com/ajbrock/SMASH): An experimental technique for efficiently exploring neural architectures.\n110. [pytorch-retinanet](https://github.com/kuangliu/pytorch-retinanet): RetinaNet in PyTorch\n111. [biogans](https://github.com/aosokin/biogans):  Implementation supporting the ICCV 2017 paper \"GANs for Biological Image Synthesis\". \n112. [Semantic Image Synthesis via Adversarial Learning]( https://github.com/woozzu/dong_iccv_2017): A PyTorch implementation of the paper \"Semantic Image Synthesis via Adversarial Learning\" in ICCV 2017. \n113. [fmpytorch](https://github.com/jmhessel/fmpytorch): A PyTorch implementation of a Factorization Machine module in cython.\n114. [ORN](https://github.com/ZhouYanzhao/ORN): A PyTorch implementation of the paper \"Oriented Response Networks\" in CVPR 2017. \n115. [pytorch-maml](https://github.com/katerakelly/pytorch-maml): PyTorch implementation of MAML: arxiv.org/abs/1703.03400\n116. [pytorch-generative-model-collections](https://github.com/znxlwm/pytorch-generative-model-collections):  Collection of generative models in Pytorch version.\n117. [vqa-winner-cvprw-2017](https://github.com/markdtw/vqa-winner-cvprw-2017): Pytorch Implementation of winner from VQA Chllange Workshop in CVPR'17. \n118. [tacotron_pytorch](https://github.com/r9y9/tacotron_pytorch) :  PyTorch implementation of Tacotron speech synthesis model. \n119. [pspnet-pytorch](https://github.com/Lextal/pspnet-pytorch): PyTorch implementation of PSPNet segmentation network\n120. [LM-LSTM-CRF](https://github.com/LiyuanLucasLiu/LM-LSTM-CRF): Empower Sequence Labeling with Task-Aware Language Model http://arxiv.org/abs/1709.04109\n121. [face-alignment](https://github.com/1adrianb/face-alignment): Pytorch implementation of the paper \"How far are we from solving the 2D \u0026 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)\", ICCV 2017\n122. [DepthNet](https://github.com/ClementPinard/DepthNet): PyTorch DepthNet Training on Still Box dataset. \n123. [EDSR-PyTorch](https://github.com/thstkdgus35/EDSR-PyTorch): PyTorch version of the paper 'Enhanced Deep Residual Networks for Single Image Super-Resolution' (CVPRW 2017)\n124. [e2c-pytorch](https://github.com/ethanluoyc/e2c-pytorch): Embed to Control implementation in PyTorch.\n125. [3D-ResNets-PyTorch](https://github.com/kenshohara/3D-ResNets-PyTorch): 3D ResNets for Action Recognition.\n126. [bandit-nmt](https://github.com/khanhptnk/bandit-nmt): This is code repo for our EMNLP 2017 paper \"Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback\", which implements the A2C algorithm on top of a neural encoder-decoder model and benchmarks the combination under simulated noisy rewards.\n127. [pytorch-a2c-ppo-acktr](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr): PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO) and Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR).\n128. [zalando-pytorch](https://github.com/baldassarreFe/zalando-pytorch): Various experiments on the \n[Fashion-MNIST](zalandoresearch/fashion-mnist) dataset from Zalando.\n129. [sphereface_pytorch](https://github.com/clcarwin/sphereface_pytorch): A PyTorch Implementation of SphereFace.\n130. [Categorical DQN](https://github.com/floringogianu/categorical-dqn): A PyTorch Implementation of Categorical DQN from [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887).\n131. [pytorch-ntm](https://github.com/loudinthecloud/pytorch-ntm): pytorch ntm implementation. \n132. [mask_rcnn_pytorch](https://github.com/felixgwu/mask_rcnn_pytorch): Mask RCNN in PyTorch.\n133. [graph_convnets_pytorch](https://github.com/xbresson/graph_convnets_pytorch): PyTorch implementation of graph ConvNets, NIPS’16\n134. [pytorch-faster-rcnn](https://github.com/ruotianluo/pytorch-faster-rcnn): A pytorch implementation of faster RCNN detection framework based on Xinlei Chen's tf-faster-rcnn.\n135. [torchMoji](https://github.com/huggingface/torchMoji): A pyTorch implementation of the DeepMoji model: state-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc.\n136. [semantic-segmentation-pytorch](https://github.com/hangzhaomit/semantic-segmentation-pytorch): Pytorch implementation for Semantic Segmentation/Scene Parsing on [MIT ADE20K dataset](http://sceneparsing.csail.mit.edu)\n137. [pytorch-qrnn](https://github.com/salesforce/pytorch-qrnn): PyTorch implementation of the Quasi-Recurrent Neural Network - up to 16 times faster than NVIDIA's cuDNN LSTM\n138. [pytorch-sgns](https://github.com/theeluwin/pytorch-sgns): Skipgram Negative Sampling in PyTorch.\n139. [SfmLearner-Pytorch ](https://github.com/ClementPinard/SfmLearner-Pytorch): Pytorch version of SfmLearner from Tinghui Zhou et al.\n140. [deformable-convolution-pytorch](https://github.com/1zb/deformable-convolution-pytorch): PyTorch implementation of Deformable Convolution. \n141. [skip-gram-pytorch](https://github.com/fanglanting/skip-gram-pytorch): A complete pytorch implementation of skipgram model (with subsampling and negative sampling). The embedding result is tested with Spearman's rank correlation.\n142. [stackGAN-v2](https://github.com/hanzhanggit/StackGAN-v2): Pytorch implementation for reproducing StackGAN_v2 results in the paper StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks by Han Zhang*, Tao Xu*, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, Dimitris Metaxas.\n143. [self-critical.pytorch](https://github.com/ruotianluo/self-critical.pytorch): Unofficial pytorch implementation for Self-critical Sequence Training for Image Captioning. \n144. [pygcn](https://github.com/tkipf/pygcn): Graph Convolutional Networks in PyTorch.\n145. [dnc](https://github.com/ixaxaar/pytorch-dnc): Differentiable Neural Computers, for Pytorch\n146. [prog_gans_pytorch_inference](https://github.com/ptrblck/prog_gans_pytorch_inference): PyTorch inference for \"Progressive Growing of GANs\" with CelebA snapshot.\n147. [pytorch-capsule](https://github.com/timomernick/pytorch-capsule): Pytorch implementation of Hinton's Dynamic Routing Between Capsules.\n148. [PyramidNet-PyTorch](https://github.com/dyhan0920/PyramidNet-PyTorch): A PyTorch implementation for PyramidNets (Deep Pyramidal Residual Networks, arxiv.org/abs/1610.02915)\n149. [radio-transformer-networks](https://github.com/gram-ai/radio-transformer-networks): A PyTorch implementation of Radio Transformer Networks from the paper \"An Introduction to Deep Learning for the Physical Layer\". arxiv.org/abs/1702.00832\n150. [honk](https://github.com/castorini/honk): PyTorch reimplementation of Google's TensorFlow CNNs for keyword spotting.\n151. [DeepCORAL](https://github.com/SSARCandy/DeepCORAL): A PyTorch implementation of 'Deep CORAL: Correlation Alignment for Deep Domain Adaptation.', ECCV 2016\n152. [pytorch-pose](https://github.com/bearpaw/pytorch-pose): A PyTorch toolkit for 2D Human Pose Estimation.\n153. [lang-emerge-parlai](https://github.com/karandesai-96/lang-emerge-parlai): Implementation of EMNLP 2017 Paper \"Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog\" using PyTorch and ParlAI\n154. [Rainbow](https://github.com/Kaixhin/Rainbow): Rainbow: Combining Improvements in Deep Reinforcement Learning \n155. [pytorch_compact_bilinear_pooling v1](https://github.com/gdlg/pytorch_compact_bilinear_pooling): This repository has a pure Python implementation of Compact Bilinear Pooling and Count Sketch for PyTorch.\n156. [CompactBilinearPooling-Pytorch v2](https://github.com/DeepInsight-PCALab/CompactBilinearPooling-Pytorch): (Yang Gao, et al.) A Pytorch Implementation for Compact Bilinear Pooling.\n157. [FewShotLearning](https://github.com/gitabcworld/FewShotLearning): Pytorch implementation of the paper \"Optimization as a Model for Few-Shot Learning\"\n158. [meProp](https://github.com/jklj077/meProp): Codes for \"meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting\".\n159. [SFD_pytorch](https://github.com/clcarwin/SFD_pytorch): A PyTorch Implementation of Single Shot Scale-invariant Face Detector.\n160. [GradientEpisodicMemory](https://github.com/facebookresearch/GradientEpisodicMemory): Continuum Learning with GEM: Gradient Episodic Memory. https://arxiv.org/abs/1706.08840\n161. [DeblurGAN](https://github.com/KupynOrest/DeblurGAN): Pytorch implementation of the paper DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks.\n162. [StarGAN](https://github.com/yunjey/StarGAN): StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Tranlsation.\n163. [CapsNet-pytorch](https://github.com/adambielski/CapsNet-pytorch): PyTorch implementation of NIPS 2017 paper Dynamic Routing Between Capsules.\n164. [CondenseNet](https://github.com/ShichenLiu/CondenseNet): CondenseNet: An Efficient DenseNet using Learned Group Convolutions.\n165. [deep-image-prior](https://github.com/DmitryUlyanov/deep-image-prior): Image restoration with neural networks but without learning.\n166. [deep-head-pose](https://github.com/natanielruiz/deep-head-pose): Deep Learning Head Pose Estimation using PyTorch.\n167. [Random-Erasing](https://github.com/zhunzhong07/Random-Erasing): This code has the source code for the paper \"Random Erasing Data Augmentation\".\n168. [FaderNetworks](https://github.com/facebookresearch/FaderNetworks): Fader Networks: Manipulating Images by Sliding Attributes - NIPS 2017\n169. [FlowNet 2.0](https://github.com/NVIDIA/flownet2-pytorch): FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\n170. [pix2pixHD](https://github.com/NVIDIA/pix2pixHD): Synthesizing and manipulating 2048x1024 images with conditional GANs tcwang0509.github.io/pix2pixHD \n171. [pytorch-smoothgrad](https://github.com/pkdn/pytorch-smoothgrad): SmoothGrad implementation in PyTorch\n172. [RetinaNet](https://github.com/c0nn3r/RetinaNet): An implementation of RetinaNet in PyTorch.\n173. [faster-rcnn.pytorch](https://github.com/jwyang/faster-rcnn.pytorch): This project is a faster faster R-CNN implementation, aimed to accelerating the training of faster R-CNN object detection models. \n174. [mixup_pytorch](https://github.com/leehomyc/mixup_pytorch): A PyTorch implementation of the paper Mixup: Beyond Empirical Risk Minimization in PyTorch.\n175. [inplace_abn](https://github.com/mapillary/inplace_abn): In-Place Activated BatchNorm for Memory-Optimized Training of DNNs\n176. [pytorch-pose-hg-3d](https://github.com/xingyizhou/pytorch-pose-hg-3d): PyTorch implementation for 3D human pose estimation\n177. [nmn-pytorch](https://github.com/HarshTrivedi/nmn-pytorch): Neural Module Network for VQA in Pytorch.\n178. [bytenet](https://github.com/kefirski/bytenet): Pytorch implementation of bytenet from \"Neural Machine Translation in Linear Time\" paper\n179. [bottom-up-attention-vqa](https://github.com/hengyuan-hu/bottom-up-attention-vqa): vqa, bottom-up-attention, pytorch\n180. [yolo2-pytorch](https://github.com/ruiminshen/yolo2-pytorch): The YOLOv2 is one of the most popular one-stage object detector. This project adopts PyTorch as the developing framework to increase productivity, and utilize ONNX to convert models into Caffe 2 to benifit engineering deployment.\n181. [reseg-pytorch](https://github.com/Wizaron/reseg-pytorch): PyTorch Implementation of ReSeg (arxiv.org/pdf/1511.07053.pdf)\n182. [binary-stochastic-neurons](https://github.com/Wizaron/binary-stochastic-neurons): Binary Stochastic Neurons in PyTorch.\n183. [pytorch-pose-estimation](https://github.com/DavexPro/pytorch-pose-estimation): PyTorch Implementation of Realtime Multi-Person Pose Estimation project.\n184. [interaction_network_pytorch](https://github.com/higgsfield/interaction_network_pytorch): Pytorch Implementation of Interaction Networks for Learning about Objects, Relations and Physics.\n185. [NoisyNaturalGradient](https://github.com/wlwkgus/NoisyNaturalGradient): Pytorch Implementation of paper \"Noisy Natural Gradient as Variational Inference\". \n186. [ewc.pytorch](https://github.com/moskomule/ewc.pytorch): An implementation of Elastic Weight Consolidation (EWC), proposed in James Kirkpatrick et al. Overcoming catastrophic forgetting in neural networks 2016(10.1073/pnas.1611835114).\n187. [pytorch-zssr](https://github.com/jacobgil/pytorch-zssr): PyTorch implementation of 1712.06087 \"Zero-Shot\" Super-Resolution using Deep Internal Learning\n188. [deep_image_prior](https://github.com/atiyo/deep_image_prior): An implementation of image reconstruction methods from Deep Image Prior (Ulyanov et al., 2017) in PyTorch.\n189. [pytorch-transformer](https://github.com/leviswind/pytorch-transformer): pytorch implementation of Attention is all you need.\n190. [DeepRL-Grounding](https://github.com/devendrachaplot/DeepRL-Grounding): This is a PyTorch implementation of the AAAI-18 paper Gated-Attention Architectures for Task-Oriented Language Grounding\n191. [deep-forecast-pytorch](https://github.com/Wizaron/deep-forecast-pytorch): Wind Speed Prediction using LSTMs in PyTorch (arxiv.org/pdf/1707.08110.pdf)\n\n## Blogs \u0026 Articles\n\n1. [Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)](https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f)\n2. [adversarial-autoencoders-with-pytorch](https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/)\n3. [transfer learning using pytorch](https://medium.com/@vishnuvig/transfer-learning-using-pytorch-4c3475f4495)\n\n\n## Pytorch elsewhere\n\n1. **[the-incredible-pytorch](https://github.com/ritchieng/the-incredible-pytorch)** : The Incredible PyTorch: a curated list of tutorials, papers, projects, communities and more relating to PyTorch. \n2. [generative models](https://github.com/wiseodd/generative-models) : Collection of generative models, e.g. GAN, VAE in Tensorflow, Keras, and Pytorch. http://wiseodd.github.io  \n3. [pytorch vs tensorflow](https://www.reddit.com/r/MachineLearning/comments/5w3q74/d_so_pytorch_vs_tensorflow_whats_the_verdict_on/) : an informative thread on reddit. \n4. [Pytorch discussion forum](https://discuss.pytorch.org/)  \n5. [pytorch notebook: docker-stack](https://hub.docker.com/r/escong/pytorch-notebook/) : A project similar to [Jupyter Notebook Scientific Python Stack](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook)\n6. [drawlikebobross](https://github.com/kendricktan/drawlikebobross): Draw like Bob Ross using the power of Neural Networks (With PyTorch)!\n7. [pytorch-tvmisc](https://github.com/t-vi/pytorch-tvmisc): Totally Versatile Miscellanea for Pytorch\n8. [pytorch-a3c-mujoco](https://github.com/andrewliao11/pytorch-a3c-mujoco): Implement A3C for Mujoco gym envs.\n9. [PyTorch in 5 Minutes](https://www.youtube.com/watch?v=nbJ-2G2GXL0\u0026list=WL\u0026index=9).\n10. [pytorch_chatbot](https://github.com/jinfagang/pytorch_chatbot): A Marvelous ChatBot implemented using PyTorch.\n11. [malmo-challenge](https://github.com/Kaixhin/malmo-challenge): Malmo Collaborative AI Challenge - Team Pig Catcher\n12. [sketchnet](https://github.com/jtoy/sketchnet): A model that takes an image and generates Processing source code to regenerate that image\n13. [Deep-Learning-Boot-Camp](https://github.com/QuantScientist/Deep-Learning-Boot-Camp): A nonprofit community run, 5-day Deep Learning Bootcamp http://deep-ml.com. \n14. [Amazon_Forest_Computer_Vision](https://github.com/mratsim/Amazon_Forest_Computer_Vision): Satellite Image tagging code using PyTorch / Keras with lots of PyTorch tricks. kaggle competition.\n\n\n##### Feedback: If you have any ideas or you want any other content to be added to this list, feel free to contribute.\n","remote_repo_id":83579167,"sha":"7219ac622e165c95a7a3bf381cedb50b768c9c37","size":47840}
,{"name":"integration-config","owner":"wikimedia","path":"README.md","readme":"# Wikimedia configuration for Jenkins\n\nThis repository holds the configuration of the Wikimedia Foundation Inc. Jenkins\njobs. It is meant to be used with a python script written by the OpenStack\nFoundation: Jenkins Job Builder.\n\nWhen you tweak or add jobs, follow the documentation maintained on mediawiki.org:\n\n  https://www.mediawiki.org/wiki/CI/JJB\n\nFor more about the Jenkins Job Builder software and how to use it, refer to the upstream documentation:\n\n  http://ci.openstack.org/jenkins-job-builder/\n\n## Example Usage\n\nGenerate XML files for Jenkins jobs from YAML files:\n\n    $ jenkins-jobs test config/jjb/ -o output/\n\nUpdate Jenkins jobs which name starts with \"selenium\":\n\n    $ jenkins-jobs --conf etc/jenkins_jobs.ini update config/jjb/ selenium*\n\n## Running tests\n\nTo test the configuration, we use tox and you need at least version 1.9+ ([bug T125705](https://phabricator.wikimedia.org/T125705))\nto run the test suite. Running `tox` in the main dir of your local clone runs the tests.\n","remote_repo_id":24098803,"sha":"fb9a052465b709aabc2d26fd42b216ab6782c42c","size":998}
,{"name":"corert","owner":"dotnet","path":"README.md","readme":"# .NET Core Runtime (CoreRT)\nThis repo contains the .NET Core runtime optimized for AOT compilation\n\n## Platform Support\n\nThis is a work in progress. The current state of platform support:\n- Windows, MacOS and Linux x64 w/ RyuJIT codegen: Simple apps. Check our [ASP.NET Core](samples/WebApi/) and [MonoGame](samples/MonoGame/) samples.\n- Linux ARM w/ RyuJIT codegen: ElmSharp Hello Tizen application ([detailed status](https://github.com/dotnet/corert/issues/4856))\n- CppCodeGen (targets all platforms that support C++): Simple C# programs. The big missing features are [reflection](https://github.com/dotnet/corert/issues/2035), [garbage collection](https://github.com/dotnet/corert/issues/2033) and [exception handling](https://github.com/dotnet/corert/issues/910).\n- WebAssembly: Early prototype that compiles and runs very trivial programs only. Many features are [not yet implemented](https://github.com/dotnet/corert/issues?q=is%3Aissue+is%3Aopen+label%3Aarch-wasm).\n\n## How to Engage, Contribute and Provide Feedback\nSome of the best ways to contribute are to try things out, file bugs, and join in design conversations.\n\nLooking for something to work on? The [_up for grabs_](https://github.com/dotnet/corert/labels/up-for-grabs) issues are a great place to start or take a look at our [documentation](Documentation).\n\nThis project follows the [.NET Core Contribution Guidelines](https://github.com/dotnet/coreclr/blob/master/Documentation/project-docs/contributing.md).\n\n[![Join the chat at https://gitter.im/dotnet/corert](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/dotnet/corert?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge\u0026utm_content=badge)\n\n### Reporting security issues and security bugs\n\nSecurity issues and bugs should be reported privately, via email, to the\nMicrosoft Security Response Center (MSRC) \u003csecure@microsoft.com\u003e. You should\nreceive a response within 24 hours. If for some reason you do not, please follow\nup via email to ensure we received your original message. Further information,\nincluding the MSRC PGP key, can be found in the\n[Security TechCenter](https://technet.microsoft.com/en-us/security/ff852094.aspx).\n\n## License\nThe CoreRT Repo is licensed under the [MIT license](https://github.com/dotnet/corert/blob/master/LICENSE.TXT).\n\n## .NET Foundation\nCoreRT is a [.NET Foundation](http://www.dotnetfoundation.org/projects) project.\n\nThis project has adopted the code of conduct defined by the [Contributor Covenant](http://contributor-covenant.org/) to clarify expected behavior in our community. For more information, see the [.NET Foundation Code of Conduct](http://www.dotnetfoundation.org/code-of-conduct).\n\n## Related Projects\nThere are many .NET related projects on GitHub.\n- The [.NET home repo](https://github.com/Microsoft/dotnet) links to 100s of .NET projects, from Microsoft and the community.\n- The [ASP.NET home repo](https://github.com/aspnet/home) is the best place to start learning about [ASP.NET Core](http://www.asp.net).\n\n## Build Status\n\n|         |Ubuntu 14.04 |Windows |Mac OS X |\n|---------|:------:|:------:|:------:|\n|**Debug**|[![Build status](https://ci.dot.net/job/dotnet_corert/job/master/job/debug_ubuntu/badge/icon)](https://ci.dot.net/job/dotnet_corert/job/master/job/debug_ubuntu/)|[![Build status](https://ci.dot.net/job/dotnet_corert/job/master/job/debug_windows_nt/badge/icon)](https://ci.dot.net/job/dotnet_corert/job/master/job/debug_windows_nt/)|[![Build Status](https://ci.dot.net/job/dotnet_corert/job/master/job/debug_osx10.12/badge/icon)](https://ci.dot.net/job/dotnet_corert/job/master/job/debug_osx10.12/)|\n|**Release**|[![Build status](https://ci.dot.net/job/dotnet_corert/job/master/job/release_ubuntu/badge/icon)](https://ci.dot.net/job/dotnet_corert/job/master/job/release_ubuntu/)|[![Build status](https://ci.dot.net/job/dotnet_corert/job/master/job/release_windows_nt/badge/icon)](https://ci.dot.net/job/dotnet_corert/job/master/job/release_windows_nt/)|[![Build Status](https://ci.dot.net/job/dotnet_corert/job/master/job/release_osx10.12/badge/icon)](https://ci.dot.net/job/dotnet_corert/job/master/job/release_osx10.12/)|\n","remote_repo_id":42552143,"sha":"e5bc3366ffdcacda6eab586554c983c0050a499f","size":4145}
,{"name":"protoactor-go","owner":"AsynkronIT","path":"README.md","readme":"[![Go Report Card](https://goreportcard.com/badge/github.com/AsynkronIT/protoactor-go)](https://goreportcard.com/report/github.com/AsynkronIT/protoactor-go) \n[![GoDoc](https://godoc.org/github.com/AsynkronIT/protoactor-go?status.svg)](https://godoc.org/github.com/AsynkronIT/protoactor-go)\n[![Build Status](https://travis-ci.org/AsynkronIT/protoactor-go.svg?branch=dev)](https://travis-ci.org/AsynkronIT/protoactor-go)\n[![Coverage Status](https://coveralls.io/repos/github/AsynkronIT/protoactor-go/badge.svg?branch=dev)](https://coveralls.io/github/AsynkronIT/protoactor-go?branch=dev)\n[![Sourcegraph](https://sourcegraph.com/github.com/AsynkronIT/protoactor-go/-/badge.svg)](https://sourcegraph.com/github.com/AsynkronIT/protoactor-go?badge)\n\n[![Join the chat at https://gitter.im/AsynkronIT/protoactor](https://badges.gitter.im/AsynkronIT/protoactor.svg)](https://gitter.im/AsynkronIT/protoactor?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge\u0026utm_content=badge)\n\n# Cross platform actors\n\nIntroducing cross platform actor support between Go and C#.\n\nCan I use this?\nThe Go implementation is still in beta, there are users using Proto Actor for Go in production already.\nBut be aware that the API might change over time until 1.0.\n\n## Sourcecode - Go\nThis is the Go repository for Proto Actor.\n\nThe C# implementation can be found here [https://github.com/AsynkronIT/protoactor-dotnet](https://github.com/AsynkronIT/protoactor-dotnet)\n\n## Design principles:\n\n**Minimalistic API** -\nThe API should be small and easy to use.\nAvoid enterprisey JVM like containers and configurations.\n\n**Build on existing technologies** - There are already a lot of great tech for e.g. networking and clustering, build on those.\ne.g. gRPC streams for networking, Consul.IO for clustering.\n\n**Pass data, not objects** - Serialization is an explicit concern, don't try to hide it.\nProtobuf all the way.\n\n**Be fast** - Do not trade performance for magic API trickery.\n\nUltra fast remoting, Proto Actor currently manages to pass over **two million messages per second** between nodes using only two actors, while still preserving message order!\nThis is six times more the new super advanced UDP based Artery transport for Scala Akka, and 30 times faster than Akka.NET.\n\n```text\n:\u003e node1.exe\n2016/12/02 14:30:09 50000\n2016/12/02 14:30:09 100000\n2016/12/02 14:30:09 150000\n... snip ...\n2016/12/02 14:30:09 900000\n2016/12/02 14:30:09 950000\n2016/12/02 14:30:10 1000000\n2016/12/02 14:30:10 Elapsed 999.9985ms\n2016/12/02 14:30:10 Msg per sec 2000003 \u003c--\n```\n\n## History\n\nAs the creator of the Akka.NET project, I have come to some distinct conclusions while being involved in that project.\nIn Akka.NET we created our own thread pool, our own networking layer, our own serialization support, our own configuration support etc. etc.\nThis was all fun and challenging, it is however now my firm opinion that this is the wrong way to go about things.\n\n**If possible, software should be composed, not built**, only add code to glue existing pieces together.\nThis yields a much better time to market, and allows us to focus on solving the actual problem at hand, in this case concurrency and distributed programming.\n\nProto Actor builds on existing technologies, Protobuf for serialization, gRPC streams for network transport.\nThis ensures cross platform compatibility, network protocol version tolerance and battle proven stability.\n\nAnother extremely important factor here is business agility and having an exit strategy.\nBy being cross platform, your organization is no longer tied into a specific platform, if you are migrating from .NET to Go, \nThis can be done while still allowing actor based services to communicate between platforms.\n\nReinvent by not reinventing.\n\n---\n\n## Why Actors\n\n![batman](/resources/batman.jpg)\n\n* Decoupled Concurrency\n* Distributed by default\n* Fault tolerance\n\nFor a more indepth description of the differences, see this thread [Actors vs. CSP](https://www.quora.com/Go-programming-language-How-are-Akka-actors-are-different-than-Goroutines-and-Channels)\n\n## Building\n\nYou need to ensure that your `$GOPATH` variable is properly set.\n\nNext, install the [standard protocol buffer implementation](https://github.com/google/protobuf) and run the following commands to get all the necessary tooling:\n\n```\ngo get github.com/AsynkronIT/protoactor-go/...\ncd $GOPATH/src/github.com/AsynkronIT/protoactor-go\ngo get ./...\nmake\n```\n\nAfter invoking last command you will have generated protobuf definitions and built the project.\n\nWindows users can use Cygwin to run make: [www.cygwin.com](https://www.cygwin.com/)\n\n## Testing\n\nThis command exectutes all tests in the repository except for consul integration tests (you need consul for running those tests). We also skip directories that don't contain any tests.\n\n```\ngo test `go list ./... | grep -v consul` | grep 'no test files'\n```\n\nIf everything is ok, you will get the output:\n\n```\nok  \tgithub.com/AsynkronIT/protoactor-go/actor\t0.115s\nok  \tgithub.com/AsynkronIT/protoactor-go/eventstream\t0.020s\nok  \tgithub.com/AsynkronIT/protoactor-go/internal/queue/goring\t2.524s\nok  \tgithub.com/AsynkronIT/protoactor-go/internal/queue/mpsc\t2.385s\nok  \tgithub.com/AsynkronIT/protoactor-go/log\t0.017s\nok  \tgithub.com/AsynkronIT/protoactor-go/mailbox\t2.742s\nok  \tgithub.com/AsynkronIT/protoactor-go/plugin\t1.227s\nok  \tgithub.com/AsynkronIT/protoactor-go/router\t1.836s\nok  \tgithub.com/AsynkronIT/protoactor-go/stream\t0.017s\n```\n\n## Hello world\n\n```go\ntype Hello struct{ Who string }\ntype HelloActor struct{}\n\nfunc (state *HelloActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case Hello:\n        fmt.Printf(\"Hello %v\\n\", msg.Who)\n    }\n}\n\nfunc main() {\n    props := actor.FromProducer(func() actor.Actor { return \u0026HelloActor{} })\n    pid := actor.Spawn(props)\n    pid.Tell(Hello{Who: \"Roger\"})\n    console.ReadLine()\n}\n```\n\n## State machines / SetBehavior, PushBehavior and PopBehavior\n\n```go\ntype Hello struct{ Who string }\ntype SetBehaviorActor struct{}\n\nfunc (state *SetBehaviorActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case Hello:\n        fmt.Printf(\"Hello %v\\n\", msg.Who)\n        context.SetBehavior(state.Other)\n    }\n}\n\nfunc (state *SetBehaviorActor) Other(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case Hello:\n        fmt.Printf(\"%v, ey we are now handling messages in another behavior\", msg.Who)\n    }\n}\n\nfunc NewSetBehaviorActor() actor.Actor {\n    return \u0026SetBehaviorActor{}\n}\n\nfunc main() {\n    props := actor.FromProducer(NewSetBehaviorActor)\n    pid := actor.Spawn(props)\n    pid.Tell(Hello{Who: \"Roger\"})\n    pid.Tell(Hello{Who: \"Roger\"})\n    console.ReadLine()\n}\n```\n\n## Lifecycle events\n\nUnlike Akka, Proto Actor uses messages for lifecycle events instead of OOP method overrides\n\n```go\ntype Hello struct{ Who string }\ntype HelloActor struct{}\n\nfunc (state *HelloActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case *actor.Started:\n        fmt.Println(\"Started, initialize actor here\")\n    case *actor.Stopping:\n        fmt.Println(\"Stopping, actor is about shut down\")\n    case *actor.Stopped:\n        fmt.Println(\"Stopped, actor and its children are stopped\")\n    case *actor.Restarting:\n        fmt.Println(\"Restarting, actor is about restart\")\n    case Hello:\n        fmt.Printf(\"Hello %v\\n\", msg.Who)\n    }\n}\n\nfunc main() {\n    props := actor.FromProducer(func() actor.Actor { return \u0026HelloActor{} })\n    pid := actor.Spawn(props)\n    actor.Tell(pid, Hello{Who: \"Roger\"})\n\n    //why wait?\n    //Stop is a system message and is not processed through the user message mailbox\n    //thus, it will be handled _before_ any user message\n    //we only do this to show the correct order of events in the console\n    time.Sleep(1 * time.Second)\n    pid.Stop()\n\n    console.ReadLine()\n}\n```\n\n## Supervision\n\nRoot actors are supervised by the `actor.DefaultSupervisionStrategy()`, which always issues a `actor.RestartDirective` for failing actors\nChild actors are supervised by their parents.\nParents can customize their child supervisor strategy using `Proto Actor.Props`\n\n### Example\n\n```go\ntype Hello struct{ Who string }\ntype ParentActor struct{}\n\nfunc (state *ParentActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case Hello:\n        props := actor.FromProducer(NewChildActor)\n        child := context.Spawn(props)\n        child.Tell(msg)\n    }\n}\n\nfunc NewParentActor() actor.Actor {\n    return \u0026ParentActor{}\n}\n\ntype ChildActor struct{}\n\nfunc (state *ChildActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case *actor.Started:\n        fmt.Println(\"Starting, initialize actor here\")\n    case *actor.Stopping:\n        fmt.Println(\"Stopping, actor is about shut down\")\n    case *actor.Stopped:\n        fmt.Println(\"Stopped, actor and its children are stopped\")\n    case *actor.Restarting:\n        fmt.Println(\"Restarting, actor is about restart\")\n    case Hello:\n        fmt.Printf(\"Hello %v\\n\", msg.Who)\n        panic(\"Ouch\")\n    }\n}\n\nfunc NewChildActor() actor.Actor {\n    return \u0026ChildActor{}\n}\n\nfunc main() {\n    decider := func(reason interface{}) actor.Directive {\n        fmt.Println(\"handling failure for child\")\n        return actor.StopDirective\n    }\n    supervisor := actor.NewOneForOneStrategy(10, 1000, decider)\n    props := actor.\n        FromProducer(NewParentActor).\n        WithSupervisor(supervisor)\n\n    pid := actor.Spawn(props)\n    pid.Tell(Hello{Who: \"Roger\"})\n\n    console.ReadLine()\n}\n```\n\n## Networking / Remoting\n\nProto Actor's networking layer is built as a thin wrapper ontop of gRPC and message serialization is built on Protocol Buffers\u003cbr/\u003e\n\n### Example\n\n#### Node 1\n\n```go\ntype MyActor struct{\n    count int\n}\n\nfunc (state *MyActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case *messages.Response:\n        state.count++\n        fmt.Println(state.count)\n    }\n}\n\nfunc main() {\n    remote.Start(\"localhost:8090\")\n\n    pid := actor.SpawnTemplate(\u0026MyActor{})\n    message := \u0026messages.Echo{Message: \"hej\", Sender: pid}\n\n    //this is the remote actor we want to communicate with\n    remote := actor.NewPID(\"localhost:8091\", \"myactor\")\n    for i := 0; i \u003c 10; i++ {\n        remote.Tell(message)\n    }\n\n    console.ReadLine()\n}\n```\n\n#### Node 2\n\n```go\ntype MyActor struct{}\n\nfunc (*MyActor) Receive(context actor.Context) {\n    switch msg := context.Message().(type) {\n    case *messages.Echo:\n        msg.Sender.Tell(\u0026messages.Response{\n            SomeValue: \"result\",\n        })\n    }\n}\n\nfunc main() {\n    remote.Start(\"localhost:8091\")\n\n    //register a name for our local actor so that it can be discovered remotely\n    remote.Register(\"hello\", actor.FromProducer(func() actor.Actor { return \u0026MyActor{} }))\n    console.ReadLine()\n}\n```\n\n### Message Contracts\n\n```proto\nsyntax = \"proto3\";\npackage messages;\nimport \"actor.proto\"; //we need to import actor.proto, so our messages can include PID's\n\n//this is the message the actor on node 1 will send to the remote actor on node 2\nmessage Echo {\n  actor.PID Sender = 1; //this is the PID the remote actor should reply to\n  string Message = 2;\n}\n\n//this is the message the remote actor should reply with\nmessage Response {\n  string SomeValue = 1;\n}\n```\n\nFor more examples, see the example folder in this repository.\n\n### Support\n\nMany thanks to [JetBrains](https://www.jetbrains.com) for support!\n","remote_repo_id":56453473,"sha":"7b70a7cc33dc30e3227bd34b5ef618d6a8832225","size":11504}
,{"name":"gradle","owner":"gradle","path":"README.md","readme":"\u003cimg src=\"gradle.png\" width=\"350px\" alt=\"Gradle Logo\" /\u003e\n\nGradle is a build tool with a focus on build automation and support for multi-language development. If you are building, testing, publishing, and deploying software on any platform, Gradle offers a flexible model that can support the entire development lifecycle from compiling and packaging code to publishing web sites. Gradle has been designed to support build automation across multiple languages and platforms including Java, Scala, Android, C/C++, and Groovy, and is closely integrated with development tools and continuous integration servers including Eclipse, IntelliJ, and Jenkins.\n\nFor more information about Gradle, please visit: https://gradle.org\n\nThis project adheres to the [Gradle Code of Conduct](https://gradle.org/conduct/). By participating, you are expected to uphold this code.\n\n## Downloading\n\nYou can download released versions and nightly build artifacts from: https://gradle.org/downloads\n\n### Installing from source\n\nTo create an install from the source tree you can run either of the following:\n\n    ./gradlew install -Pgradle_installPath=/usr/local/gradle-source-build\n\nThis will create a minimal installation; just what's needed to run Gradle (i.e. no docs).\n\nYou can then build a Gradle based project with this installation:\n\n    /usr/local/gradle-source-build/bin/gradle «some task»\n\nTo create a full installation (includes docs):\n\n    ./gradlew installAll -Pgradle_installPath=/usr/local/gradle-source-build\n\n## Contributing\n\nIf you're looking to contribute to Gradle or provide a patch/pull request, you can find more info [here](https://github.com/gradle/gradle/blob/master/.github/CONTRIBUTING.md).\n","remote_repo_id":302322,"sha":"41d9adefb464de9b95a5ef7a19dd4a3b47bc2fdd","size":1696}
,{"name":"data-profiler","owner":"giagiannis","path":"README.md","readme":"data-profiler [![Build Status](https://travis-ci.org/giagiannis/data-profiler.svg?branch=master)](https://travis-ci.org/giagiannis/data-profiler) [![goreport](https://goreportcard.com/badge/github.com/giagiannis/data-profiler)](https://goreportcard.com/report/github.com/giagiannis/data-profiler) [![Coverage Status](https://coveralls.io/repos/github/giagiannis/data-profiler/badge.svg?branch=master)](https://coveralls.io/github/giagiannis/data-profiler?branch=master) [![Docker Automated build](https://img.shields.io/docker/automated/jrottenberg/ffmpeg.svg)](https://hub.docker.com/r/ggian/data-profiler/)\n=============\n__data-profiler__ is a Go project used to transform a set of datasets, based on a set of characteristics (distribution similarity, correlation, etc.), in order to model the behavior of an operator, applied on top of them using Machine Learning techniques.\n\n\nScreenshots\n-----------\n\n![Similarity Matrix](https://github.com/giagiannis/data-profiler/raw/master/_imgs/SM.png \"Dataset Similarity Matrix\")\n\n![Dataset Space](https://github.com/giagiannis/data-profiler/raw/master/_imgs/DS.png \"Dataset Space\")\n\n![SVM Modeling](https://github.com/giagiannis/data-profiler/raw/master/_imgs/SVMModeling.png \"Operator Modeling with SVM\")\n\n![SVM Residuals Distribution](https://github.com/giagiannis/data-profiler/raw/master/_imgs/ResidualDistribution.png \"SVM Residual Distribution\")\n\nInstallation\n------------\nYou have two ways of installing __data-profiler__:\n\n1. Through Go:\n\n```bash\n# GOPATH must be set\n~\u003e go get github.com/giagiannis/data-profiler\n```\n\n2. Using Docker:\n\n```bash\n~\u003e docker pull ggian/data-profiler\n```\n\nUsage\n-----\n__data-profiler__ can be used both through a CLI and a Web interface.\n\n1. CLI \n\nYou can access the CLI client through the __data-profiler-utils__ binary.\n\n```bash\n~\u003e $GOPATH/bin/data-profiler-utils\n```\n\nThis previous command will give an overview of the available actions.\n\n__Note:__ use this client only if you know how data-profiler works.\n\n2. Web UI\n\nFirst run the Docker container, providing a directory with the dataset files. \n\n```bash\n~\u003e docker run -v /src/datasets:/datasets -p 8080:8080 -d ggian/data-profiler\n```\n\nThis command mounts the host's _/src/datasets_ directory to the container and forwards the host's 8080 port to the container. After the successful start of the container, go to _http://dockerhost:8080_ and insert the first set of datasets for analysis.\n\n\nLicense\n-------\nApache License v2.0 (see [LICENSE](LICENSE) file for more)\n\n\nContact\n-------\nGiannis Giannakopoulos ggian@cslab.ece.ntua.gr\n","remote_repo_id":60160548,"sha":"d8073973fc28cd1d4ed8fe979cf88041ac5da987","size":2569}
,{"name":"cartographer","owner":"googlecartographer","path":"README.rst","readme":".. Copyright 2016 The Cartographer Authors\n\n.. Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n..      http://www.apache.org/licenses/LICENSE-2.0\n\n.. Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n============\nCartographer\n============\n\n|build| |docs| |license|\n\nPurpose\n=======\n\n`Cartographer`_ is a system that provides real-time simultaneous localization\nand mapping (`SLAM`_) in 2D and 3D across multiple platforms and sensor\nconfigurations.\n\n|video|\n\n.. _Cartographer: https://github.com/googlecartographer/cartographer\n.. _SLAM: https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping\n\nOpen house\n==========\n\nWe regularly meet in an open-for-all Google hangout to discuss progress and plans for Cartographer.\n\nThe next Cartographer Open House Hangout is on Thursday, January 25, 5pm CET (8am PT) [`Hangouts link`_].\n\n.. _Hangouts link: https://staging.talkgadget.google.com/hangouts/_/google.com/cartographeropenhouse\n\n- January 11, 2018: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/180111/slides.pdf\u003e`_\n- December 7, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/171207/slides.pdf\u003e`_\n- November 23, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/171123/slides.pdf\u003e`_\n- November 9, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/171109/slides.pdf\u003e`_\n- October 26, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/171026/slides.pdf\u003e`_\n- October 12, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/171012/slides.pdf\u003e`_\n- September 14, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/170914/slides.pdf\u003e`_\n- August 17, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/170817/slides.pdf\u003e`_\n- July 20, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/170720/slides.pdf\u003e`_\n- July 6, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/170706/slides.pdf\u003e`_\n- June 22, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/170622/sildes.pdf\u003e`_\n- June 8, 2017: `Slides \u003chttps://storage.googleapis.com/cartographer-public-data/cartographer-open-house/170608/slides.pdf\u003e`_\n\nGetting started\n===============\n\n* Learn to use Cartographer at `our Read the Docs site`_.\n* Please join the `mailing list`_ and ask questions.\n\n.. _our Read the Docs site: https://google-cartographer.readthedocs.io\n.. _mailing list: https://groups.google.com/forum/#!forum/google-cartographer\n\nContributing\n============\n\nYou can find information about contributing to Cartographer at `our Contribution\npage`_.\n\n.. _our Contribution page: https://github.com/googlecartographer/cartographer/blob/master/CONTRIBUTING.md\n\n.. |build| image:: https://travis-ci.org/googlecartographer/cartographer.svg?branch=master\n    :alt: Build Status\n    :scale: 100%\n    :target: https://travis-ci.org/googlecartographer/cartographer\n.. |docs| image:: https://readthedocs.org/projects/google-cartographer/badge/?version=latest\n    :alt: Documentation Status\n    :scale: 100%\n    :target: https://google-cartographer.readthedocs.io/en/latest/?badge=latest\n.. |license| image:: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n     :alt: Apache 2 license.\n     :scale: 100%\n     :target: https://github.com/googlecartographer/cartographer/blob/master/LICENSE\n.. |video| image:: https://j.gifs.com/wp3BJM.gif\n    :alt: Cartographer 3D SLAM Demo\n    :scale: 100%\n    :target: https://youtu.be/DM0dpHLhtX0\n","remote_repo_id":64732358,"sha":"bcfa1016fbd9b38acabb47f3f6399da2d701860c","size":4180}
,{"name":"monero","owner":"monero-project","path":"README.md","readme":"# Monero\n\nCopyright (c) 2014-2017 The Monero Project.   \nPortions Copyright (c) 2012-2013 The Cryptonote developers.\n\n## Development resources\n\n- Web: [getmonero.org](https://getmonero.org)\n- Forum: [forum.getmonero.org](https://forum.getmonero.org)\n- Mail: [dev@getmonero.org](mailto:dev@getmonero.org)\n- GitHub: [https://github.com/monero-project/monero](https://github.com/monero-project/monero)\n- IRC: [#monero-dev on Freenode](http://webchat.freenode.net/?randomnick=1\u0026channels=%23monero-dev\u0026prompt=1\u0026uio=d4)\n\n## Vulnerability response\n\n- Our [Vulnerability Response Process](https://github.com/monero-project/meta/blob/master/VULNERABILITY_RESPONSE_PROCESS.md) encourages responsible disclosure\n- We are also available via [HackerOne](https://hackerone.com/monero)\n\n## Build\n\n| Operating System      | Processor | Status |\n| --------------------- | -------- |--------|\n| Ubuntu 16.04          |  i686    | [![Ubuntu 16.04 i686](https://build.getmonero.org/png?builder=monero-static-ubuntu-i686)](https://build.getmonero.org/builders/monero-static-ubuntu-i686)\n| Ubuntu 16.04          |  amd64   | [![Ubuntu 16.04 amd64](https://build.getmonero.org/png?builder=monero-static-ubuntu-amd64)](https://build.getmonero.org/builders/monero-static-ubuntu-amd64)\n| Ubuntu 16.04          |  armv7   | [![Ubuntu 16.04 armv7](https://build.getmonero.org/png?builder=monero-static-ubuntu-arm7)](https://build.getmonero.org/builders/monero-static-ubuntu-arm7)\n| Debian Stable         |  armv8   | [![Debian armv8](https://build.getmonero.org/png?builder=monero-static-debian-armv8)](https://build.getmonero.org/builders/monero-static-debian-armv8)\n| OSX 10.10             |  amd64   | [![OSX 10.10 amd64](https://build.getmonero.org/png?builder=monero-static-osx-10.10)](https://build.getmonero.org/builders/monero-static-osx-10.10)\n| OSX 10.11             |  amd64   | [![OSX 10.11 amd64](https://build.getmonero.org/png?builder=monero-static-osx-10.11)](https://build.getmonero.org/builders/monero-static-osx-10.11)\n| OSX 10.12             |  amd64   | [![OSX 10.12 amd64](https://build.getmonero.org/png?builder=monero-static-osx-10.12)](https://build.getmonero.org/builders/monero-static-osx-10.12)\n| FreeBSD 11            |  amd64   | [![FreeBSD 11 amd64](https://build.getmonero.org/png?builder=monero-static-freebsd64)](https://build.getmonero.org/builders/monero-static-freebsd64)\n| DragonFly BSD 4.6     |  amd64   | [![DragonFly BSD amd64](https://build.getmonero.org/png?builder=monero-static-dragonflybsd-amd64)](https://build.getmonero.org/builders/monero-static-dragonflybsd-amd64)\n| Windows (MSYS2/MinGW) |  i686    | [![Windows (MSYS2/MinGW) i686](https://build.getmonero.org/png?builder=monero-static-win32)](https://build.getmonero.org/builders/monero-static-win32)\n| Windows (MSYS2/MinGW) |  amd64   | [![Windows (MSYS2/MinGW) amd64](https://build.getmonero.org/png?builder=monero-static-win64)](https://build.getmonero.org/builders/monero-static-win64)\n\n## Coverage\n\n| Type      | Status |\n|-----------|--------|\n| Coverity  | [![Coverity Status](https://scan.coverity.com/projects/9657/badge.svg)](https://scan.coverity.com/projects/9657/)\n| Coveralls | [![Coveralls Status](https://coveralls.io/repos/github/monero-project/monero/badge.svg?branch=master)](https://coveralls.io/github/monero-project/monero?branch=master)\n| License   | [![License](https://img.shields.io/badge/license-BSD3-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n\n## Introduction\n\nMonero is a private, secure, untraceable, decentralised digital currency. You are your bank, you control your funds, and nobody can trace your transfers unless you allow them to do so.\n\n**Privacy:** Monero uses a cryptographically sound system to allow you to send and receive funds without your transactions being easily revealed on the blockchain (the ledger of transactions that everyone has). This ensures that your purchases, receipts, and all transfers remain absolutely private by default.\n\n**Security:** Using the power of a distributed peer-to-peer consensus network, every transaction on the network is cryptographically secured. Individual wallets have a 25 word mnemonic seed that is only displayed once, and can be written down to backup the wallet. Wallet files are encrypted with a passphrase to ensure they are useless if stolen.\n\n**Untraceability:** By taking advantage of ring signatures, a special property of a certain type of cryptography, Monero is able to ensure that transactions are not only untraceable, but have an optional measure of ambiguity that ensures that transactions cannot easily be tied back to an individual user or computer.\n\n## About this project\n\nThis is the core implementation of Monero. It is open source and completely free to use without restrictions, except for those specified in the license agreement below. There are no restrictions on anyone creating an alternative implementation of Monero that uses the protocol and network in a compatible manner.\n\nAs with many development projects, the repository on Github is considered to be the \"staging\" area for the latest changes. Before changes are merged into that branch on the main repository, they are tested by individual developers in their own branches, submitted as a pull request, and then subsequently tested by contributors who focus on testing and code reviews. That having been said, the repository should be carefully considered before using it in a production environment, unless there is a patch in the repository for a particular show-stopping issue you are experiencing. It is generally a better idea to use a tagged release for stability.\n\n**Anyone is welcome to contribute to Monero's codebase!** If you have a fix or code change, feel free to submit it as a pull request directly to the \"master\" branch. In cases where the change is relatively small or does not affect other parts of the codebase it may be merged in immediately by any one of the collaborators. On the other hand, if the change is particularly large or complex, it is expected that it will be discussed at length either well in advance of the pull request being submitted, or even directly on the pull request.\n\n## Supporting the project\n\nMonero is a 100% community-sponsored endeavor. If you want to join our efforts, the easiest thing you can do is support the project financially. Both Monero and Bitcoin donations can be made to **donate.getmonero.org** if using a client that supports the [OpenAlias](https://openalias.org) standard. Alternatively you can send XMR to the Monero donation address via the `donate` command (type `help` in the command-line wallet for details).\n\nThe Monero donation address is: `44AFFq5kSiGBoZ4NMDwYtN18obc8AemS33DBLWs3H7otXft3XjrpDtQGv7SqSsaBYBb98uNbr2VBBEt7f2wfn3RVGQBEP3A` (viewkey: `f359631075708155cc3d92a32b75a7d02a5dcf27756707b47a2b31b21c389501`)\n\nThe Bitcoin donation address is: `1KTexdemPdxSBcG55heUuTjDRYqbC5ZL8H`\n\nCore development funding and/or some supporting services are also graciously provided by sponsors:\n\n[\u003cimg width=\"80\" src=\"https://static.getmonero.org/images/sponsors/mymonero.png\"/\u003e](https://mymonero.com)\n[\u003cimg width=\"150\" src=\"https://static.getmonero.org/images/sponsors/kitware.png?1\"/\u003e](http://kitware.com)\n[\u003cimg width=\"100\" src=\"https://static.getmonero.org/images/sponsors/dome9.png\"/\u003e](http://dome9.com)\n[\u003cimg width=\"150\" src=\"https://static.getmonero.org/images/sponsors/araxis.png\"/\u003e](http://araxis.com)\n[\u003cimg width=\"150\" src=\"https://static.getmonero.org/images/sponsors/jetbrains.png\"/\u003e](http://www.jetbrains.com/)\n[\u003cimg width=\"150\" src=\"https://static.getmonero.org/images/sponsors/navicat.png\"/\u003e](http://www.navicat.com/)\n[\u003cimg width=\"150\" src=\"https://static.getmonero.org/images/sponsors/symas.png\"/\u003e](http://www.symas.com/)\n\nThere are also several mining pools that kindly donate a portion of their fees, [a list of them can be found on our Bitcointalk post](https://bitcointalk.org/index.php?topic=583449.0).\n\n## License\n\nSee [LICENSE](LICENSE).\n\n## Contributing\n\nIf you want to help out, see [CONTRIBUTING](CONTRIBUTING.md) for a set of guidelines.\n\n## Scheduled mandatory software upgrades\n\nMonero uses a fixed-schedule mandatory software upgrade (hard fork) mechanism to implement new features. This means that users of Monero (end users and service providers) need to run current versions and upgrade their software on a regular schedule. Mandatory software upgrades occur during the months of March and September. The required software for these upgrades will be available prior to the scheduled date. Please check the repository prior to this date for the proper Monero software version. Below is the historical schedule and the projected schedule for the next upgrade.\nDates are provided in the format YYYY-MM-DD. \n\n\n| Software upgrade block height | Date       | Fork version | Minimum Monero version | Recommended Monero version | Details                                                                            |  \n| ------------------------------ | -----------| ----------------- | ---------------------- | -------------------------- | ---------------------------------------------------------------------------------- |\n| 1009827                        | 2016-03-22 | v2                | v0.9.4                 | v0.9.4                     | Allow only \u003e= ringsize 3, blocktime = 120 seconds, fee-free blocksize 60 kb       |\n| 1141317                        | 2016-09-21 | v3                | v0.9.4                 | v0.10.0                    | Splits coinbase into denominations  |\n| 1220516                        | 2017-01-05 | v4                | v0.10.1                | v0.10.2.1                  | Allow normal and RingCT transactions |\n| 1288616                        | 2017-04-15 | v5                | v0.10.3.0              | v0.10.3.1                  | Adjusted minimum blocksize and fee algorithm      |\n| 1400000                        | 2017-09-16 | v6                | v0.11.0.0              | v0.11.0.0                  | Allow only RingCT transactions, allow only \u003e= ringsize 5      |\n| XXXXXXX                        | 2018-03-XX | XX                | XXXXXXXXX              | XXXXXXXXX                  | XXXXXX\n\nX's indicate that these details have not been determined as of commit date, 2017-09-20. \n\n## Release staging schedule and protocol\n\nApproximately three months prior to a scheduled mandatory software upgrade, a branch from Master will be created with the new release version tag. Pull requests that address bugs should then be made to both Master and the new release branch. Pull requests that require extensive review and testing (generally, optimizations and new features) should *not* be made to the release branch. \n\n## Installing Monero from a package\n\nPackages are available for\n\n* Ubuntu and [snap supported](https://snapcraft.io/docs/core/install) systems, via a community contributed build.\n\n    snap install monero --beta\n\nInstalling a snap is very quick. Snaps are secure. They are isolated with all of their dependencies. Snaps also auto update when a new version is released.\n\n* Arch Linux (via [AUR](https://aur.archlinux.org/)):\n  - Stable release: [`monero`](https://aur.archlinux.org/packages/monero)\n  - Bleeding edge: [`monero-git`](https://aur.archlinux.org/packages/monero-git)\n\n* Void Linux:\n\n    xbps-install -S monero\n\n* GuixSD\n\n        guix package -i monero\n\n* OS X via [Homebrew](http://brew.sh)\n\n        brew tap sammy007/cryptonight\n        brew install monero --build-from-source\n\n* Docker\n\n        # Build using all available cores\n        docker build -t monero .\n\n        # or build using a specific number of cores (reduce RAM requirement)\n        docker build --build-arg NPROC=1 -t monero .\n     \n        # either run in foreground\n        docker run -it -v /monero/chain:/root/.bitmonero -v /monero/wallet:/wallet -p 18080:18080 monero\n\n        # or in background\n        docker run -it -d -v /monero/chain:/root/.bitmonero -v /monero/wallet:/wallet -p 18080:18080 monero\n\nPackaging for your favorite distribution would be a welcome contribution!\n\n## Compiling Monero from source\n\n### Dependencies\n\nThe following table summarizes the tools and libraries required to build. A\nfew of the libraries are also included in this repository (marked as\n\"Vendored\"). By default, the build uses the library installed on the system,\nand ignores the vendored sources. However, if no library is found installed on\nthe system, then the vendored source will be built and used. The vendored\nsources are also used for statically-linked builds because distribution\npackages often include only shared library binaries (`.so`) but not static\nlibrary archives (`.a`).\n\n| Dep            | Min. version  | Vendored | Debian/Ubuntu pkg  | Arch pkg       | Optional | Purpose        |\n| -------------- | ------------- | ---------| ------------------ | -------------- | -------- | -------------- |\n| GCC            | 4.7.3         | NO       | `build-essential`  | `base-devel`   | NO       |                |\n| CMake          | 3.0.0         | NO       | `cmake`            | `cmake`        | NO       |                |\n| pkg-config     | any           | NO       | `pkg-config`       | `base-devel`   | NO       |                |\n| Boost          | 1.58          | NO       | `libboost-all-dev` | `boost`        | NO       | C++ libraries  |\n| OpenSSL        | basically any | NO       | `libssl-dev`       | `openssl`      | NO       | sha256 sum     |\n| libzmq         | 3.0.0         | NO       | `libzmq3-dev`      | `zeromq`       | NO       | ZeroMQ library |\n| libunbound     | 1.4.16        | YES      | `libunbound-dev`   | `unbound`      | NO       | DNS resolver   |\n| libsodium      | ?             | NO       | `libsodium-dev`    | ?              | NO       | libsodium      |\n| libminiupnpc   | 2.0           | YES      | `libminiupnpc-dev` | `miniupnpc`    | YES      | NAT punching   |\n| libunwind      | any           | NO       | `libunwind8-dev`   | `libunwind`    | YES      | Stack traces   |\n| liblzma        | any           | NO       | `liblzma-dev`      | `xz`           | YES      | For libunwind  |\n| libreadline    | 6.3.0         | NO       | `libreadline6-dev` | `readline`     | YES      | Input editing  |\n| ldns           | 1.6.17        | NO       | `libldns-dev`      | `ldns`         | YES      | SSL toolkit    |\n| expat          | 1.1           | NO       | `libexpat1-dev`    | `expat`        | YES      | XML parsing    |\n| GTest          | 1.5           | YES      | `libgtest-dev`^    | `gtest`        | YES      | Test suite     |\n| Doxygen        | any           | NO       | `doxygen`          | `doxygen`      | YES      | Documentation  |\n| Graphviz       | any           | NO       | `graphviz`         | `graphviz`     | YES      | Documentation  |\n\n\n[^] On Debian/Ubuntu `libgtest-dev` only includes sources and headers. You must\nbuild the library binary manually. This can be done with the following command ```sudo apt-get install libgtest-dev \u0026\u0026 cd /usr/src/gtest \u0026\u0026 sudo cmake . \u0026\u0026 sudo make \u0026\u0026 sudo mv libg* /usr/lib/ ```\n\n### Build instructions\n\nMonero uses the CMake build system and a top-level [Makefile](Makefile) that\ninvokes cmake commands as needed.\n\n#### On Linux and OS X\n\n* Install the dependencies\n* Change to the root of the source code directory and build:\n\n        cd monero\n        make\n\n    *Optional*: If your machine has several cores and enough memory, enable\n    parallel build by running `make -j\u003cnumber of threads\u003e` instead of `make`. For\n    this to be worthwhile, the machine should have one core and about 2GB of RAM\n    available per thread.\n\n    *Note*: If cmake can not find zmq.hpp file on OS X, installing `zmq.hpp` from\n    https://github.com/zeromq/cppzmq to `/usr/local/include` should fix that error.\n\n* The resulting executables can be found in `build/release/bin`\n\n* Add `PATH=\"$PATH:$HOME/monero/build/release/bin\"` to `.profile`\n\n* Run Monero with `monerod --detach`\n\n* **Optional**: build and run the test suite to verify the binaries:\n\n        make release-test\n\n    *NOTE*: `core_tests` test may take a few hours to complete.\n\n* **Optional**: to build binaries suitable for debugging:\n\n         make debug\n\n* **Optional**: to build statically-linked binaries:\n\n         make release-static\n\n* **Optional**: build documentation in `doc/html` (omit `HAVE_DOT=YES` if `graphviz` is not installed):\n\n        HAVE_DOT=YES doxygen Doxyfile\n\n#### On the Raspberry Pi\n\nTested on a Raspberry Pi Zero with a clean install of minimal Raspbian Stretch (2017-09-07 or later) from https://www.raspberrypi.org/downloads/raspbian/. If you are using Raspian Jessie, [please see note in the following section](#note-for-raspbian-jessie-users). \n\n* `apt-get update \u0026\u0026 apt-get upgrade` to install all of the latest software\n\n* Install the dependencies for Monero from the 'Debian' column in the table above.\n\n* Increase the system swap size:\n```\t\n\tsudo /etc/init.d/dphys-swapfile stop  \n\tsudo nano /etc/dphys-swapfile  \n\tCONF_SWAPSIZE=1024  \n\tsudo /etc/init.d/dphys-swapfile start  \n```\n* Clone monero and checkout most recent release version:\n```\n        git clone https://github.com/monero-project/monero.git\n\tcd monero\n\tgit checkout tags/v0.11.0.0\n```\n* Build:\n```\n        make release\n```\n* Wait 4-6 hours\n\n* The resulting executables can be found in `build/release/bin`\n\n* Add `PATH=\"$PATH:$HOME/monero/build/release/bin\"` to `.profile`\n\n* Run Monero with `monerod --detach`\n\n* You may wish to reduce the size of the swap file after the build has finished, and delete the boost directory from your home directory\n\n#### *Note for Raspbian Jessie users:*\n\nIf you are using the older Raspbian Jessie image, compiling Monero is a bit more complicated. The version of Boost available in the Debian Jessie repositories is too old to use with Monero, and thus you must compile a newer version yourself. The following explains the extra steps, and has been tested on a Raspberry Pi 2 with a clean install of minimal Raspbian Jessie.\n\n* As before, `apt-get update \u0026\u0026 apt-get upgrade` to install all of the latest software, and increase the system swap size\n\n```\t\n\tsudo /etc/init.d/dphys-swapfile stop  \n\tsudo nano /etc/dphys-swapfile  \n\tCONF_SWAPSIZE=1024  \n\tsudo /etc/init.d/dphys-swapfile start  \n```\n\n* Then, install the dependencies for Monero except `libunwind` and `libboost-all-dev`\n\n* Install the latest version of boost (this may first require invoking `apt-get remove --purge libboost*` to remove a previous version if you're not using a clean install):\n```\n\tcd  \n\twget https://sourceforge.net/projects/boost/files/boost/1.64.0/boost_1_64_0.tar.bz2  \n\ttar xvfo boost_1_64_0.tar.bz2  \n\tcd boost_1_64_0  \n\t./bootstrap.sh  \n\tsudo ./b2  \n```\n* Wait ~8 hours\n```\n\tsudo ./bjam install\n```\n* Wait ~4 hours\n\n* From here, follow the [general Raspberry Pi instructions](#on-the-raspberry-pi) from the \"Clone monero and checkout most recent release version\" step.\n\n#### On Windows:\n\nBinaries for Windows are built on Windows using the MinGW toolchain within\n[MSYS2 environment](http://msys2.github.io). The MSYS2 environment emulates a\nPOSIX system. The toolchain runs within the environment and *cross-compiles*\nbinaries that can run outside of the environment as a regular Windows\napplication.\n\n**Preparing the build environment**\n\n* Download and install the [MSYS2 installer](http://msys2.github.io), either the 64-bit or the 32-bit package, depending on your system.\n* Open the MSYS shell via the `MSYS2 Shell` shortcut\n* Update packages using pacman:  \n\n        pacman -Syuu  \n\n* Exit the MSYS shell using Alt+F4  \n* Edit the properties for the `MSYS2 Shell` shortcut changing \"msys2_shell.bat\" to \"msys2_shell.cmd -mingw64\" for 64-bit builds or \"msys2_shell.cmd -mingw32\" for 32-bit builds\n* Restart MSYS shell via modified shortcut and update packages again using pacman:  \n\n        pacman -Syuu  \n\n\n* Install dependencies:\n\n    To build for 64-bit Windows:\n\n        pacman -S mingw-w64-x86_64-toolchain make mingw-w64-x86_64-cmake mingw-w64-x86_64-boost mingw-w64-x86_64-openssl mingw-w64-x86_64-zeromq mingw-w64-x86_64-libsodium\n\n    To build for 32-bit Windows:\n \n        pacman -S mingw-w64-i686-toolchain make mingw-w64-i686-cmake mingw-w64-i686-boost mingw-w64-i686-openssl mingw-w64-i686-zeromq mingw-w64-i686-libsodium\n\n* Open the MingW shell via `MinGW-w64-Win64 Shell` shortcut on 64-bit Windows\n  or `MinGW-w64-Win64 Shell` shortcut on 32-bit Windows. Note that if you are\n  running 64-bit Windows, you will have both 64-bit and 32-bit MinGW shells.\n\n**Building**\n\n* If you are on a 64-bit system, run:\n\n        make release-static-win64\n\n* If you are on a 32-bit system, run:\n\n        make release-static-win32\n\n* The resulting executables can be found in `build/release/bin`\n\n### On FreeBSD:\n\nThe project can be built from scratch by following instructions for Linux above. If you are running monero in a jail you need to add the flag: `allow.sysvipc=1` to your jail configuration, otherwise lmdb will throw the error message: `Failed to open lmdb environment: Function not implemented`.\n\nWe expect to add Monero into the ports tree in the near future, which will aid in managing installations using ports or packages.\n\n### On OpenBSD:\n\n#### OpenBSD \u003c 6.2\n\nThis has been tested on OpenBSD 5.8.\n\nYou will need to add a few packages to your system. `pkg_add db cmake gcc gcc-libs g++ miniupnpc gtest`.\n\nThe doxygen and graphviz packages are optional and require the xbase set.\n\nThe Boost package has a bug that will prevent librpc.a from building correctly. In order to fix this, you will have to Build boost yourself from scratch. Follow the directions here (under \"Building Boost\"):\nhttps://github.com/bitcoin/bitcoin/blob/master/doc/build-openbsd.md\n\nYou will have to add the serialization, date_time, and regex modules to Boost when building as they are needed by Monero.\n\nTo build: `env CC=egcc CXX=eg++ CPP=ecpp DEVELOPER_LOCAL_TOOLS=1 BOOST_ROOT=/path/to/the/boost/you/built make release-static-64`\n\n#### OpenBSD \u003e= 6.2\n\nYou will need to add a few packages to your system. Choose version 4 for db. `pkg_add db cmake miniupnpc zeromq`.\n\nThe doxygen and graphviz packages are optional and require the xbase set.\n\n\nBuild the Boost library using clang. This guide is derived from: https://github.com/bitcoin/bitcoin/blob/master/doc/build-openbsd.md\n\nWe assume you are compiling with a non-root user and you have `doas` enabled.\n\nNote: do not use the boost package provided by OpenBSD, as we are installing boost to `/usr/local`.\n\n```\n# Create boost building directory\nmkdir ~/boost\ncd ~/boost\n\n# Fetch boost source\nftp -o boost_1_64_0.tar.bz2 https://netcologne.dl.sourceforge.net/project/boost/boost/1.64.0/boost_1_64_0.tar.bz2 \n\n# MUST output: (SHA256) boost_1_64_0.tar.bz2: OK\necho \"7bcc5caace97baa948931d712ea5f37038dbb1c5d89b43ad4def4ed7cb683332 boost_1_64_0.tar.bz2\" | sha256 -c\ntar xfj boost_1_64_0.tar.bz2\n\n# Fetch a boost patch, required for OpenBSD\nftp -o boost.patch https://raw.githubusercontent.com/openbsd/ports/bee9e6df517077a7269ff0dfd57995f5c6a10379/devel/boost/patches/patch-boost_test_impl_execution_monitor_ipp\ncd boost_1_64_0\npatch -p0 \u003c ../boost.patch\n\n# Start building boost\necho 'using clang : : c++ : \u003ccxxflags\u003e\"-fvisibility=hidden -fPIC\" \u003clinkflags\u003e\"\" \u003carchiver\u003e\"ar\" \u003cstriper\u003e\"strip\"  \u003cranlib\u003e\"ranlib\" \u003crc\u003e\"\" : ;' \u003e user-config.jam\n./bootstrap.sh --without-icu --with-libraries=chrono,filesystem,program_options,system,thread,test,date_time,regex,serialization --with-toolset=clang\n./b2 toolset=clang cxxflags=\"-stdlib=libc++\" linkflags=\"-stdlib=libc++\"\ndoas ./b2 -d0 runtime-link=shared threadapi=pthread threading=multi link=static variant=release --layout=tagged --build-type=complete --user-config=user-config.jam -sNO_BZIP2=1 --prefix=/usr/local install\n```\n\nBuild cppzmq\n\nBuild the cppzmq bindings.\n\nWe assume you are compiling with a non-root user and you have `doas` enabled.\n\n```\n# Create a library link so cmake is able to find it\ndoas ln -s /usr/local/lib/libzmq.so.4.1 /usr/local/lib/libzmq.so\n\n# Create cppzmq building directory\nmkdir ~/cppzmq\ncd ~/cppzmq\n\n# Fetch cppzmq source\nftp -o cppzmq-4.2.2.tar.gz https://github.com/zeromq/cppzmq/archive/v4.2.2.tar.gz\n\n# MUST output: (SHA256) cppzmq-4.2.2.tar.gz: OK\necho \"3ef50070ac5877c06c6bb25091028465020e181bbfd08f110294ed6bc419737d cppzmq-4.2.2.tar.gz\" | sha256 -c\ntar xfz cppzmq-4.2.2.tar.gz\n\n# Start building cppzmq\ncd cppzmq-4.2.2\nmkdir build\ncd build\ncmake ..\ndoas make install\n```\n\nBuild monero: `env DEVELOPER_LOCAL_TOOLS=1 BOOST_ROOT=/usr/local make release-static`\n\n### On Solaris:\n\nThe default Solaris linker can't be used, you have to install GNU ld, then run cmake manually with the path to your copy of GNU ld:\n\n        mkdir -p build/release\n        cd build/release\n        cmake -DCMAKE_LINKER=/path/to/ld -D CMAKE_BUILD_TYPE=Release ../..\n        cd ../..\n\nThen you can run make as usual.\n\n### On Linux for Android (using docker):\n\n        # Build image (select android64.Dockerfile for aarch64)\n        cd utils/build_scripts/ \u0026\u0026 docker build -f android32.Dockerfile -t monero-android .\n        # Create container\n        docker create -it --name monero-android monero-android bash\n        # Get binaries\n        docker cp monero-android:/opt/android/monero/build/release/bin .\n\n### Building portable statically linked binaries\n\nBy default, in either dynamically or statically linked builds, binaries target the specific host processor on which the build happens and are not portable to other processors. Portable binaries can be built using the following targets:\n\n* ```make release-static-linux-x86_64``` builds binaries on Linux on x86_64 portable across POSIX systems on x86_64 processors\n* ```make release-static-linux-i686``` builds binaries on Linux on x86_64 or i686 portable across POSIX systems on i686 processors\n* ```make release-static-linux-armv8``` builds binaries on Linux portable across POSIX systems on armv8 processors\n* ```make release-static-linux-armv7``` builds binaries on Linux portable across POSIX systems on armv7 processors\n* ```make release-static-linux-armv6``` builds binaries on Linux portable across POSIX systems on armv6 processors\n* ```make release-static-win64``` builds binaries on 64-bit Windows portable across 64-bit Windows systems\n* ```make release-static-win32``` builds binaries on 64-bit or 32-bit Windows portable across 32-bit Windows systems\n\n## Running monerod\n\nThe build places the binary in `bin/` sub-directory within the build directory\nfrom which cmake was invoked (repository root by default). To run in\nforeground:\n\n    ./bin/monerod\n\nTo list all available options, run `./bin/monerod --help`.  Options can be\nspecified either on the command line or in a configuration file passed by the\n`--config-file` argument.  To specify an option in the configuration file, add\na line with the syntax `argumentname=value`, where `argumentname` is the name\nof the argument without the leading dashes, for example `log-level=1`.\n\nTo run in background:\n\n    ./bin/monerod --log-file monerod.log --detach\n\nTo run as a systemd service, copy\n[monerod.service](utils/systemd/monerod.service) to `/etc/systemd/system/` and\n[monerod.conf](utils/conf/monerod.conf) to `/etc/`. The [example\nservice](utils/systemd/monerod.service) assumes that the user `monero` exists\nand its home is the data directory specified in the [example\nconfig](utils/conf/monerod.conf).\n\nIf you're on Mac, you may need to add the `--max-concurrency 1` option to\nmonero-wallet-cli, and possibly monerod, if you get crashes refreshing.\n\n## Internationalization\n\nSee [README.i18n.md](README.i18n.md).\n\n## Using Tor\n\nWhile Monero isn't made to integrate with Tor, it can be used wrapped with torsocks, if you add --p2p-bind-ip 127.0.0.1 to the monerod command line. You also want to set DNS requests to go over TCP, so they'll be routed through Tor, by setting DNS_PUBLIC=tcp or use a particular DNS server with DNS_PUBLIC=tcp://a.b.c.d (default is 8.8.4.4, which is Google DNS). You may also disable IGD (UPnP port forwarding negotiation), which is pointless with Tor. To allow local connections from the wallet, you might have to add TORSOCKS_ALLOW_INBOUND=1, some OSes need it and some don't. Example:\n\n`DNS_PUBLIC=tcp torsocks monerod --p2p-bind-ip 127.0.0.1 --no-igd`\n\nor:\n\n`DNS_PUBLIC=tcp TORSOCKS_ALLOW_INBOUND=1 torsocks monerod --p2p-bind-ip 127.0.0.1 --no-igd`\n\nTAILS ships with a very restrictive set of firewall rules. Therefore, you need to add a rule to allow this connection too, in addition to telling torsocks to allow inbound connections. Full example:\n\n`sudo iptables -I OUTPUT 2 -p tcp -d 127.0.0.1 -m tcp --dport 18081 -j ACCEPT`\n\n`DNS_PUBLIC=tcp torsocks ./monerod --p2p-bind-ip 127.0.0.1 --no-igd --rpc-bind-ip 127.0.0.1 --data-dir /home/amnesia/Persistent/your/directory/to/the/blockchain`\n\n`./monero-wallet-cli`\n\n## Debugging\n\nThis section contains general instructions for debugging failed installs or problems encountered with Monero. First ensure you are running the latest version built from the Github repo.\n\n### Obtaining stack traces and core dumps on Unix systems\n\nWe generally use the tool `gdb` (GNU debugger) to provide stack trace functionality, and `ulimit` to provide core dumps in builds which crash or segfault.\n\n* To use gdb in order to obtain a stack trace for a build that has stalled:\n\nRun the build.\n\nOnce it stalls, enter the following command:\n\n```\ngdb /path/to/monerod `pidof monerod` \n```\n\nType `thread apply all bt` within gdb in order to obtain the stack trace\n\n* If however the core dumps or segfaults:\n\nEnter `ulimit -c unlimited` on the command line to enable unlimited filesizes for core dumps\n\nEnter `echo core | sudo tee /proc/sys/kernel/core_pattern` to stop cores from being hijacked by other tools\n\nRun the build.\n\nWhen it terminates with an output along the lines of \"Segmentation fault (core dumped)\", there should be a core dump file in the same directory as monerod. It may be named just `core`, or `core.xxxx` with numbers appended.\n\nYou can now analyse this core dump with `gdb` as follows:\n\n`gdb /path/to/monerod /path/to/dumpfile`\n\nPrint the stack trace with `bt`\n\n* To run monero within gdb:\n\nType `gdb /path/to/monerod`\n\nPass command-line options with `--args` followed by the relevant arguments\n\nType `run` to run monerod\n\n### Analysing memory corruption\n\nWe use the tool `valgrind` for this.\n\nRun with `valgrind /path/to/monerod`. It will be slow.\n\n### LMDB\n\nInstructions for debugging suspected blockchain corruption as per @HYC\n\nThere is an `mdb_stat` command in the LMDB source that can print statistics about the database but it's not routinely built. This can be built with the following command:\n\n`cd ~/monero/external/db_drivers/liblmdb \u0026\u0026 make`\n\nThe output of `mdb_stat -ea \u003cpath to blockchain dir\u003e` will indicate inconsistencies in the blocks, block_heights and block_info table.\n\nThe output of `mdb_dump -s blocks \u003cpath to blockchain dir\u003e` and `mdb_dump -s block_info \u003cpath to blockchain dir\u003e` is useful for indicating whether blocks and block_info contain the same keys.\n\nThese records are dumped as hex data, where the first line is the key and the second line is the data.\n","remote_repo_id":19316619,"sha":"0de529fe3559b4dd74dd131216748453f300c0ee","size":31172}
,{"name":"fips","owner":"floooh","path":"README.md","readme":"fips\n====\n\n[![Build Status](https://travis-ci.org/floooh/fips.svg?branch=master)](https://travis-ci.org/floooh/fips)\n\nfips is a highlevel build system wrapper written in Python for C/C++ projects.\n\nRead the docs to get a better idea what this means:\n\nhttp://floooh.github.io/fips/index.html\n\n### Public Service Announcements\n\n- **16-Jan-2018**: The iOS build configs now put the resulting .app bundle\ninto the ```fips-deploy/[proj]/[config]/``` directory, so they behave\nthe same as most other target platforms. This makes it\neasier for helper scripts (code generators and verbs) to\nfind the iOS app bundle (for instance to copy asset files).\n\n- **05-Jan-2018**: Import definitions in fips.yml files can now contain an\nexpression which is evaluated in cmake. This can be used to include or\nexclude platform-specific includes. [See here for details](http://floooh.github.io/fips/imports.html)\n\n- **04-Jan-2018**: The previously experimental Visual Studio Code support is\nnow 'official', [see here for details](http://floooh.github.io/2018/01/04/vscode-fips.html)\n\n- **16-Aug-2017**: I found (and fixed) some inconsistent behaviour when \nthe cmake project name is different from the project's directory name,\nthis may change the behaviour of cmake- and python-code-generator\nscripts which used the FIPS\\_PROJECT\\_DEPLOY\\_DIR and \nFIPS\\_PROJECT\\_BUILD\\_DIR (but the previous behaviour was clearly a bug,\nwhich only manifested itself if the cmake project name and directory\nname differed). See this ticket for details: https://github.com/floooh/fips/issues/154\n\n- **25-Apr-2017**: I committed a small fix which changes the order of\nimported dependencies so that imported dependencies now always come\nbefore the importing project. This was often also the case previously\nbut could fail in cases where the same dependency was included from\ndifferent projects. No changes should be required in your project,\nat least if the dependency tree was defined correctly and didn't\ndepend on some hidden ordering.\n\n- **27-Mar-2017**: the root path of the emscripten SDK has changed from\nemsdk\\_portable to emsdk-portable, a fix has been committed, but you\nneed to setup the emscripten SDK again (first, wipe the fips-sdks directory,\nthen run './fips setup emscripten' again from a project directory)\n\n- **25-Feb-2017**: what happened in the last year:\n  - python3 compatibility contributed by Levente Polyak (thanks!)\n  - various Eclipse fixes contributed by Martin Gerhardy (thanks!)\n  - Windows: Cygwin support contributed by Fungos, many thanks! also \n    for the many smaller fixes :)\n  - new verb './fips update' updates all dependencies (unless\n    they have uncommitted or unpushed changes)\n  - new helper functions git.add, git.commit and git.push,\n    these are not exposed as fips verbs, but are useful\n    for writing your own verbs (e.g. build automation scripts)\n  - emscripten: removed the FIPS\\_EMSCRIPTEN\\_EXPORTED\\_FUNCTIONS\n    cmake options, this is better done by directly annotating\n    exported functions with EMSCRIPTEN_KEEPALIVE (or soon\n    [EMSCRIPTEN_EXPORT](https://github.com/kripken/emscripten/pull/4977))\n  - a new predefined cmake variable FIPS\\_BUILD\\_DIR, this points\n    to the build root directory (../fips\\_build)\n  - two new predefined cmake variables FIPS\\_PROJECT\\_BUILD\\_DIR\n    and FIPS\\_PROJECT\\_DEPLOY\\_DIR, these are useful to pass\n    as arguments to code generator scripts\n  - emscripten: use linker response files when using the UNIX\n    Makefiles generator to workaround command line length limit \n    on Windows\n  - emscripten: on Windows, use the the Emscripten SDK incoming\n    branch (requires LLVM compilation, but behaviour is now the\n    same as on OSX and Linux)\n  - fips\\_files\\_ex() and related cmake functions now warn if \n    the globbed file list is empty, previously this generated\n    a rather cryptic cmake syntax error message\n  - emscripten: added support for WebAssembly (toolchain flags \n    and build configs)\n  - emscripten: added a config option FIPS\\_EMSCRIPTEN\\_USE\\_WEBGL2\n  - emscripten: added new cmake options \n    FIPS\\_EMSCRIPTEN\\_USE\\_CPU\\_PROFILER and \n    FIPS\\_EMSCRIPTEN\\_USE\\_MEMORY\\_PROFILER (these generate a build\n    with emscripten's built-in cpu and memory profilers)\n  - emscripten: added a FIPS\\_EMSCRIPTEN\\_USE\\_SAFE\\_HEAP cmake option\n  - emscripten: use the smaller 'shell\\_minimal.html' file instead\n    of the original file which has a big SVG logo in it\n  - emscripten: use the -s NO\\_EXIT\\_RUNTIME which slightly \n    reduces code size \n  - Windows UWP support (not in daily use though)\n\n- **26-Feb-2016**: cmake generator definition in fips build config files\nis now more flexible by exposing the cmake -A (generator platform) \nand -T options (generator toolset), there's now also a 'Default' generator\nwhich lets cmake select the 'best' build file generator for the platform. All this\ntogether simplifies the version situation with Visual Studio on Windows. \nPreviously, the build config win64-vs2013-debug was used as default config.\nWhen only VS2015 is installed, generating build files had failed, unless\nthe build config win64-vs2015-debug was selected manually. Now there's\na new generic default config called **win64-vstudio-debug**. This lets\ncmake pick whatever VStudio version is installed. Of course it is still\npossible to pick a specific Visual Studio version with the 'old' build\nconfigs \\*-vs2013-\\* and \\*-vs2015-\\*.\n\n- **14-Feb-2016**: fips can now import dependencies pinned to a specific git\n  revision (previously only by tag or branch name). Many thanks to fungos\n  (https://github.com/fungos) for implementing this! Here's how a specific\n  revision is specified in the fips.yml file:\n```\n  imports:\n    fips-hello-dep3:\n      git:    https://github.com/fungos/fips-hello-dep3.git\n      rev:    191f59f0\n```\n- **03-Dec-2015**: I have added a new 'no\\_auto\\_import' policy/feature for\n  advanced uses which allows to manually select modules from imported \n  projects. This is more work but can provide a cleaner project layout\n  if only a few modules from imported projects are needed. See the\n  documentation web page for details (http://floooh.github.io/fips/imports.html, \n  search for 'Selectively importing modules'). The default behaviour should\n  be exactly as before. If anything is broken in your project, please\n  don't hesitate to write a ticket :)\n\n- **13-Oct-2015**: 'fips run' has learned to run Android apps, after building\n  your project with one of the Android build configs, simply do a \n  'fips run [target]' like on the other platforms. This will (re-)install\n  the app, launch it, and then run 'adb logcat' (simply hit Ctrl-C when done)\n\n- **10-Oct-2015**: I committed a simplification for nested dependency\n  resolution yesterday (turns out cmake does this on its own with\n  'target_link_libraries'), however this may introduce some link-order problems\n  in existing projects when using GCC or emscripten. If your project no longer\n  links because of this, and you think that fixing the depedency order in the\n  CMakeLists.txt files is too big a hassle and fips should take care of this,\n  please simply open a ticket, and I'll try to find a solution in fips. I\n  haven't made up my mind about this either yet, the few cases in Oryol were\n  easy to fix, but larger projects may be more tricky to fix.\n\n- **29-Jul-2015**: cross-compiling is now more flexible\n    * cross-compile target platform names are no longer hardwired, fips\n      projects can now add define their own cross-compile platforms\n    * fips projects can now provide their own cmake-toolchain files or override\n      the standard toolchain files\n\n- **05-Feb-2015**: the NaCl SDK setup bug has been fixed by the NaCl team, so\n  './fips setup nacl' should now work also with the latest Python 2.7.9\n\n- **01-Feb-2015**: the code generation refactoring branch has been merged back\n  into the master branch, code generation is now controlled with the new\n  **fips_generate()** cmake macro, see [Oryol\n  engine](https://github.com/floooh/oryol) and [code generation doc\n  page](http://floooh.github.io/fips/codegen.html) for details!\n\n- **30-Jan-2015**: please note that the NaCl SDK setup script is currently\n  broken with Python 2.7.9 (2.7.6 works), this is tracked in the following bug:\n  https://code.google.com/p/chromium/issues/detail?id=452137  \n\n### List of Fipsified Projects:\n\nLibs and engines:\n\n- **[accidentalnoise](https://code.google.com/p/accidental-noise-library/)**: https://github.com/mgerhardy/fips-accidentalnoise\n- **[bgfx](https://github.com/bkaradzic/bgfx)**: https://github.com/floooh/fips-bgfx\n- **[cjson](http://cjson.sourceforge.net/)**: https://github.com/floooh/fips-cjson\n- **[cpptoml](https://github.com/skystrife/cpptoml)**: https://github.com/floooh/fips-cpptoml\n- **[enet](https://github.com/lsalzman/enet)**: https://github.com/mgerhardy/fips-enet\n- **[freetype2](http://git.savannah.gnu.org/cgit/freetype/freetype2.git/)**: https://github.com/mgerhardy/fips-freetype2\n- **[glew](https://github.com/nigels-com/glew)**: https://github.com/fungos/fips-glew\n- **[glfw](https://github.com/glfw/glfw)**: https://github.com/floooh/fips-glfw\n- **[gliml](https://github.com/floooh/gliml)**: https://github.com/floooh/gliml\n- **[glm](https://github.com/g-truc/glm)**: https://github.com/floooh/fips-glm\n- **[googletest](https://code.google.com/p/googletest/)**: https://github.com/mgerhardy/fips-googletest\n- **[imgui](https://github.com/ocornut/imgui)**: https://github.com/fungos/fips-imgui\n- **[libcurl (precompiled)](http://curl.haxx.se/libcurl/)**: https://github.com/floooh/fips-libcurl\n- **[libnoise](https://github.com/qknight/libnoise)**: https://github.com/mgerhardy/fips-libnoise\n- **[nanovg](https://github.com/memononen/nanovg)**: https://github.com/fungos/fips-nanovg\n- **[nativefiledialog](https://github.com/mlabbe/nativefiledialog)**: https://github.com/fungos/fips-nfd\n- **[oryol](http://floooh.github.io/oryol/)**: https://github.com/floooh/oryol\n- **[polyvox](https://bitbucket.org/volumesoffun/polyvox.git)**: https://github.com/mgerhardy/fips-polyvox\n- **[recastnavigation](https://github.com/memononen/recastnavigation)**: https://github.com/fungos/fips-recast\n- **[remotery](https://github.com/Celtoys/Remotery)**: https://github.com/floooh/fips-remotery\n- **[sauce](https://github.com/phs/sauce)**: https://github.com/mgerhardy/fips-sauce\n- **[simpleai](https://github.com/mgerhardy/simpleai)**: https://github.com/mgerhardy/fips-simpleai\n- **[stb](https://github.com/nothings/stb)**: https://github.com/fungos/fips-stb\n- **[turbobadger](https://github.com/fruxo/turbobadger)**: https://github.com/fungos/fips-turbobadger\n- **[unittestpp](https://github.com/unittest-cpp/unittest-cpp)**: https://github.com/floooh/fips-unittestpp\n- **[vld (precompiled)](https://github.com/KindDragon/vld)**: https://github.com/floooh/fips-vld\n- **[zlib](http://www.zlib.net/)**: https://github.com/floooh/fips-zlib\n\nTest projects:\n\n- **oryol-test-app**:     https://github.com/floooh/oryol-test-app.git\n- **fips-hello-world**:   https://github.com/floooh/fips-hello-world.git\n- **fips-hello-dep1**:    https://github.com/floooh/fips-hello-dep1.git\n- **fips-hello-dep2**:    https://github.com/floooh/fips-hello-dep2.git\n\n### Progress\n\nfips is currently heavily **work in progress**, everything may change or\nbreak at any time.\n\nI'm trying to put up progress videos from time to time:\n\n- first progress video: https://www.youtube.com/watch?v=6F_AecDqRIY\n- 2nd progress video: https://www.youtube.com/watch?v=W0MYjpR0G8c\n- 3rd progress video: https://www.youtube.com/watch?v=3bQrYYaYU4w\n- 4th progress video: https://vimeo.com/115050871\n- using fips with Oryol 3D engine: https://www.youtube.com/watch?v=LaC4Sqatyts\n- compiling and debugging in QtCreator and CLion IDEs: https://www.youtube.com/watch?v=Sp5TywYeNzE\n- building a standalone Oryol app: https://www.youtube.com/watch?v=z8nwrGh2Zsc\n\n","remote_repo_id":27764892,"sha":"a0015d2e5928c908d69a7493f63e3e218fad69c4","size":11917}
,{"name":"cds","owner":"ovh","path":"README.md","readme":"# CDS: Continuous Delivery Service\n\n[![Join the chat at https://gitter.im/ovh-cds/Lobby](https://badges.gitter.im/ovh-cds/Lobby.svg)](https://gitter.im/ovh-cds/Lobby?utm_source=badge\u0026utm_medium=badge\u0026utm_campaign=pr-badge\u0026utm_content=badge)\n[![Go Report Card](https://goreportcard.com/badge/github.com/ovh/cds)](https://goreportcard.com/report/github.com/ovh/cds)\n[![Coverage Status](https://coveralls.io/repos/github/ovh/cds/badge.svg?branch=master)](https://coveralls.io/github/ovh/cds?branch=master)\n\n\u003cimg align=\"right\" src=\"https://raw.githubusercontent.com/ovh/cds/master/logo-background.png\" width=\"25%\"\u003e\n\nCDS is a pipeline based Continuous Delivery Service written in Go(lang).\n\n**This project is under active development**\n\n## Documentation\n\nDocumentation is available [here](https://ovh.github.io/cds/)\n\n## Overview\n\nCDS is composend of several components\n\n### Engine\n\nThe core component of CDS: [read more](/engine/README.md)\n\n### WebUI\n\nCDS Web UI: [read more](ui/README.md)\n\n### CLI\n\nCDS Command line interface: [read more](https://ovh.github.io/cds/cli/cdsctl/)\n\n### Worker\n\nIn CDS, a worker is an agent executing actions pushed in queue by CDS engine: [read more](https://ovh.github.io/cds/cli/worker/)\n\n### Hatchery\n\nIn CDS, a hatchery is an agent which spawn workers: [read more](https://ovh.github.io/cds/hatchery/)\n\n### Contrib\n\nActions, Plugins, Templates, uServices are under : [read more](contrib)\n\n### SDK\n\nA Go(lang) SDK is available at github.com/ovh/cds/sdk. It provides helper functions for all API handlers, with embedded authentification mechanism.\n\n[![GoDoc](https://godoc.org/github.com/ovh/cds/sdk?status.svg)](https://godoc.org/github.com/ovh/cds/sdk)\n\n## Links\n\n* OVH home (us): https://www.ovh.com/us/\n* OVH home (fr): https://www.ovh.com/fr/\n* OVH community: https://community.ovh.com/c/open-source/continuous-delivery-service\n\n## License\n\n3-clause BSD\n","remote_repo_id":70572539,"sha":"e3d2e0d59a8f6c7a2d058b73bbc79281c8fdddfd","size":1888}
,{"name":"ravendb","owner":"ravendb","path":"readme.md","readme":"# RavenDB - An ACID NoSQL Document Database\nThis repository contains source code for the [RavenDB](https://ravendb.net/) document database. With a RavenDB database you can set up a NoSQL data architecture or add a NoSQL layer to your current relational database.\n\n![RavenDb Studio](docs/readmeScreenshot.png)\n\n## Supported Platforms\n- Windows\n- Linux\n- Docker\n- MacOS\n- Raspberry Pi\n\n## Grab Your License and Latest Version\n**Download the latest version of [RavenDB](https://ravendb.net/downloads#server/dev)**\n\n## Getting Started\nInstall and [set up your database](https://ravendb.net/docs/article-page/latest/csharp/start/getting-started).\n\n## Learn RavenDB Quickly\n[RavenDB Bootcamp](https://ravendb.net/learn) is a free, self-directed learning course. In just three units you will learn how to use RavenDB to create fully-functional, real-world programs with NoSQL Databases. If you are unfamiliar with NoSQL, it’s okay. We will provide you with all the information you need.\n\n## Stay Updated on New Developments\nWe are always adding new features to improve your RavenDB experience. Check out [our latest improvements](https://ravendb.net/docs/article-page/latest/csharp/start/whats-new), updated weekly.\n\n## Documentation\nAccess [full documentation](https://ravendb.net/docs/article-page/latest/csharp) for RavenDB. Like our database, it is easy to use.\n\n## Where to Ask for Help\nIf you have any questions, or need further assistance, you can [contact us directly](https://ravendb.net/contact).\n\n## Report an Issue\nYou can create issues and track them at our [YouTrack](http://issues.hibernatingrhinos.com/) page.\n\n## RavenDB Developer Community Group\nIf you have any questions please visit our [community group](http://groups.google.com/group/ravendb/). The solutions for the most common challenges are available. You are welcome to join!\n\n## Submit a Pull Request\nEach Pull Request will be checked against following rules:\n\n- `cla/signed` - all commit authors need to sign CLA. This can be done using our [CLA sign form](http://ravendb.net/contributors/cla/sign)\n- `commit/whitespace` - all changed files cannot contain TABs inside them. Before doing any work we suggest executing our `git_setup.cmd`. This will install git pre-commit hook that will normalize all whitespaces during commit\n- `commit/message/conventions` - all commit messages (except in merge commits) must contain issue number from our [YouTrack](http://issues.hibernatingrhinos.com) e.g. 'RavenDB-1234 Fixed issue with something'\n- `tests` - this executes `build.cmd Test` on our CI to check if no constraints were violated\n\n \u003cbr\u003e\u003cbr\u003e\n\n## Setup \u0026 Run\n### Prerequisites:\n\n#### Windows\nMicrosoft Visual C++ 2015 Redistributable Package should be installed prior to RavenDB launch.\n[Visual C++ Downloads](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\nSee also: [Windows Prerequisites](https://docs.microsoft.com/en-us/dotnet/core/windows-prerequisites)\n\n#### Linux/MacOS\nIt is recommended that you update your OS before launching an instance of RavenDB.\nFor example, Ubuntu-16.x as an updated OS doesn't require any additional packages.\nlibsodium (1.0.13 or up) must be installed prior to RavenDB launch.\n```\nIn Ubuntu 16.x: apt-get install libsodium-18\nIn MacOS 10.12: brew install libsodium\n```\nYou might need to also install additional packages, for example:\n```\napt-get install libunwind8 liblttng-ust0 libcurl3 libssl1.0.0 libuuid1 libkrb5 zlib1g libicu55\n```\n\nSee also: [Linux Prerequisites](https://docs.microsoft.com/en-us/dotnet/core/linux-prerequisites) or [MacOS Prerequisites](https://docs.microsoft.com/en-us/dotnet/core/macos-prerequisites)\n\n### Lauch RavenDB:\nRunning locally:\n```\n\u003cpath/to/ravendb\u003e/Server/Raven.Server\n```\n\nRegistering as service in Windows:\n```\n.\\rvn.exe windows-service register --service-name RavenDB4\n```\n\nRunning as service in Linux, add to your daemon script:\n```\n\u003cpath/to/ravendb\u003e/Server/Raven.Server --daemon\n```\n\n### Hello World (.NET)\n\n#### Server Side\n\n- Launch RavenDB server instance as follows:\n```\n   \u003cpath/to/ravendb\u003e/Server/Raven.Server --ServerUrl=http://localhost:8080\n```\n\n- Open a web browser and enter `http://localhost:8080`\n- Click on `Databases` on the left menu, and then create a new database named `SampleDataDB`\n- Click on `Settings` and then on `Create Sample Data` in the left menu. Now Click on `Create`\n\n#### Client Side\n\n- Install dotnet core sdk. See : [Downloads](https://www.microsoft.com/net/download) and [PowerShell](https://github.com/PowerShell/PowerShell/releases)\n\n- Open terminal and type:\n\n```\n   mkdir HelloWorld\n   cd HelloWorld\n   dotnet new console\n```\n\n- Add RavenDB Client package:\n\n```\n   dotnet add package RavenDB.Client --version 4.0.0-*\n```\n\n- Replace the content of Program.cs with the following:\n```\nusing System;\nusing Raven.Client.Documents;\n\nnamespace HelloWorld\n{\n    class Shippers\n    {\n        public string Name;\n        public string Phone;\n    }\n    \n    class Program\n    {\n        static void Main(string[] args)\n        {\n            using (var store = new DocumentStore\n            {\n                Urls = new string[] {\"http://localhost:8080\"},\n                Database = \"SampleDataDB\"\n            })\n            {\n                store.Initialize();\n\n                using (var session = store.OpenSession())\n                {\n                    var shipper = session.Load\u003cShippers\u003e(\"shippers/1-A\");\n                    Console.WriteLine(\"Shipper #1 : \" + shipper.Name + \", Phone: \" + shipper.Phone);\n                }\n            }\n        }\n    }\n}\n```\n\n- Type:\n```\n   dotnet restore\n   dotnet build\n   dotnet run\n```\n\n###### Enjoy :)\n","remote_repo_id":542714,"sha":"fd89f17ae756a8f8defea3f4cede41a3fbd9585e","size":5666}
,{"name":"all-cabal-metadata","owner":"commercialhaskell","path":"README.md","readme":"# all-cabal-metadata\n\n[![Build Status](https://travis-ci.org/commercialhaskell/all-cabal-metadata.svg?branch=master)](https://travis-ci.org/commercialhaskell/all-cabal-metadata)\n\nCurrent metadata for all cabal files. Generated using the\n[stackage-metadata](https://github.com/commercialhaskell/all-cabal-metadata-tool)\npackage. You can parse the contents of this repository using that package.\n","remote_repo_id":35514054,"sha":"ab1d7aa9c35087b623daea3c153254e7b7512bf1","size":394}
,{"name":"Chrysoberyl","owner":"catseye","path":"README.markdown","readme":"Chrysoberyl\n===========\n\n*Chrysoberyl* is an attempt to catalogue, and curate, the things produced\nby, and related to, Cat's Eye Technologies.\n\nIt is something between a wiki and a database and a semantic web and\n_The Devil's Dictionary_.\n\nIt is supposed to be primarily informative, and only secondarily machine-\nprocessable, and only thirdly structured.  For this purpose, it has\nhistorically been collected in relatively ad-hoc YAML files, but in 2017\nit was converted to [Feedmark][] format, which is a subset of Markdown.\n\nThese Feedmark articles can be found in [the articles directory](articles/).\n\nChrysoberyl contains primarily things produced by Cat's Eye Technologies;\nit only contains things not produced by Cat's Eye Technologies when they\ndirectly relate to things that are (e.g. Perl 5.12 might have an entry,\nbut only as a \"Project Dependency\", not as a \"Programming Language\".)\n\nThis README used to contain a lot more information, but a lot of it has\ngone out of date at this point, but if you're interested, you can look\nit up in this repository's history.\n\n[Feedmark]: http://catseye.tc/node/Feedmark\n","remote_repo_id":5296382,"sha":"c411f31225f19ac7e7a737fd09c3e4d465d0f4bd","size":1120}
,{"name":"skipper","owner":"zalando","path":"readme.md","readme":"[![Build Status](https://travis-ci.org/zalando/skipper.svg)](https://travis-ci.org/zalando/skipper)\n[![GoDoc](https://godoc.org/github.com/zalando/skipper?status.svg)](https://godoc.org/github.com/zalando/skipper)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Go Report Card](https://goreportcard.com/badge/zalando/skipper)](https://goreportcard.com/report/zalando/skipper)\n[![codecov](https://codecov.io/gh/zalando/skipper/branch/master/graph/badge.svg)](https://codecov.io/gh/zalando/skipper)\n\n\u003cp\u003e\u003cimg height=\"360\" alt=\"Skipper\" src=\"https://raw.githubusercontent.com/zalando/skipper/gh-pages/img/skipper.h360.png\"\u003e\u003c/p\u003e\n\n# Skipper\n\nSkipper is an HTTP router and reverse proxy for service composition. It's designed to handle \u003e100k HTTP route\ndefinitions with detailed lookup conditions, and flexible augmentation of the request flow with filters. It can be\nused out of the box or extended with custom lookup, filter logic and configuration sources.\n\n### NOTE for Skoap users\n\nThe Skoap filters can be found currently in the branch called 'skoap-migration'. The original incubator repository at zalando-incubator/skoap has been removed.\n\n## Main features:\n\nAn overview of [deployments and data-clients](https://zalando.github.io/skipper/deployments/)\nshows some use cases to run skipper.\n\nSkipper\n\n- identifies routes based on the requests' properties, such as path, method, host and headers\n- allows modification of the requests and responses with filters that are independently configured for each route\n- simultaneously streams incoming requests and backend responses\n- optionally acts as a final endpoint (shunt), e.g. as a static file server or a mock backend for diagnostics\n- updates routing rules without downtime, while supporting multiple types of data sources — including\n  [etcd](https://github.com/coreos/etcd), [Kubernetes Ingress](https://zalando.github.io/skipper/dataclients/kubernetes/), [Innkeeper](https://github.com/zalando/innkeeper), [static files](https://zalando.github.io/skipper/dataclients/eskip-file/), [route string](https://zalando.github.io/skipper/dataclients/route-string/) and\n  [custom configuration sources](https://godoc.org/github.com/zalando/skipper/predicates/source)\n- can serve as a\n  [Kubernetes Ingress controller](https://zalando.github.io/skipper/dataclients/kubernetes/)\n  without reloads. You can use it in combination with a controller that will route public traffic to\n  your skipper fleet; [see AWS example](https://github.com/zalando-incubator/kube-ingress-aws-controller)\n- shipped with eskip: a descriptive configuration language designed for routing rules\n\nSkipper provides a default executable command with a few built-in filters. However, its primary use case is to\nbe extended with custom filters, predicates or data sources. [Go here for additional documentation](https://godoc.org/github.com/zalando/skipper).\n\nA few examples for extending Skipper:\n\n- Authentication proxy https://github.com/zalando-incubator/skoap (repository removed see 'skoap-migration' branch)\n- Image server https://github.com/zalando-stups/skrop\n- Plugins https://github.com/skipper-plugins/\n\n### Getting Started\n\n#### Prerequisites/Requirements\n\nIn order to build and run Skipper, only the latest version of Go needs to be installed. Skipper can use\nInnkeeper or Etcd as data sources for routes, or for the simplest cases, a local configuration file. See more\ndetails in the documentation: https://godoc.org/github.com/zalando/skipper.\n\n\n#### Installation\n\nSkipper is 'go get' compatible. If needed, create a Go workspace first:\n\n    mkdir ws\n    cd ws\n    export GOPATH=$(pwd)\n    export PATH=$PATH:$GOPATH/bin\n\nGet the Skipper packages:\n\n    go get github.com/zalando/skipper/...\n\n\n#### Running\n\nCreate a file with a route:\n\n    echo 'hello: Path(\"/hello\") -\u003e \"https://www.example.org\"' \u003e example.eskip\n\nOptionally, verify the file's syntax:\n\n    eskip check example.eskip\n\nStart Skipper and make an HTTP request:\n\n    skipper -routes-file example.eskip \u0026\n    curl localhost:9090/hello\n\n##### Docker\n\nTo run the latest Docker container:\n\n    docker run registry.opensource.zalan.do/pathfinder/skipper:latest\n\n#### Working with the code\n\nGetting the code with the test dependencies (`-t` switch):\n\n    go get -t github.com/zalando/skipper/...\n\nBuild and test all packages:\n\n    cd src/github.com/zalando/skipper\n    make deps\n    make install\n    make check\n\n\n#### Kubernetes Ingress\n\nSkipper can be used to run as an Kubernetes Ingress controller.\n[Details with examples](https://zalando.github.io/skipper/dataclients/kubernetes)\nof [Skipper's capabilities](https://zalando.github.io/skipper/dataclients/kubernetes/#skipper-features) and an\n[overview](https://zalando.github.io/skipper/deployments/#kubernetes-ingress)\nyou will can be found in our [deployment docs](https://zalando.github.io/skipper).\n\nFor AWS integration, we provide an ingress controller\nhttps://github.com/zalando-incubator/kube-ingress-aws-controller, that\nmanage ALBs in front of your skipper deployment.\nA production example,\nhttps://github.com/zalando-incubator/kubernetes-on-aws/blob/dev/cluster/manifests/skipper/daemonset.yaml,\ncan be found in our Kubernetes configuration https://github.com/zalando-incubator/kubernetes-on-aws.\n\n### Documentation\n\n[Skipper's Documentation](https://zalando.github.io/skipper) and\n[Godoc developer documentation](https://godoc.org/github.com/zalando/skipper),\nincludes information about [deployment use cases](https://zalando.github.io/skipper/deployments/)\nand detailed information on these topics:\n\n- The [Routing](https://godoc.org/github.com/zalando/skipper/routing) Mechanism\n- Matching Requests\n- [Filters](https://godoc.org/github.com/zalando/skipper/filters) - Augmenting Requests and Responses\n- Service Backends\n- Route Definitions\n- Data Sources: [eskip file](https://godoc.org/github.com/zalando/skipper/eskipfile), [etcd](https://godoc.org/github.com/zalando/skipper/etcd), [Inkeeper API](https://godoc.org/github.com/zalando/skipper/innkeeper), [Kubernetes](https://godoc.org/github.com/zalando/skipper/dataclients/kubernetes), [Route string](https://godoc.org/github.com/zalando/skipper/dataclients/routestring)\n- [Circuit Breakers](https://godoc.org/github.com/zalando/skipper/filters/circuit)\n- Extending It with Customized Predicates, Filters, and Builds\n- [Predicates](https://godoc.org/github.com/zalando/skipper/predicates) - additional predicates to match a route\n- [Proxy Packages](https://godoc.org/github.com/zalando/skipper/proxy)\n- [Logging](https://godoc.org/github.com/zalando/skipper/logging) and [Metrics](https://godoc.org/github.com/zalando/skipper/metrics)\n- Performance Considerations\n- [Rate Limiters](https://godoc.org/github.com/zalando/skipper/filters/ratelimit)\n- [Opentracing plugin](https://github.com/skipper-plugins/opentracing/)\n\n#### 1 Minute Skipper introduction\n\nThe following example shows a skipper routes file in eskip format, that has 3 named routes: baidu, google and yandex.\n\n    % cat doc-1min-intro.eskip\n    baidu:\n            Path(\"/baidu\")\n            -\u003e setRequestHeader(\"Host\", \"www.baidu.com\")\n            -\u003e setPath(\"/s\")\n            -\u003e setQuery(\"wd\", \"godoc skipper\")\n            -\u003e \"http://www.baidu.com\";\n    google:\n            *\n            -\u003e setPath(\"/search\")\n            -\u003e setQuery(\"q\", \"godoc skipper\")\n            -\u003e \"https://www.google.com\";\n    yandex:\n            * \u0026\u0026 Cookie(\"yandex\", \"true\")\n            -\u003e setPath(\"/search/\")\n            -\u003e setQuery(\"text\", \"godoc skipper\")\n            -\u003e tee(\"http://127.0.0.1:12345/\")\n            -\u003e \"https://yandex.ru\";\n\nMatching the route:\n\n- baidu is using Path() matching to differentiate the HTTP requests to select the route.\n- google is the default matching with wildcard '*'\n- yandex is the default matching with wildcard '*' if you have a cookie \"yandex=true\"\n\nRequest Filters:\n\n- If baidu is selected, skipper sets the Host header, changes the path and sets a query string to the http request to the backend \"http://www.baidu.com\".\n- If google is selected, skipper changes the path and sets a query string to the http request to the backend \"https://www.google.com\".\n- If yandex is selected, skipper changes the path and sets a query string to the http request to the backend \"https://yandex.ru\". The modified request will be copied to \"http://127.0.0.1:12345/\"\n\nRun skipper with the routes file doc-1min-intro.eskip shown above\n\n    % skipper -routes-file doc-1min-intro.eskip\n\nTo test each route you can use curl:\n\n    % curl -v localhost:9090/baidu\n    % curl -v localhost:9090/\n    % curl -v --cookie \"yandex=true\" localhost:9090/\n\nTo see the request that is made by the tee() filter you can use nc:\n\n    [terminal1]% nc -l 12345\n    [terminal2]% curl -v --cookie \"yandex=true\" localhost:9090/\n\n#### 3 Minutes Skipper in Kubernetes introduction\n\nYou should have a base understanding of [Kubernetes](https://kubernetes.io) and\n[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/).\n\nPrerequisites: First you have to install skipper-ingress as for\nexample daemonset, create a deployment and a service.\n\nWe start to deploy skipper-ingress as a daemonset, use hostNetwork and\nexpose the TCP port 9999 on each Kubernetes worker node for incoming ingress\ntraffic.\n\n    % cat skipper-ingress-ds.yaml\n    apiVersion: extensions/v1beta1\n    kind: DaemonSet\n    metadata:\n      name: skipper-ingress\n      namespace: kube-system\n      labels:\n        application: skipper-ingress\n        version: v0.9.115\n        component: ingress\n    spec:\n      selector:\n        matchLabels:\n          application: skipper-ingress\n      updateStrategy:\n        type: RollingUpdate\n      template:\n        metadata:\n          name: skipper-ingress\n          labels:\n            application: skipper-ingress\n            version: v0.9.115\n            component: ingress\n          annotations:\n            scheduler.alpha.kubernetes.io/critical-pod: ''\n        spec:\n          affinity:\n            nodeAffinity:\n              requiredDuringSchedulingIgnoredDuringExecution:\n                nodeSelectorTerms:\n                - matchExpressions:\n                  - key: master\n                    operator: DoesNotExist\n          tolerations:\n          - key: CriticalAddonsOnly\n            operator: Exists\n          hostNetwork: true\n          containers:\n          - name: skipper-ingress\n            image: registry.opensource.zalan.do/pathfinder/skipper:v0.9.115\n            ports:\n            - name: ingress-port\n              containerPort: 9999\n              hostPort: 9999\n            args:\n              - \"skipper\"\n              - \"-kubernetes\"\n              - \"-kubernetes-in-cluster\"\n              - \"-address=:9999\"\n              - \"-proxy-preserve-host\"\n              - \"-serve-host-metrics\"\n              - \"-enable-ratelimits\"\n              - \"-experimental-upgrade\"\n              - \"-metrics-exp-decay-sample\"\n            resources:\n              limits:\n                cpu: 200m\n                memory: 200Mi\n              requests:\n                cpu: 25m\n                memory: 25Mi\n            readinessProbe:\n              httpGet:\n                path: /kube-system/healthz\n                port: 9999\n              initialDelaySeconds: 5\n              timeoutSeconds: 5\n\n\nWe now deploy a simple demo application serving html:\n\n    % cat demo-deployment.yaml\n    apiVersion: apps/v1beta1\n    kind: Deployment\n    metadata:\n      name: skipper-demo\n    spec:\n      replicas: 2\n      template:\n        metadata:\n          labels:\n            application: skipper-demo\n        spec:\n          containers:\n          - name: skipper-demo\n            image: registry.opensource.zalan.do/pathfinder/skipper:v0.9.117\n            args:\n              - \"skipper\"\n              - \"-inline-routes\"\n              - \"* -\u003e inlineContent(\\\"\u003cbody style='color: white; background-color: green;'\u003e\u003ch1\u003eHello!\u003c/h1\u003e\\\") -\u003e \u003cshunt\u003e\"\n            ports:\n            - containerPort: 9090\n\nWe deploy a service type ClusterIP that we will select from ingress:\n\n    % cat demo-svc.yaml\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: sszuecs-demo\n      labels:\n        application: skipper-demo\n    spec:\n      type: ClusterIP\n      ports:\n        - port: 80\n          protocol: TCP\n          targetPort: 9090\n          name: external\n      selector:\n        application: sszuecs-demo\n\nTo deploy both, you have to run:\n\n    % kubectl create -f demo-deployment.yaml\n    % kubectl create -f demo-svc.yaml\n\nNow we have a skipper-ingress running as daemonset exposing the TCP\nport 9999 on each worker node, a backend application running with 2\nreplicas that serves some html on TCP port 9090, and we expose a\ncluster service on TCP port 80. Besides skipper-ingress, deployment\nand service can not be reached from outside the cluster. Now we expose\nthe application with Ingress to the external network:\n\n    % cat demo-ing.yaml\n    apiVersion: extensions/v1beta1\n    kind: Ingress\n    metadata:\n      name: skipper-demo\"\n    spec:\n      rules:\n      - host: skipper-demo.\u003cmydomain.org\u003e\n        http:\n          paths:\n          - backend:\n              serviceName: skipper-demo\"\n              servicePort: 80\n\nTo deploy this ingress, you have to run:\n\n    % kubectl create -f demo-ing.yaml\n\nSkipper will configure itself for the given ingress, such that you can test doing:\n\n    % curl -v -H\"Host: skipper-demo.\u003cmydomain.org\u003e\" http://\u003cnodeip\u003e:9999/\n\nThe next question you may ask is: how to expose this to your customers?\n\nThe answer depends on your setup and complexity requirements. In the\nsimplest case you could add one A record in your DNS *.\u003cmydomain.org\u003e\nto your frontend loadbalancer IP that directs all traffic from *.\u003cmydomain.org\u003e\nto all Kubernetes worker nodes on TCP port 9999.\n\nA more complex setup we use in production and can be done with\nsomething that configures your frontend loadbalancer, for example\n[kube-aws-ingress-controller](https://github.com/zalando-incubator/kube-ingress-aws-controller),\nand your DNS, [external-dns](https://github.com/kubernetes-incubator/external-dns)\nautomatically.\n\n### Packaging support\n\nSee https://github.com/zalando/skipper/blob/master/packaging/readme.md\n\nIn case you want to implement and link your own modules into your\nskipper for more advanced features like [opentracing API](https://github.com/opentracing) support there\nis https://github.com/skipper-plugins organization to enable you to do\nso. In order to explain you the build process with custom Go modules\nthere is https://github.com/skipper-plugins/skipper-tracing-build,\nthat is used to build skipper's [opentracing package](https://github.com/skipper-plugins/opentracing).\n\n\n## Community\n\nUser or developer questions can be asked in our [public Google Group](https://groups.google.com/forum/#!forum/skipper-router)\n\n### Proposals\n\nWe do our proposals open in [Skipper's Google drive](https://drive.google.com/drive/folders/0B9LwJMF9koB-ZEk4bEhZal9uOWM).\nIf you want to make a proposal feel free to create an\n[issue](https://github.com/zalando/skipper/issues) and if it is a\nbigger change we will invite you to a document, such that we can work together.\n","remote_repo_id":38812664,"sha":"2af09700bf3301ff7baaa2aced4f135ea923c1bb","size":15233}
,{"name":"grimoirelab-toolkit","owner":"grimoirelab","path":"README.md","readme":"# GrimoireLab Toolkit [![Build Status](https://travis-ci.org/grimoirelab/grimoirelab-toolkit.svg?branch=master)](https://travis-ci.org/grimoirelab/grimoirelab-toolkit) [![Coverage Status](https://img.shields.io/coveralls/grimoirelab/grimoirelab-toolkit.svg)](https://coveralls.io/r/grimoirelab/grimoirelab-toolkit?branch=master)\n\nToolkit of common functions used across GrimoireLab projects.\n\nThis package provides a library composed by functions widely used in other\nGrimoireLab projects. These function deal with date handling, introspection,\nURIs/URLs, among other topics.\n\n## Requirements\n\n* Python \u003e= 3.4\n* python3-dateutil \u003e= 2.6\n\n## Installation\n\n```\n$ pip3 install -r requirements.txt\n$ python3 setup.py install\n```\n\n## License\n\nLicensed under GNU General Public License (GPL), version 3 or later.\n","remote_repo_id":91110001,"sha":"0331cdd1e417eb973966d68221baf1673f25737c","size":806}
